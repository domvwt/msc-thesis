
@misc{akibaOptunaNextgenerationHyperparameter2019,
  title = {Optuna: {{A Next-generation Hyperparameter Optimization Framework}}},
  shorttitle = {Optuna},
  author = {Akiba, Takuya and Sano, Shotaro and Yanase, Toshihiko and Ohta, Takeru and Koyama, Masanori},
  date = {2019-07-25},
  number = {arXiv:1907.10902},
  eprint = {1907.10902},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1907.10902},
  url = {http://arxiv.org/abs/1907.10902},
  urldate = {2022-09-19},
  abstract = {The purpose of this study is to introduce new design-criteria for next-generation hyperparameter optimization software. The criteria we propose include (1) define-by-run API that allows users to construct the parameter search space dynamically, (2) efficient implementation of both searching and pruning strategies, and (3) easy-to-setup, versatile architecture that can be deployed for various purposes, ranging from scalable distributed computing to light-weight experiment conducted via interactive interface. In order to prove our point, we will introduce Optuna, an optimization software which is a culmination of our effort in the development of a next generation optimization software. As an optimization software designed with define-by-run principle, Optuna is particularly the first of its kind. We will present the design-techniques that became necessary in the development of the software that meets the above criteria, and demonstrate the power of our new design through experimental results and real world applications. Our software is available under the MIT license (https://github.com/pfnet/optuna/).},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/domvwt/Zotero/storage/T7IGCJ62/Akiba et al. - 2019 - Optuna A Next-generation Hyperparameter Optimizat.pdf;/home/domvwt/Zotero/storage/T7BATBQW/1907.html}
}

@unpublished{akogluGraphbasedAnomalyDetection2014,
  title = {Graph-Based {{Anomaly Detection}} and {{Description}}: {{A Survey}}},
  shorttitle = {Graph-Based {{Anomaly Detection}} and {{Description}}},
  author = {Akoglu, Leman and Tong, Hanghang and Koutra, Danai},
  date = {2014-04-28},
  number = {arXiv:1404.4679},
  eprint = {1404.4679},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1404.4679},
  url = {http://arxiv.org/abs/1404.4679},
  urldate = {2022-06-12},
  abstract = {Detecting anomalies in data is a vital task, with numerous high-impact applications in areas such as security, finance, health care, and law enforcement. While numerous techniques have been developed in past years for spotting outliers and anomalies in unstructured collections of multi-dimensional points, with graph data becoming ubiquitous, techniques for structured \{\textbackslash em graph\} data have been of focus recently. As objects in graphs have long-range correlations, a suite of novel technology has been developed for anomaly detection in graph data. This survey aims to provide a general, comprehensive, and structured overview of the state-of-the-art methods for anomaly detection in data represented as graphs. As a key contribution, we provide a comprehensive exploration of both data mining and machine learning algorithms for these \{\textbackslash em detection\} tasks. we give a general framework for the algorithms categorized under various settings: unsupervised vs. (semi-)supervised approaches, for static vs. dynamic graphs, for attributed vs. plain graphs. We highlight the effectiveness, scalability, generality, and robustness aspects of the methods. What is more, we stress the importance of anomaly \{\textbackslash em attribution\} and highlight the major techniques that facilitate digging out the root cause, or the `why', of the detected anomalies for further analysis and sense-making. Finally, we present several real-world applications of graph-based anomaly detection in diverse domains, including financial, auction, computer traffic, and social networks. We conclude our survey with a discussion on open theoretical and practical challenges in the field.},
  archiveprefix = {arXiv},
  issue = {arXiv:1404.4679},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Social and Information Networks},
  file = {/home/domvwt/Zotero/storage/DU9XP2TV/Akoglu et al. - 2014 - Graph-based Anomaly Detection and Description A S.pdf;/home/domvwt/Zotero/storage/CB2E5CCP/1404.html}
}

@incollection{akogluOddballSpottingAnomalies2010,
  title = {Oddball: {{Spotting Anomalies}} in {{Weighted Graphs}}},
  shorttitle = {Oddball},
  booktitle = {Advances in {{Knowledge Discovery}} and {{Data Mining}}},
  author = {Akoglu, Leman and McGlohon, Mary and Faloutsos, Christos},
  editor = {Zaki, Mohammed J. and Yu, Jeffrey Xu and Ravindran, B. and Pudi, Vikram},
  date = {2010},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  volume = {6119},
  pages = {410--421},
  publisher = {{Springer Berlin Heidelberg}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-13672-6_40},
  url = {http://link.springer.com/10.1007/978-3-642-13672-6_40},
  urldate = {2022-06-13},
  abstract = {Given a large, weighted graph, how can we find anomalies? Which rules should be violated, before we label a node as an anomaly? We propose the OddBall algorithm, to find such nodes. The contributions are the following: (a) we discover several new rules (power laws) in density, weights, ranks and eigenvalues that seem to govern the socalled “neighborhood sub-graphs” and we show how to use these rules for anomaly detection; (b) we carefully choose features, and design OddBall, so that it is scalable and it can work un-supervised (no user-defined constants) and (c) we report experiments on many real graphs with up to 1.6 million nodes, where OddBall indeed spots unusual nodes that agree with intuition.},
  editorb = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard},
  editorbtype = {redactor},
  isbn = {978-3-642-13671-9 978-3-642-13672-6},
  langid = {english},
  annotation = {Series Editors: \_:n290},
  file = {/home/domvwt/Zotero/storage/8Z77X9QL/Akoglu et al. - 2010 - oddball Spotting Anomalies in Weighted Graphs.pdf}
}

@online{ApacheSparkUnified2022,
  title = {Apache {{Spark}}: A Unified Engine for Big Data Processing: {{Communications}} of the {{ACM}}: {{Vol}} 59, {{No}} 11},
  date = {2022-06-13},
  url = {https://dl.acm.org/doi/10.1145/2934664},
  urldate = {2022-06-13},
  file = {/home/domvwt/Zotero/storage/Z6ADAHLP/2934664.html}
}

@inproceedings{atwoodDiffusionConvolutionalNeuralNetworks2016,
  title = {Diffusion-{{Convolutional Neural Networks}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Atwood, James and Towsley, Don},
  date = {2016},
  volume = {29},
  publisher = {{Curran Associates, Inc.}},
  url = {https://papers.nips.cc/paper/2016/hash/390e982518a50e280d8e2b535462ec1f-Abstract.html},
  urldate = {2022-09-18},
  abstract = {We present diffusion-convolutional neural networks (DCNNs), a new model for graph-structured data.  Through the introduction of a diffusion-convolution operation, we show how diffusion-based representations can be learned from graph-structured data and used as an effective basis for node classification. DCNNs have several attractive qualities, including a latent representation for graphical data that is invariant under isomorphism, as well as polynomial-time prediction and learning that can be represented as tensor operations and efficiently implemented on a GPU.  Through several experiments with real structured datasets, we demonstrate that DCNNs are able to  outperform probabilistic relational models and kernel-on-graph methods at relational node classification tasks.}
}

@online{BeneficialOwnershipData2022,
  title = {Beneficial {{Ownership Data Standard}}},
  date = {2022-09-18},
  url = {https://www.openownership.org/en/topics/beneficial-ownership-data-standard/},
  urldate = {2022-09-18},
  abstract = {The Beneficial Ownership Data Standard is an open standard providing guidance for collecting, sharing and using high-quality data on beneficial ownership},
  langid = {english},
  organization = {{openownership.org}},
  file = {/home/domvwt/Zotero/storage/RHMC32Y5/beneficial-ownership-data-standard.html}
}

@book{berger-wolfProceedings2019SIAM2019,
  title = {Proceedings of the 2019 {{SIAM International Conference}} on {{Data Mining}}},
  editor = {Berger-Wolf, Tanya and Chawla, Nitesh},
  date = {2019-05-06},
  publisher = {{Society for Industrial and Applied Mathematics}},
  location = {{Philadelphia, PA}},
  doi = {10.1137/1.9781611975673},
  url = {https://epubs.siam.org/doi/book/10.1137/1.9781611975673},
  urldate = {2022-06-13},
  abstract = {Attributed networks are ubiquitous and form a critical component of modern information infrastructure, where additional node attributes complement the raw network structure in knowledge discovery. Recently, detecting anomalous nodes on attributed networks has attracted an increasing amount of research attention, with broad applications in various high-impact domains, such as cybersecurity, finance, and healthcare. Most of the existing attempts, however, tackle the problem with shallow learning mechanisms by ego-network or community analysis, or through subspace selection. Undoubtedly, these models cannot fully address the computational challenges on attributed networks. For example, they often suffer from the network sparsity and data nonlinearity issues, and fail to capture the complex interactions between different information modalities, thus negatively impact the performance of anomaly detection. To tackle the aforementioned problems, in this paper, we study the anomaly detection problem on attributed networks by developing a novel deep model. In particular, our proposed deep model: (1) explicitly models the topological structure and nodal attributes seamlessly for node embedding learning with the prevalent graph convolutional network (GCN); and (2) is customized to address the anomaly detection problem by virtue of deep autoencoder that leverages the learned embeddings to reconstruct the original data. The synergy between GCN and autoencoder enables us to spot anomalies by measuring the reconstruction errors of nodes from both the structure and the attribute perspectives. Extensive experiments on real-world attributed network datasets demonstrate the efficacy of our proposed algorithm.},
  isbn = {978-1-61197-567-3},
  langid = {english},
  file = {/home/domvwt/Zotero/storage/C2GN2SPK/Berger-Wolf and Chawla - 2019 - Proceedings of the 2019 SIAM International Confere.pdf}
}

@book{bondyGraphTheory1982,
  title = {Graph {{Theory}}},
  author = {Bondy, Adrian and Murty, U. S. R.},
  date = {1982},
  eprint = {5Z71jwEACAAJ},
  eprinttype = {googlebooks},
  publisher = {{Springer London}},
  abstract = {The primary aim of this book is to present a coherent introduction to graph theory, suitable as a textbook for advanced undergraduate and beginning graduate students in mathematics and computer science. It provides a systematic treatment of the theory of graphs without sacrificing its intuitive and aesthetic appeal. Commonly used proof techniques are described and illustrated. The book also serves as an introduction to research in graph theory.},
  isbn = {978-1-84800-663-8},
  langid = {english},
  pagetotal = {655},
  keywords = {Computers / Data Science / General,Computers / Programming / Algorithms,Mathematics / Applied,Mathematics / Combinatorics,Mathematics / Discrete Mathematics,Mathematics / Numerical Analysis,Mathematics / Optimization}
}

@online{Book2022,
  title = {About the {{Book}}},
  date = {2022-04-27},
  url = {http://www.databookuw.com/databookuw.com/index.html},
  urldate = {2022-04-27},
  langid = {english},
  organization = {{DATA DRIVEN SCIENCE \& ENGINEERING}},
  file = {/home/domvwt/Zotero/storage/7WVI5T7S/www.databookuw.com.html}
}

@misc{brancoSurveyPredictiveModelling2015,
  title = {A {{Survey}} of {{Predictive Modelling}} under {{Imbalanced Distributions}}},
  author = {Branco, Paula and Torgo, Luis and Ribeiro, Rita},
  date = {2015-05-13},
  number = {arXiv:1505.01658},
  eprint = {1505.01658},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1505.01658},
  url = {http://arxiv.org/abs/1505.01658},
  urldate = {2022-09-12},
  abstract = {Many real world data mining applications involve obtaining predictive models using data sets with strongly imbalanced distributions of the target variable. Frequently, the least common values of this target variable are associated with events that are highly relevant for end users (e.g. fraud detection, unusual returns on stock markets, anticipation of catastrophes, etc.). Moreover, the events may have different costs and benefits, which when associated with the rarity of some of them on the available training data creates serious problems to predictive modelling techniques. This paper presents a survey of existing techniques for handling these important applications of predictive analytics. Although most of the existing work addresses classification tasks (nominal target variables), we also describe methods designed to handle similar problems within regression tasks (numeric target variables). In this survey we discuss the main challenges raised by imbalanced distributions, describe the main approaches to these problems, propose a taxonomy of these methods and refer to some related problems within predictive modelling.},
  archiveprefix = {arXiv},
  issue = {arXiv:1505.01658},
  keywords = {Computer Science - Machine Learning,I.2.6},
  file = {/home/domvwt/Zotero/storage/JMU7Y7UK/Branco et al. - 2015 - A Survey of Predictive Modelling under Imbalanced .pdf;/home/domvwt/Zotero/storage/GN2QBGNQ/1505.html}
}

@online{brownleeROCCurvesPrecisionRecall2020,
  title = {{{ROC Curves}} and {{Precision-Recall Curves}} for {{Imbalanced Classification}}},
  author = {Brownlee, Jason},
  date = {2020-01-05T18:00:37+00:00},
  url = {https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-imbalanced-classification/},
  urldate = {2022-09-12},
  abstract = {Most imbalanced classification problems involve two classes: a negative case with the majority of examples and a positive case with a minority of examples. Two diagnostic tools that help in the interpretation of binary (two-class) classification predictive models are ROC Curves and Precision-Recall curves. Plots from the curves can be created and used to understand […]},
  langid = {american},
  organization = {{Machine Learning Mastery}},
  file = {/home/domvwt/Zotero/storage/4DM86HMC/roc-curves-and-precision-recall-curves-for-imbalanced-classification.html}
}

@unpublished{brunaSpectralNetworksLocally2014,
  title = {Spectral {{Networks}} and {{Locally Connected Networks}} on {{Graphs}}},
  author = {Bruna, Joan and Zaremba, Wojciech and Szlam, Arthur and LeCun, Yann},
  date = {2014-05-21},
  number = {arXiv:1312.6203},
  eprint = {1312.6203},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1312.6203},
  url = {http://arxiv.org/abs/1312.6203},
  urldate = {2022-06-13},
  abstract = {Convolutional Neural Networks are extremely efficient architectures in image and audio recognition tasks, thanks to their ability to exploit the local translational invariance of signal classes over their domain. In this paper we consider possible generalizations of CNNs to signals defined on more general domains without the action of a translation group. In particular, we propose two constructions, one based upon a hierarchical clustering of the domain, and another based on the spectrum of the graph Laplacian. We show through experiments that for low-dimensional graphs it is possible to learn convolutional layers with a number of parameters independent of the input size, resulting in efficient deep architectures.},
  archiveprefix = {arXiv},
  issue = {arXiv:1312.6203},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  file = {/home/domvwt/Zotero/storage/CLDL846L/Bruna et al. - 2014 - Spectral Networks and Locally Connected Networks o.pdf;/home/domvwt/Zotero/storage/IKKQIFAS/1312.html}
}

@unpublished{busbridgeRelationalGraphAttention2019,
  title = {Relational {{Graph Attention Networks}}},
  author = {Busbridge, Dan and Sherburn, Dane and Cavallo, Pietro and Hammerla, Nils Y.},
  date = {2019-04-11},
  number = {arXiv:1904.05811},
  eprint = {1904.05811},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1904.05811},
  url = {http://arxiv.org/abs/1904.05811},
  urldate = {2022-06-13},
  abstract = {We investigate Relational Graph Attention Networks, a class of models that extends non-relational graph attention mechanisms to incorporate relational information, opening up these methods to a wider variety of problems. A thorough evaluation of these models is performed, and comparisons are made against established benchmarks. To provide a meaningful comparison, we retrain Relational Graph Convolutional Networks, the spectral counterpart of Relational Graph Attention Networks, and evaluate them under the same conditions. We find that Relational Graph Attention Networks perform worse than anticipated, although some configurations are marginally beneficial for modelling molecular properties. We provide insights as to why this may be, and suggest both modifications to evaluation strategies, as well as directions to investigate for future work.},
  archiveprefix = {arXiv},
  issue = {arXiv:1904.05811},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/domvwt/Zotero/storage/IN6DLDNQ/Busbridge et al. - 2019 - Relational Graph Attention Networks.pdf;/home/domvwt/Zotero/storage/CW2ZHUQM/1904.html}
}

@inproceedings{catherineBankAccountClassification2021,
  title = {Bank {{Account Classification}} for {{Gambling Transactions}}},
  booktitle = {2021 3rd {{East Indonesia Conference}} on {{Computer}} and {{Information Technology}} ({{EIConCIT}})},
  author = {{Catherine} and {Denny} and Shihab, Muhammad Rifki},
  date = {2021-04},
  pages = {302--308},
  doi = {10.1109/EIConCIT50028.2021.9431874},
  abstract = {Financial services provided by banks are often misused for money laundering. Gambling is a criminal offense in the jurisdiction of the Republic of Indonesia. The increase in the number of customers is a challenge for the Bank to supervise the financial transactions. Based on the previous research, classification in machine learning often used to identify money laundering in the banking industry. However, there are no studies about identifying misuse of accounts in gambling activities using machine learning. This research used real financial transaction data using the SLR, experimental, and semi structured interviews with several Subject Matter Expertise. The results of this study indicate the classification with ensemble algorithms such as LightGBM can identify gambling accounts. Based on the evaluation results of classification performance with LightGBM, this model has the best performance compared to other ensemble models at a precision of 97.26\%. These findings can be used as a basis for automatic reporting of suspicious financial transactions to financial regulatory.},
  eventtitle = {2021 3rd {{East Indonesia Conference}} on {{Computer}} and {{Information Technology}} ({{EIConCIT}})},
  keywords = {classification,Computational modeling,Error analysis,gambling,machine learning,Machine learning,Machine learning algorithms,money laundering,Performance evaluation,Stakeholders,Training},
  file = {/home/domvwt/Zotero/storage/QYPJKW2K/9431874.html}
}

@unpublished{chalapathyDeepLearningAnomaly2019,
  title = {Deep {{Learning}} for {{Anomaly Detection}}: {{A Survey}}},
  shorttitle = {Deep {{Learning}} for {{Anomaly Detection}}},
  author = {Chalapathy, Raghavendra and Chawla, Sanjay},
  date = {2019-01-23},
  number = {arXiv:1901.03407},
  eprint = {1901.03407},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1901.03407},
  url = {http://arxiv.org/abs/1901.03407},
  urldate = {2022-06-12},
  abstract = {Anomaly detection is an important problem that has been well-studied within diverse research areas and application domains. The aim of this survey is two-fold, firstly we present a structured and comprehensive overview of research methods in deep learning-based anomaly detection. Furthermore, we review the adoption of these methods for anomaly across various application domains and assess their effectiveness. We have grouped state-of-the-art research techniques into different categories based on the underlying assumptions and approach adopted. Within each category we outline the basic anomaly detection technique, along with its variants and present key assumptions, to differentiate between normal and anomalous behavior. For each category, we present we also present the advantages and limitations and discuss the computational complexity of the techniques in real application domains. Finally, we outline open issues in research and challenges faced while adopting these techniques.},
  archiveprefix = {arXiv},
  issue = {arXiv:1901.03407},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/domvwt/Zotero/storage/6ZQERYCA/Chalapathy and Chawla - 2019 - Deep Learning for Anomaly Detection A Survey.pdf;/home/domvwt/Zotero/storage/BIJGKCM7/1901.html}
}

@article{chandolaAnomalyDetectionSurvey2009,
  title = {Anomaly Detection: {{A}} Survey},
  shorttitle = {Anomaly Detection},
  author = {Chandola, Varun and Banerjee, Arindam and Kumar, Vipin},
  date = {2009-07-30},
  journaltitle = {ACM Computing Surveys},
  shortjournal = {ACM Comput. Surv.},
  volume = {41},
  number = {3},
  pages = {15:1--15:58},
  issn = {0360-0300},
  doi = {10.1145/1541880.1541882},
  url = {https://doi.org/10.1145/1541880.1541882},
  urldate = {2022-06-12},
  abstract = {Anomaly detection is an important problem that has been researched within diverse research areas and application domains. Many anomaly detection techniques have been specifically developed for certain application domains, while others are more generic. This survey tries to provide a structured and comprehensive overview of the research on anomaly detection. We have grouped existing techniques into different categories based on the underlying approach adopted by each technique. For each category we have identified key assumptions, which are used by the techniques to differentiate between normal and anomalous behavior. When applying a given technique to a particular domain, these assumptions can be used as guidelines to assess the effectiveness of the technique in that domain. For each category, we provide a basic anomaly detection technique, and then show how the different existing techniques in that category are variants of the basic technique. This template provides an easier and more succinct understanding of the techniques belonging to each category. Further, for each category, we identify the advantages and disadvantages of the techniques in that category. We also provide a discussion on the computational complexity of the techniques since it is an important issue in real application domains. We hope that this survey will provide a better understanding of the different directions in which research has been done on this topic, and how techniques developed in one area can be applied in domains for which they were not intended to begin with.},
  issue = {3},
  keywords = {Anomaly detection,outlier detection}
}

@article{chawlaSMOTESyntheticMinority2002,
  title = {{{SMOTE}}: {{Synthetic Minority Over-sampling Technique}}},
  shorttitle = {{{SMOTE}}},
  author = {Chawla, N. V. and Bowyer, K. W. and Hall, L. O. and Kegelmeyer, W. P.},
  date = {2002-06-01},
  journaltitle = {Journal of Artificial Intelligence Research},
  shortjournal = {jair},
  volume = {16},
  eprint = {1106.1813},
  eprinttype = {arxiv},
  primaryclass = {cs},
  pages = {321--357},
  issn = {1076-9757},
  doi = {10.1613/jair.953},
  url = {http://arxiv.org/abs/1106.1813},
  urldate = {2022-09-18},
  abstract = {An approach to the construction of classifiers from imbalanced datasets is described. A dataset is imbalanced if the classification categories are not approximately equally represented. Often real-world data sets are predominately composed of "normal" examples with only a small percentage of "abnormal" or "interesting" examples. It is also the case that the cost of misclassifying an abnormal (interesting) example as a normal example is often much higher than the cost of the reverse error. Under-sampling of the majority (normal) class has been proposed as a good means of increasing the sensitivity of a classifier to the minority class. This paper shows that a combination of our method of over-sampling the minority (abnormal) class and under-sampling the majority (normal) class can achieve better classifier performance (in ROC space) than only under-sampling the majority class. This paper also shows that a combination of our method of over-sampling the minority class and under-sampling the majority class can achieve better classifier performance (in ROC space) than varying the loss ratios in Ripper or class priors in Naive Bayes. Our method of over-sampling the minority class involves creating synthetic minority class examples. Experiments are performed using C4.5, Ripper and a Naive Bayes classifier. The method is evaluated using the area under the Receiver Operating Characteristic curve (AUC) and the ROC convex hull strategy.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence},
  file = {/home/domvwt/Zotero/storage/6W3CCC5S/Chawla et al. - 2002 - SMOTE Synthetic Minority Over-sampling Technique.pdf;/home/domvwt/Zotero/storage/WNT263SN/1106.html}
}

@inproceedings{chenXGBoostScalableTree2016,
  title = {{{XGBoost}}: {{A Scalable Tree Boosting System}}},
  shorttitle = {{{XGBoost}}},
  booktitle = {Proceedings of the 22nd {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  author = {Chen, Tianqi and Guestrin, Carlos},
  date = {2016-08-13},
  eprint = {1603.02754},
  eprinttype = {arxiv},
  primaryclass = {cs},
  pages = {785--794},
  doi = {10.1145/2939672.2939785},
  url = {http://arxiv.org/abs/1603.02754},
  urldate = {2022-06-13},
  abstract = {Tree boosting is a highly effective and widely used machine learning method. In this paper, we describe a scalable end-to-end tree boosting system called XGBoost, which is used widely by data scientists to achieve state-of-the-art results on many machine learning challenges. We propose a novel sparsity-aware algorithm for sparse data and weighted quantile sketch for approximate tree learning. More importantly, we provide insights on cache access patterns, data compression and sharding to build a scalable tree boosting system. By combining these insights, XGBoost scales beyond billions of examples using far fewer resources than existing systems.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning},
  file = {/home/domvwt/Zotero/storage/ZFQRFR7P/Chen and Guestrin - 2016 - XGBoost A Scalable Tree Boosting System.pdf;/home/domvwt/Zotero/storage/YP79A28Y/1603.html}
}

@online{CompaniesHouse2022a,
  title = {Companies {{House}}},
  date = {2022-06-12},
  url = {http://download.companieshouse.gov.uk/en_pscdata.html},
  urldate = {2022-06-12},
  file = {/home/domvwt/Zotero/storage/DWHDWVPW/en_pscdata.html}
}

@online{CompaniesHouseData,
  title = {Companies {{House}} Data Products},
  url = {https://www.gov.uk/guidance/companies-house-data-products},
  urldate = {2022-09-18},
  abstract = {How to access public data from the Companies House register using our data products.},
  langid = {english},
  organization = {{GOV.UK}},
  file = {/home/domvwt/Zotero/storage/GFJHY7IH/companies-house-data-products.html}
}

@online{CompaniesWeKeep2022,
  title = {The {{Companies We Keep}}},
  date = {2022-05-24},
  url = {https:///en/campaigns/corruption-and-money-laundering/anonymous-company-owners/companies-we-keep/},
  urldate = {2022-05-24},
  abstract = {What the UK's open data register actually tells us about company ownership},
  organization = {{Global Witness}},
  file = {/home/domvwt/Zotero/storage/MT2IM93I/companies-we-keep.html}
}

@online{DataKind2022,
  title = {{{DataKind}}},
  date = {2022-05-24},
  url = {https://www.datakind.org/blog/datakind.org},
  urldate = {2022-05-24},
  abstract = {Harnessing the power of data science + AI in the service of humanity},
  langid = {english},
  file = {/home/domvwt/Zotero/storage/5NBMJETQ/what-does-the-uk-beneficial-ownership-data-show-us.html}
}

@book{davisonBootstrapMethodsTheir1997,
  title = {Bootstrap {{Methods}} and Their {{Application}}},
  author = {Davison, A. C. and Hinkley, D. V.},
  date = {1997},
  series = {Cambridge {{Series}} in {{Statistical}} and {{Probabilistic Mathematics}}},
  publisher = {{Cambridge University Press}},
  location = {{Cambridge}},
  doi = {10.1017/CBO9780511802843},
  url = {https://www.cambridge.org/core/books/bootstrap-methods-and-their-application/ED2FD043579F27952363566DC09CBD6A},
  urldate = {2022-09-20},
  abstract = {Bootstrap methods are computer-intensive methods of statistical analysis, which use simulation to calculate standard errors, confidence intervals, and significance tests. The methods apply for any level of modelling, and so can be used for fully parametric, semiparametric, and completely nonparametric analysis. This 1997 book gives a broad and up-to-date coverage of bootstrap methods, with numerous applied examples, developed in a coherent way with the necessary theoretical basis. Applications include stratified data; finite populations; censored and missing data; linear, nonlinear, and smooth regression models; classification; time series and spatial problems. Special features of the book include: extensive discussion of significance tests and confidence intervals; material on various diagnostic methods; and methods for efficient computation, including improved Monte Carlo simulation. Each chapter includes both practical and theoretical exercises. S-Plus programs for implementing the methods described in the text are available from the supporting website.},
  isbn = {978-0-521-57471-6},
  file = {/home/domvwt/Zotero/storage/CHHRRBUU/ED2FD043579F27952363566DC09CBD6A.html}
}

@unpublished{defferrardConvolutionalNeuralNetworks2017,
  title = {Convolutional {{Neural Networks}} on {{Graphs}} with {{Fast Localized Spectral Filtering}}},
  author = {Defferrard, Michaël and Bresson, Xavier and Vandergheynst, Pierre},
  date = {2017-02-05},
  number = {arXiv:1606.09375},
  eprint = {1606.09375},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1606.09375},
  url = {http://arxiv.org/abs/1606.09375},
  urldate = {2022-06-13},
  abstract = {In this work, we are interested in generalizing convolutional neural networks (CNNs) from low-dimensional regular grids, where image, video and speech are represented, to high-dimensional irregular domains, such as social networks, brain connectomes or words' embedding, represented by graphs. We present a formulation of CNNs in the context of spectral graph theory, which provides the necessary mathematical background and efficient numerical schemes to design fast localized convolutional filters on graphs. Importantly, the proposed technique offers the same linear computational complexity and constant learning complexity as classical CNNs, while being universal to any graph structure. Experiments on MNIST and 20NEWS demonstrate the ability of this novel deep learning system to learn local, stationary, and compositional features on graphs.},
  archiveprefix = {arXiv},
  issue = {arXiv:1606.09375},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/domvwt/Zotero/storage/9I85V2TU/Defferrard et al. - 2017 - Convolutional Neural Networks on Graphs with Fast .pdf;/home/domvwt/Zotero/storage/7BU4NEF2/1606.html}
}

@incollection{dingDeepAnomalyDetection2019,
  title = {Deep {{Anomaly Detection}} on {{Attributed Networks}}},
  author = {Ding, Kaize and Li, Jundong and Bhanushali, Rohit and Liu, Huan},
  date = {2019-05-06},
  pages = {594--602},
  doi = {10.1137/1.9781611975673.67},
  isbn = {978-1-61197-567-3},
  file = {/home/domvwt/Zotero/storage/RCRB5A7S/Ding et al. - 2019 - Deep Anomaly Detection on Attributed Networks.pdf}
}

@inproceedings{duanAANEAnomalyAware2020,
  title = {{{AANE}}: {{Anomaly Aware Network Embedding}} for {{Anomalous Link Detection}}},
  shorttitle = {{{AANE}}},
  booktitle = {2020 {{IEEE International Conference}} on {{Data Mining}} ({{ICDM}})},
  author = {Duan, Dongsheng and Tong, Lingling and Li, Yangxi and Lu, Jie and Shi, Lei and Zhang, Cheng},
  date = {2020-11},
  pages = {1002--1007},
  issn = {2374-8486},
  doi = {10.1109/ICDM50108.2020.00116},
  abstract = {Existing network embedding models regard all the links in a network as normal and model them without distinction. In real networks, there may be anomalous links like noise or adversarial links. We explicitly consider the existence of anomalous links in a network and propose anomaly aware network embedding (AANE) model. The key of AANE is the design of a new loss, which consists of anomaly aware loss and adjusted fitting loss. We adopt an anomaly indicator to iteratively select significant anomalous links from the network during model training, and removal loss and deviation loss are designed to model the reconstruction errors of selected anomalous and normal links respectively. To instantiate AANE, AAGAE and AAGCN are implemented on graph auto-encoder (GAE) and graph convolution based auto-encoder (GCNAE) respectively. For the purpose of evaluation, a heuristic anomalous link generation algorithm is proposed and by using the algorithm we generate anomalous links into six real world network datasets. Experimental results show that AANE outperforms both basic and competitive network embedding models in terms of anomalous link detection performance in most cases.},
  eventtitle = {2020 {{IEEE International Conference}} on {{Data Mining}} ({{ICDM}})},
  keywords = {Anomaly Detection,Conferences,Convolution,Design methodology,Fitting,Graph Auto-Encoder,Heterogeneous networks,Heuristic algorithms,Network Embedding,Training},
  file = {/home/domvwt/Zotero/storage/NEL5ES3R/9338406.html}
}

@article{dumitrescuAnomalyDetectionGraphs2022,
  title = {Anomaly {{Detection}} in {{Graphs}} of {{Bank Transactions}} for {{Anti Money Laundering Applications}}},
  author = {Dumitrescu, Bogdan and Băltoiu, Andra and Budulan, Ştefania},
  date = {2022},
  journaltitle = {IEEE Access},
  volume = {10},
  pages = {47699--47714},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2022.3170467},
  abstract = {Our aim in this paper is to detect bank clients involved in suspicious activities related to money laundering, using the graph of transactions of the bank. Although we have a labeled real dataset, our target is not only to obtain relevant results on it, but also on random graphs in which typical anomaly patterns have been injected. So, we want simultaneously adequacy to the real data and robustness. Our method is based on designing new features; the most important are those resulting from the reduced egonet, which is the subgraph that remains from an egonet after eliminating the nodes connected with a single edge to the center; another feature is built by appealing to random walks and serves as indicator of circular flows. Our features are added to usual egonet features and a general anomaly detection algorithm, in our case Isolation Forest, serves to detect the anomalies. Experiments on the real data and a comprehensive set of synthetic data show that our approach is adequate, robust and better than some previous methods.},
  eventtitle = {{{IEEE Access}}},
  keywords = {Anomaly detection,bank transactions,egonet,Feature extraction,graphs,Licenses,Linear programming,Matrix decomposition,money laundering,random walk,Robustness,Task analysis},
  file = {/home/domvwt/Zotero/storage/SCKPAMSU/Dumitrescu et al. - 2022 - Anomaly Detection in Graphs of Bank Transactions f.pdf;/home/domvwt/Zotero/storage/49MG8D6N/9762926.html}
}

@inproceedings{duvenaudConvolutionalNetworksGraphs2015,
  title = {Convolutional {{Networks}} on {{Graphs}} for {{Learning Molecular Fingerprints}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Duvenaud, David K and Maclaurin, Dougal and Iparraguirre, Jorge and Bombarell, Rafael and Hirzel, Timothy and Aspuru-Guzik, Alan and Adams, Ryan P},
  date = {2015},
  volume = {28},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper/2015/hash/f9be311e65d81a9ad8150a60844bb94c-Abstract.html},
  urldate = {2022-06-13},
  abstract = {We introduce a convolutional neural network that operates directly on graphs.These networks allow end-to-end learning of prediction pipelines whose inputs are graphs of arbitrary size and shape.The architecture we present generalizes standard molecular feature extraction methods based on circular fingerprints.We show that these data-driven features are more interpretable, and have better predictive performance on a variety of tasks.},
  file = {/home/domvwt/Zotero/storage/T6S2EZHH/Duvenaud et al. - 2015 - Convolutional Networks on Graphs for Learning Mole.pdf}
}

@misc{EstimatingInternationalTax2019,
  title = {Estimating {{International Tax Evasion}} by {{Individuals}}},
  date = {2019-09},
  publisher = {{European Commission}},
  url = {https://ec.europa.eu/taxation_customs/system/files/2019-10/2019-taxation-papers-76.pdf},
  urldate = {2022-06-05},
  file = {/home/domvwt/Zotero/storage/VDYAFYCG/2019-taxation-papers-76.pdf}
}

@book{europeancommission.directorategeneralfortaxationandcustomsunion.EstimatingInternationalTax2019,
  title = {Estimating International Tax Evasion by Individuals.},
  author = {{European Commission. Directorate General for Taxation and Customs Union.}},
  date = {2019},
  publisher = {{Publications Office}},
  location = {{LU}},
  url = {https://data.europa.eu/doi/10.2778/300732},
  urldate = {2022-06-05},
  langid = {english},
  file = {/home/domvwt/Zotero/storage/R72GFIUB/2019-taxation-papers-76.pdf}
}

@book{europeanunionagencyforlawenforcementcooperationShadowMoneyInternational2021,
  title = {Shadow Money: The International Networks of Illicit Finance.},
  shorttitle = {Shadow Money},
  author = {{European Union Agency for Law Enforcement Cooperation}},
  date = {2021},
  url = {https://op.europa.eu/publication/manifestation_identifier/PUB_QLAN21003ENN},
  urldate = {2022-06-05},
  abstract = {The recent release of confidential information once more revealed the operations of vast international networks for illicit finance. They rely on offshore tax havens, complex webs of legal business structures and corruption to facilitate a variety of criminal activities including tax evasion, fraud and money laundering. The Pandora Papers is a leak of almost 12 million documents that expose hidden wealth, tax avoidance and money laundering by prominent individuals and politically exposed persons (PEPs). The Pandora Papers leak includes 6.4 million documents, almost three million images, more than a million emails and almost half-a-million spreadsheets. The international networks of illicit finance revealed by the Pandora Papers leak enable criminals to launder illicit proceeds, hide assets, engage in corruption and sustain a globalised criminal economy.},
  isbn = {978-92-95220-36-2},
  langid = {english},
  annotation = {OCLC: 1308399128},
  file = {/home/domvwt/Zotero/storage/DK4KZ8L9/Shadow money – the international networks of illicit finance_PUBLIC_0.pdf}
}

@misc{europolShadowMoneyInternational2022,
  title = {Shadow Money – the International Networks of Illicit Finance},
  author = {{Europol}},
  date = {2022-06-05},
  url = {https://www.europol.europa.eu/cms/sites/default/files/documents/Shadow%20money%20%E2%80%93%20the%20international%20networks%20of%20illicit%20finance_PUBLIC_0.pdf},
  urldate = {2022-06-05}
}

@article{fawcettIntroductionROCAnalysis2006,
  title = {An Introduction to {{ROC}} Analysis},
  author = {Fawcett, Tom},
  date = {2006-06-01},
  journaltitle = {Pattern Recognition Letters},
  shortjournal = {Pattern Recognition Letters},
  series = {{{ROC Analysis}} in {{Pattern Recognition}}},
  volume = {27},
  number = {8},
  pages = {861--874},
  issn = {0167-8655},
  doi = {10.1016/j.patrec.2005.10.010},
  url = {https://www.sciencedirect.com/science/article/pii/S016786550500303X},
  urldate = {2022-09-19},
  abstract = {Receiver operating characteristics (ROC) graphs are useful for organizing classifiers and visualizing their performance. ROC graphs are commonly used in medical decision making, and in recent years have been used increasingly in machine learning and data mining research. Although ROC graphs are apparently simple, there are some common misconceptions and pitfalls when using them in practice. The purpose of this article is to serve as an introduction to ROC graphs and as a guide for using them in research.},
  langid = {english},
  keywords = {Classifier evaluation,Evaluation metrics,ROC analysis},
  file = {/home/domvwt/Zotero/storage/IQ4AVIRM/Fawcett - 2006 - An introduction to ROC analysis.pdf;/home/domvwt/Zotero/storage/DBJZM53M/S016786550500303X.html}
}

@misc{ferludinTFGNNGraphNeural2022,
  title = {{{TF-GNN}}: {{Graph Neural Networks}} in {{TensorFlow}}},
  shorttitle = {{{TF-GNN}}},
  author = {Ferludin, Oleksandr and Eigenwillig, Arno and Blais, Martin and Zelle, Dustin and Pfeifer, Jan and Sanchez-Gonzalez, Alvaro and Li, Sibon and Abu-El-Haija, Sami and Battaglia, Peter and Bulut, Neslihan and Halcrow, Jonathan and de Almeida, Filipe Miguel Gonçalves and Lattanzi, Silvio and Linhares, André and Mayer, Brandon and Mirrokni, Vahab and Palowitch, John and Paradkar, Mihir and She, Jennifer and Tsitsulin, Anton and Villela, Kevin and Wang, Lisa and Wong, David and Perozzi, Bryan},
  options = {useprefix=true},
  date = {2022-07-07},
  number = {arXiv:2207.03522},
  eprint = {2207.03522},
  eprinttype = {arxiv},
  primaryclass = {physics, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2207.03522},
  url = {http://arxiv.org/abs/2207.03522},
  urldate = {2022-08-24},
  abstract = {TensorFlow GNN (TF-GNN) is a scalable library for Graph Neural Networks in TensorFlow. It is designed from the bottom up to support the kinds of rich heterogeneous graph data that occurs in today's information ecosystems. Many production models at Google use TF-GNN and it has been recently released as an open source project. In this paper, we describe the TF-GNN data model, its Keras modeling API, and relevant capabilities such as graph sampling, distributed training, and accelerator support.},
  archiveprefix = {arXiv},
  issue = {arXiv:2207.03522},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Computer Science - Social and Information Networks,Physics - Physics and Society,Statistics - Machine Learning},
  file = {/home/domvwt/Zotero/storage/DEW5VRPB/2207.html}
}

@book{fernandezLearningImbalancedData2018,
  title = {Learning from {{Imbalanced Data Sets}}},
  author = {Fernández},
  date = {2018-11-01},
  edition = {1st ed. 2018 edition},
  publisher = {{Springer}},
  location = {{New York, NY}},
  isbn = {978-3-319-98073-7},
  langid = {english},
  pagetotal = {396}
}

@misc{feyFastGraphRepresentation2019,
  title = {Fast {{Graph Representation Learning}} with {{PyTorch Geometric}}},
  author = {Fey, Matthias and Lenssen, Jan Eric},
  date = {2019-04-25},
  number = {arXiv:1903.02428},
  eprint = {1903.02428},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1903.02428},
  url = {http://arxiv.org/abs/1903.02428},
  urldate = {2022-09-19},
  abstract = {We introduce PyTorch Geometric, a library for deep learning on irregularly structured input data such as graphs, point clouds and manifolds, built upon PyTorch. In addition to general graph data structures and processing methods, it contains a variety of recently published methods from the domains of relational learning and 3D data processing. PyTorch Geometric achieves high data throughput by leveraging sparse GPU acceleration, by providing dedicated CUDA kernels and by introducing efficient mini-batch handling for input examples of different size. In this work, we present the library in detail and perform a comprehensive comparative study of the implemented methods in homogeneous evaluation scenarios.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/domvwt/Zotero/storage/BZIEWFPU/Fey and Lenssen - 2019 - Fast Graph Representation Learning with PyTorch Ge.pdf;/home/domvwt/Zotero/storage/U66CNXBX/1903.html}
}

@article{friedmanGreedyFunctionApproximation2001,
  title = {Greedy Function Approximation: A Gradient Boosting Machine},
  shorttitle = {Greedy Function Approximation},
  author = {Friedman, Jerome H.},
  date = {2001},
  journaltitle = {Annals of statistics},
  pages = {1189--1232},
  publisher = {{JSTOR}},
  file = {/home/domvwt/Zotero/storage/2UIA354H/Friedman - 2001 - Greedy function approximation a gradient boosting.pdf;/home/domvwt/Zotero/storage/GJILTNCB/2699986.html}
}

@article{fronzetticolladonUsingSocialNetwork2017,
  title = {Using Social Network Analysis to Prevent Money Laundering},
  author = {Fronzetti Colladon, Andrea and Remondi, Elisa},
  date = {2017-01-01},
  journaltitle = {Expert Systems with Applications},
  shortjournal = {Expert Systems with Applications},
  volume = {67},
  pages = {49--58},
  issn = {0957-4174},
  doi = {10.1016/j.eswa.2016.09.029},
  url = {https://www.sciencedirect.com/science/article/pii/S0957417416305139},
  urldate = {2022-06-13},
  abstract = {This research explores the opportunities for the application of network analytic techniques to prevent money laundering. We worked on real world data by analyzing the central database of a factoring company, mainly operating in Italy, over a period of 19 months. This database contained the financial operations linked to the factoring business, together with other useful information about the company clients. We propose a new approach to sort and map relational data and present predictive models – based on network metrics – to assess risk profiles of clients involved in the factoring business. We find that risk profiles can be predicted by using social network metrics. In our dataset, the most dangerous social actors deal with bigger or more frequent financial operations; they are more peripheral in the transactions network; they mediate transactions across different economic sectors and operate in riskier countries or Italian regions. Finally, to spot potential clusters of criminals, we propose a visual analysis of the tacit links existing among different companies who share the same owner or representative. Our findings show the importance of using a network-based approach when looking for suspicious financial operations and potential criminals.},
  langid = {english},
  keywords = {Anti-money laundering,Decision support systems,Factoring,Fraud detection,Social network},
  file = {/home/domvwt/Zotero/storage/7EHIPLSG/Fronzetti Colladon and Remondi - 2017 - Using social network analysis to prevent money lau.pdf;/home/domvwt/Zotero/storage/BHQHA9IQ/S0957417416305139.html}
}

@book{goriNewModelEarning2005,
  title = {A New Model for Earning in Raph Domains},
  author = {Gori, M. and Monfardini, Gabriele and Scarselli, Franco},
  date = {2005-01-01},
  journaltitle = {Proceedings of the International Joint Conference on Neural Networks},
  volume = {2},
  pages = {734 vol. 2},
  doi = {10.1109/IJCNN.2005.1555942},
  abstract = {In several applications the information is naturally represented by graphs. Traditional approaches cope with graphical data structures using a preprocessing phase which transforms the graphs into a set of flat vectors. However, in this way, important topological information may be lost and the achieved results may heavily depend on the preprocessing stage. This paper presents a new neural model, called graph neural network (GNN), capable of directly processing graphs. GNNs extends recursive neural networks and can be applied on most of the practically useful kinds of graphs, including directed, undirected, labelled and cyclic graphs. A learning algorithm for GNNs is proposed and some experiments are discussed which assess the properties of the model.},
  isbn = {978-0-7803-9048-5},
  pagetotal = {729}
}

@article{goyalGraphEmbeddingTechniques2018,
  title = {Graph {{Embedding Techniques}}, {{Applications}}, and {{Performance}}: {{A Survey}}},
  shorttitle = {Graph {{Embedding Techniques}}, {{Applications}}, and {{Performance}}},
  author = {Goyal, Palash and Ferrara, Emilio},
  date = {2018-07},
  journaltitle = {Knowledge-Based Systems},
  shortjournal = {Knowledge-Based Systems},
  volume = {151},
  eprint = {1705.02801},
  eprinttype = {arxiv},
  pages = {78--94},
  issn = {09507051},
  doi = {10.1016/j.knosys.2018.03.022},
  url = {http://arxiv.org/abs/1705.02801},
  urldate = {2022-05-11},
  abstract = {Graphs, such as social networks, word co-occurrence networks, and communication networks, occur naturally in various real-world applications. Analyzing them yields insight into the structure of society, language, and different patterns of communication. Many approaches have been proposed to perform the analysis. Recently, methods which use the representation of graph nodes in vector space have gained traction from the research community. In this survey, we provide a comprehensive and structured analysis of various graph embedding techniques proposed in the literature. We first introduce the embedding task and its challenges such as scalability, choice of dimensionality, and features to be preserved, and their possible solutions. We then present three categories of approaches based on factorization methods, random walks, and deep learning, with examples of representative algorithms in each category and analysis of their performance on various tasks. We evaluate these state-of-the-art methods on a few common datasets and compare their performance against one another. Our analysis concludes by suggesting some potential applications and future directions. We finally present the open-source Python library we developed, named GEM (Graph Embedding Methods, available at https://github.com/palash1992/GEM), which provides all presented algorithms within a unified interface to foster and facilitate research on the topic.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Computer Science - Social and Information Networks,Physics - Data Analysis; Statistics and Probability},
  file = {/home/domvwt/Zotero/storage/5DLAPX6I/Goyal and Ferrara - 2018 - Graph Embedding Techniques, Applications, and Perf.pdf}
}

@online{GraphNeuralNetworks2022,
  title = {Graph Neural Networks: {{A}} Review of Methods and Applications | {{Elsevier Enhanced Reader}}},
  date = {2022-09-02},
  url = {https://reader.elsevier.com/reader/sd/pii/S2666651021000012?token=461B92D75E40A2737971B84287528D26AC52C70F027F65D05E41E25146E09ADB80DD23F5DF013C1C9B3BC15E83C04DCD&originRegion=eu-west-1&originCreation=20220902095407},
  urldate = {2022-09-02},
  file = {/home/domvwt/Zotero/storage/LYE3KLB3/S2666651021000012.html}
}

@software{grattarolaWelcomeSpektral2022,
  title = {Welcome to {{Spektral}}},
  author = {Grattarola, Daniele},
  date = {2022-05-23T01:40:51Z},
  origdate = {2019-01-17T11:19:10Z},
  url = {https://github.com/danielegrattarola/spektral},
  urldate = {2022-05-24},
  abstract = {Graph Neural Networks with Keras and Tensorflow 2.},
  keywords = {deep-learning,graph-deep-learning,graph-neural-networks,keras,python,tensorflow,tensorflow2},
  annotation = {Programmers: \_:n67}
}

@article{grubbsProceduresDetectingOutlying1969,
  title = {Procedures for {{Detecting Outlying Observations}} in {{Samples}}},
  author = {Grubbs, Frank E.},
  date = {1969-02-01},
  journaltitle = {Technometrics},
  volume = {11},
  number = {1},
  pages = {1--21},
  publisher = {{Taylor \& Francis}},
  issn = {0040-1706},
  doi = {10.1080/00401706.1969.10490657},
  url = {https://www.tandfonline.com/doi/abs/10.1080/00401706.1969.10490657},
  urldate = {2022-06-12},
  abstract = {Procedures are given for determining statistically whether the highest observation, the lowest observation, the highest and lowest observations, the two highest observations, the two lowest observations, or more of the observations in the sample are statistical outliers. Both the statistical formulae and the application of the procedures to examples are given, thus representing a rather complete treatment of tests for outliers in single samples. This paper has been prepared primarily as an expository and tutorial article on the problem of detecting outlying observations in much experimental work. We cover only tests of significance in thii paper.},
  issue = {1},
  annotation = {\_eprint: https://www.tandfonline.com/doi/pdf/10.1080/00401706.1969.10490657},
  file = {/home/domvwt/Zotero/storage/7E4VA7T4/00401706.1969.html}
}

@misc{hamiltonInductiveRepresentationLearning2018,
  title = {Inductive {{Representation Learning}} on {{Large Graphs}}},
  author = {Hamilton, William L. and Ying, Rex and Leskovec, Jure},
  date = {2018-09-10},
  number = {arXiv:1706.02216},
  eprint = {1706.02216},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1706.02216},
  url = {http://arxiv.org/abs/1706.02216},
  urldate = {2022-09-19},
  abstract = {Low-dimensional embeddings of nodes in large graphs have proved extremely useful in a variety of prediction tasks, from content recommendation to identifying protein functions. However, most existing approaches require that all nodes in the graph are present during training of the embeddings; these previous approaches are inherently transductive and do not naturally generalize to unseen nodes. Here we present GraphSAGE, a general, inductive framework that leverages node feature information (e.g., text attributes) to efficiently generate node embeddings for previously unseen data. Instead of training individual embeddings for each node, we learn a function that generates embeddings by sampling and aggregating features from a node's local neighborhood. Our algorithm outperforms strong baselines on three inductive node-classification benchmarks: we classify the category of unseen nodes in evolving information graphs based on citation and Reddit post data, and we show that our algorithm generalizes to completely unseen graphs using a multi-graph dataset of protein-protein interactions.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Social and Information Networks,Statistics - Machine Learning},
  file = {/home/domvwt/Zotero/storage/M826LBVQ/Hamilton et al. - 2018 - Inductive Representation Learning on Large Graphs.pdf;/home/domvwt/Zotero/storage/E7JFSKVD/1706.html}
}

@article{heLearningImbalancedData2009,
  title = {Learning from {{Imbalanced Data}}},
  author = {He, Haibo and Garcia, Edwardo A.},
  date = {2009-09},
  journaltitle = {IEEE Transactions on Knowledge and Data Engineering},
  volume = {21},
  number = {9},
  pages = {1263--1284},
  issn = {1558-2191},
  doi = {10.1109/TKDE.2008.239},
  abstract = {With the continuous expansion of data availability in many large-scale, complex, and networked systems, such as surveillance, security, Internet, and finance, it becomes critical to advance the fundamental understanding of knowledge discovery and analysis from raw data to support decision-making processes. Although existing knowledge discovery and data engineering techniques have shown great success in many real-world applications, the problem of learning from imbalanced data (the imbalanced learning problem) is a relatively new challenge that has attracted growing attention from both academia and industry. The imbalanced learning problem is concerned with the performance of learning algorithms in the presence of underrepresented data and severe class distribution skews. Due to the inherent complex characteristics of imbalanced data sets, learning from such data requires new understandings, principles, algorithms, and tools to transform vast amounts of raw data efficiently into information and knowledge representation. In this paper, we provide a comprehensive review of the development of research in learning from imbalanced data. Our focus is to provide a critical review of the nature of the problem, the state-of-the-art technologies, and the current assessment metrics used to evaluate learning performance under the imbalanced learning scenario. Furthermore, in order to stimulate future research in this field, we also highlight the major opportunities and challenges, as well as potential important research directions for learning from imbalanced data.},
  eventtitle = {{{IEEE Transactions}} on {{Knowledge}} and {{Data Engineering}}},
  keywords = {active learning,assessment metrics.,Availability,classification,cost-sensitive learning,Data analysis,Data engineering,Data security,Decision making,Finance,Imbalanced learning,IP networks,kernel-based learning,Knowledge representation,Large-scale systems,sampling methods,Surveillance},
  file = {/home/domvwt/Zotero/storage/RYEA4D22/5128907.html}
}

@online{HeterogeneousGraphLearning,
  title = {Heterogeneous {{Graph Learning}} — {{PyTorch Geometric}} Documentation},
  url = {https://pytorch-geometric.readthedocs.io/en/latest/notes/heterogeneous.html},
  urldate = {2022-09-19},
  file = {/home/domvwt/Zotero/storage/RX5WVP9W/heterogeneous.html}
}

@misc{huHeterogeneousGraphTransformer2020,
  title = {Heterogeneous {{Graph Transformer}}},
  author = {Hu, Ziniu and Dong, Yuxiao and Wang, Kuansan and Sun, Yizhou},
  date = {2020-03-02},
  number = {arXiv:2003.01332},
  eprint = {2003.01332},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2003.01332},
  url = {http://arxiv.org/abs/2003.01332},
  urldate = {2022-09-20},
  abstract = {Recent years have witnessed the emerging success of graph neural networks (GNNs) for modeling structured data. However, most GNNs are designed for homogeneous graphs, in which all nodes and edges belong to the same types, making them infeasible to represent heterogeneous structures. In this paper, we present the Heterogeneous Graph Transformer (HGT) architecture for modeling Web-scale heterogeneous graphs. To model heterogeneity, we design node- and edge-type dependent parameters to characterize the heterogeneous attention over each edge, empowering HGT to maintain dedicated representations for different types of nodes and edges. To handle dynamic heterogeneous graphs, we introduce the relative temporal encoding technique into HGT, which is able to capture the dynamic structural dependency with arbitrary durations. To handle Web-scale graph data, we design the heterogeneous mini-batch graph sampling algorithm---HGSampling---for efficient and scalable training. Extensive experiments on the Open Academic Graph of 179 million nodes and 2 billion edges show that the proposed HGT model consistently outperforms all the state-of-the-art GNN baselines by 9\%--21\% on various downstream tasks.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Social and Information Networks,Statistics - Machine Learning},
  file = {/home/domvwt/Zotero/storage/B5RF4JEJ/Hu et al. - 2020 - Heterogeneous Graph Transformer.pdf;/home/domvwt/Zotero/storage/IR3XVZQD/2003.html}
}

@misc{huStrategiesPretrainingGraph2020,
  title = {Strategies for {{Pre-training Graph Neural Networks}}},
  author = {Hu, Weihua and Liu, Bowen and Gomes, Joseph and Zitnik, Marinka and Liang, Percy and Pande, Vijay and Leskovec, Jure},
  date = {2020-02-18},
  number = {arXiv:1905.12265},
  eprint = {1905.12265},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1905.12265},
  url = {http://arxiv.org/abs/1905.12265},
  urldate = {2022-09-17},
  abstract = {Many applications of machine learning require a model to make accurate pre-dictions on test examples that are distributionally different from training ones, while task-specific labels are scarce during training. An effective approach to this challenge is to pre-train a model on related tasks where data is abundant, and then fine-tune it on a downstream task of interest. While pre-training has been effective in many language and vision domains, it remains an open question how to effectively use pre-training on graph datasets. In this paper, we develop a new strategy and self-supervised methods for pre-training Graph Neural Networks (GNNs). The key to the success of our strategy is to pre-train an expressive GNN at the level of individual nodes as well as entire graphs so that the GNN can learn useful local and global representations simultaneously. We systematically study pre-training on multiple graph classification datasets. We find that naive strategies, which pre-train GNNs at the level of either entire graphs or individual nodes, give limited improvement and can even lead to negative transfer on many downstream tasks. In contrast, our strategy avoids negative transfer and improves generalization significantly across downstream tasks, leading up to 9.4\% absolute improvements in ROC-AUC over non-pre-trained models and achieving state-of-the-art performance for molecular property prediction and protein function prediction.},
  archiveprefix = {arXiv},
  issue = {arXiv:1905.12265},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/domvwt/Zotero/storage/HEJ22IRG/1905.html}
}

@online{icijOffshoreHavensHidden2021,
  title = {Offshore Havens and Hidden Riches of World Leaders and Billionaires Exposed in Unprecedented Leak - {{ICIJ}}},
  author = {{ICIJ}},
  date = {2021-10-03T12:26:00-04:00},
  url = {https://www.icij.org/investigations/pandora-papers/global-investigation-tax-havens-offshore/},
  urldate = {2022-06-04},
  abstract = {The Pandora Papers reveal the inner workings of a shadow economy that benefits the wealthy and well-connected at the expense of everyone else.},
  langid = {american},
  file = {/home/domvwt/Zotero/storage/7NV32V77/global-investigation-tax-havens-offshore.html}
}

@online{IgraphNetworkAnalysis2022,
  title = {Igraph – {{Network}} Analysis Software},
  date = {2022-05-24},
  url = {https://igraph.org/},
  urldate = {2022-05-24},
  file = {/home/domvwt/Zotero/storage/NVWNB3UD/igraph.org.html}
}

@online{KeepingYourPeople2016,
  title = {Keeping Your People with Significant Control ({{PSC}}) Register},
  date = {2016-04-06},
  url = {https://www.gov.uk/government/news/keeping-your-people-with-significant-control-psc-register},
  urldate = {2022-06-12},
  abstract = {From 6 April 2016 companies, LLPs and SEs need to keep a register of their 'people with significant control'.},
  langid = {english},
  organization = {{GOV.UK}},
  file = {/home/domvwt/Zotero/storage/46XWZ6CM/keeping-your-people-with-significant-control-psc-register.html}
}

@misc{kingmaAdamMethodStochastic2017,
  title = {Adam: {{A Method}} for {{Stochastic Optimization}}},
  shorttitle = {Adam},
  author = {Kingma, Diederik P. and Ba, Jimmy},
  date = {2017-01-29},
  number = {arXiv:1412.6980},
  eprint = {1412.6980},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1412.6980},
  url = {http://arxiv.org/abs/1412.6980},
  urldate = {2022-09-19},
  abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning},
  file = {/home/domvwt/Zotero/storage/HIXAZFSX/Kingma and Ba - 2017 - Adam A Method for Stochastic Optimization.pdf;/home/domvwt/Zotero/storage/HS56PCEK/1412.html}
}

@unpublished{kipfSemiSupervisedClassificationGraph2017,
  title = {Semi-{{Supervised Classification}} with {{Graph Convolutional Networks}}},
  author = {Kipf, Thomas N. and Welling, Max},
  date = {2017-02-22},
  number = {arXiv:1609.02907},
  eprint = {1609.02907},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1609.02907},
  url = {http://arxiv.org/abs/1609.02907},
  urldate = {2022-06-13},
  abstract = {We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.},
  archiveprefix = {arXiv},
  issue = {arXiv:1609.02907},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/domvwt/Zotero/storage/4LD3AZPR/Kipf and Welling - 2017 - Semi-Supervised Classification with Graph Convolut.pdf;/home/domvwt/Zotero/storage/LLXCFDNU/1609.html}
}

@misc{kipfSemiSupervisedClassificationGraph2017a,
  title = {Semi-{{Supervised Classification}} with {{Graph Convolutional Networks}}},
  author = {Kipf, Thomas N. and Welling, Max},
  date = {2017-02-22},
  number = {arXiv:1609.02907},
  eprint = {1609.02907},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1609.02907},
  url = {http://arxiv.org/abs/1609.02907},
  urldate = {2022-09-19},
  abstract = {We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/domvwt/Zotero/storage/QQCAKQSF/Kipf and Welling - 2017 - Semi-Supervised Classification with Graph Convolut.pdf;/home/domvwt/Zotero/storage/BUZRU6IL/1609.html}
}

@online{LearningImbalancedData,
  title = {Learning from {{Imbalanced Data Sets}}: {{Amazon}}.Co.Uk: {{Fernández}}, {{Alberto}}, {{García}}, {{Salvador}}, {{Galar}}, {{Mikel}}, {{Prati}}, {{Ronaldo C}}., {{Krawczyk}}, {{Bartosz}}, {{Herrera}}, {{Francisco}}: 9783319980737: {{Books}}},
  url = {https://www.amazon.co.uk/Learning-Imbalanced-Data-Alberto-Fern%C3%A1ndez/dp/3319980734},
  urldate = {2022-09-19},
  file = {/home/domvwt/Zotero/storage/W8U5ATRU/3319980734.html}
}

@article{legorrecLearningNetworkEmbeddings2021,
  title = {Learning Network Embeddings Using Small Graphlets},
  author = {le Gorrec, Luce and Knight, Philip A. and Caen, Auguste},
  options = {useprefix=true},
  date = {2021-12-15},
  journaltitle = {Social Network Analysis and Mining},
  shortjournal = {Soc. Netw. Anal. Min.},
  volume = {12},
  number = {1},
  pages = {20},
  issn = {1869-5469},
  doi = {10.1007/s13278-021-00846-9},
  url = {https://doi.org/10.1007/s13278-021-00846-9},
  urldate = {2022-09-18},
  abstract = {Techniques for learning vectorial representations of graphs (graph embeddings) have recently emerged as an effective approach to facilitate machine learning on graphs. Some of the most popular methods involve sophisticated features such as graph kernels or convolutional networks. In this work, we introduce two straightforward supervised learning algorithms based on small-size graphlet counts, combined with a dimension reduction step. The first relies on a classic feature extraction method powered by principal component analysis (PCA). The second is a feature selection procedure also based on PCA. Despite their conceptual simplicity, these embeddings are arguably more meaningful than some popular alternatives and at the same time are competitive with state-of-the-art methods. We illustrate this second point on a downstream classification task. We then use our algorithms in a novel setting, namely to conduct an analysis of author relationships in Wikipedia articles, for which we present an original dataset. Finally, we provide empirical evidence suggesting that our methods could also be adapted to unsupervised learning algorithms.},
  issue = {1},
  langid = {english},
  keywords = {Complex networks,Graph classification,Graph embeddings,Graphlets}
}

@unpublished{leskovecTraditionalMethodsMachine2020,
  title = {Traditional {{Methods}} for {{Machine Learning}} in {{Graphs}}},
  author = {Leskovec, Jure},
  date = {2020},
  location = {{Stanford University}},
  url = {http://snap.stanford.edu/class/cs224w-2020/slides/02-tradition-ml.pdf},
  urldate = {2022-09-18},
  abstract = {Machine Learning with Graphs},
  howpublished = {Lecture}
}

@unpublished{liGatedGraphSequence2017,
  title = {Gated {{Graph Sequence Neural Networks}}},
  author = {Li, Yujia and Tarlow, Daniel and Brockschmidt, Marc and Zemel, Richard},
  date = {2017-09-22},
  number = {arXiv:1511.05493},
  eprint = {1511.05493},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1511.05493},
  url = {http://arxiv.org/abs/1511.05493},
  urldate = {2022-06-13},
  abstract = {Graph-structured data appears frequently in domains including chemistry, natural language semantics, social networks, and knowledge bases. In this work, we study feature learning techniques for graph-structured inputs. Our starting point is previous work on Graph Neural Networks (Scarselli et al., 2009), which we modify to use gated recurrent units and modern optimization techniques and then extend to output sequences. The result is a flexible and broadly useful class of neural network models that has favorable inductive biases relative to purely sequence-based models (e.g., LSTMs) when the problem is graph-structured. We demonstrate the capabilities on some simple AI (bAbI) and graph algorithm learning tasks. We then show it achieves state-of-the-art performance on a problem from program verification, in which subgraphs need to be matched to abstract data structures.},
  archiveprefix = {arXiv},
  issue = {arXiv:1511.05493},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  file = {/home/domvwt/Zotero/storage/CH23BIB4/Li et al. - 2017 - Gated Graph Sequence Neural Networks.pdf;/home/domvwt/Zotero/storage/H8D3BAHZ/1511.html}
}

@online{liInferenceHeterogeneousNetworks2018,
  title = {Inference in Heterogeneous Networks},
  author = {Li, Yuan},
  date = {2018-01-01},
  abstract = {Last two decades have seen a surge of interests in approaches that leverage network structure in machine learning models. For many networks, not only the connections of the network but also the network attributes, such as node attributes and dyadic attributes, are observed. This heterogeneity in networks raises new challenges for the inference problem in networks. This dissertation discusses how to handle the heterogeneous networks for different ma- chine learning applications, namely community detection, node classification, and node representation learning. For community detection in network with node attributes, we introduce a mathematical approach that combines topology information and nodes at- tributes. The algorithm explores the correlation between node attributes and community assignment, and uses the diversity of dyadic attributes induced by different types of nodes to improve performance as well. We also study node classification problem in a transaction network, where rich information of node and edge is available, within Markov random field framework. We present a novel algorithm that automatically learns node prior and edge potential in the Markov random field, hence results in better classification. Finally, we generalize deepwalk to incorporate the dyadic attributes in network representation learning by biasing the random walk sampling procedure in deepwalk. The algorithm learns the sampling weights in a data driven manner and constructs a proper proximity measure based on the dyadic attributes.},
  keywords = {Statistics},
  file = {/home/domvwt/Zotero/storage/V4Z5BWYP/td96k2674.html}
}

@unpublished{liSpecAESpectralAutoEncoder2019,
  title = {{{SpecAE}}: {{Spectral AutoEncoder}} for {{Anomaly Detection}} in {{Attributed Networks}}},
  shorttitle = {{{SpecAE}}},
  author = {Li, Yuening and Huang, Xiao and Li, Jundong and Du, Mengnan and Zou, Na},
  date = {2019-10-09},
  number = {arXiv:1908.03849},
  eprint = {1908.03849},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1908.03849},
  url = {http://arxiv.org/abs/1908.03849},
  urldate = {2022-06-13},
  abstract = {Anomaly detection aims to distinguish observations that are rare and different from the majority. While most existing algorithms assume that instances are i.i.d., in many practical scenarios, links describing instance-to-instance dependencies and interactions are available. Such systems are called attributed networks. Anomaly detection in attributed networks has various applications such as monitoring suspicious accounts in social media and financial fraud in transaction networks. However, it remains a challenging task since the definition of anomaly becomes more complicated and topological structures are heterogeneous with nodal attributes. In this paper, we propose a spectral convolution and deconvolution based framework -- SpecAE, to project the attributed network into a tailored space to detect global and community anomalies. SpecAE leverages Laplacian sharpening to amplify the distances between representations of anomalies and the ones of the majority. The learned representations along with reconstruction errors are combined with a density estimation model to perform the detection. They are trained jointly as an end-to-end framework. Experiments on real-world datasets demonstrate the effectiveness of SpecAE.},
  archiveprefix = {arXiv},
  issue = {arXiv:1908.03849},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/domvwt/Zotero/storage/MEA8Z6YT/Li et al. - 2019 - SpecAE Spectral AutoEncoder for Anomaly Detection.pdf;/home/domvwt/Zotero/storage/S76URILE/1908.html}
}

@inproceedings{lunaFindingShellCompany2018,
  title = {Finding Shell Company Accounts Using Anomaly Detection},
  booktitle = {Proceedings of the {{ACM India Joint International Conference}} on {{Data Science}} and {{Management}} of {{Data}}},
  author = {Luna, Devendra Kumar and Palshikar, Girish Keshav and Apte, Manoj and Bhattacharya, Arnab},
  date = {2018-01-11},
  series = {{{CoDS-COMAD}} '18},
  pages = {167--174},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/3152494.3152519},
  url = {https://doi.org/10.1145/3152494.3152519},
  urldate = {2022-06-12},
  abstract = {Money laundering refers to activities pertaining to hiding the true income, evading taxes, or converting illegally earned money for normal use. These activities are often performed through shell companies that masquerade as real companies but where actual the purpose is to launder money. Shell companies are used in all the three phases of money laundering, namely, placement, layering, and integration, often simultaneously. In this paper, we aim to identify shell companies. We propose to use only bank transactions since that is easily available. In particular, we look at all incoming and outgoing transactions from a particular bank account along with its various attributes, and use anomaly detection techniques to identify the accounts that pertain to shell companies. Our aim is to create an initial list of potential shell company candidates which can be investigated by financial experts later. Due to lack of real data, we propose a banking transactions simulator (BTS) to simulate both honest as well as shell company transactions by studying a host of actual real-world fraud cases. We apply anomaly detection algorithms to detect candidate shell companies. Results indicate that we are able to identify the shell companies with a high degree of precision and recall.1},
  isbn = {978-1-4503-6341-9},
  keywords = {bank transaction simulation,money laundering,shell companies},
  file = {/home/domvwt/Zotero/storage/9UEPDNJ2/Luna et al. - 2018 - Finding shell company accounts using anomaly detec.pdf}
}

@unpublished{maComprehensiveSurveyGraph2021,
  title = {A {{Comprehensive Survey}} on {{Graph Anomaly Detection}} with {{Deep Learning}}},
  author = {Ma, Xiaoxiao and Wu, Jia and Xue, Shan and Yang, Jian and Zhou, Chuan and Sheng, Quan Z. and Xiong, Hui and Akoglu, Leman},
  date = {2021-10-11},
  eprint = {2106.07178},
  eprinttype = {arxiv},
  primaryclass = {cs},
  url = {http://arxiv.org/abs/2106.07178},
  urldate = {2022-04-20},
  abstract = {Anomalies represent rare observations (e.g., data records or events) that deviate significantly from others. Over several decades, research on anomaly mining has received increasing interests due to the implications of these occurrences in a wide range of disciplines. Anomaly detection, which aims to identify rare observations, is among the most vital tasks in the world, and has shown its power in preventing detrimental events, such as financial fraud, network intrusion, and social spam. The detection task is typically solved by identifying outlying data points in the feature space and inherently overlooks the relational information in real-world data. Graphs have been prevalently used to represent the structural information, which raises the graph anomaly detection problem - identifying anomalous graph objects (i.e., nodes, edges and sub-graphs) in a single graph, or anomalous graphs in a database/set of graphs. However, conventional anomaly detection techniques cannot tackle this problem well because of the complexity of graph data. For the advent of deep learning, graph anomaly detection with deep learning has received a growing attention recently. In this survey, we aim to provide a systematic and comprehensive review of the contemporary deep learning techniques for graph anomaly detection. We compile open-sourced implementations, public datasets, and commonly-used evaluation metrics to provide affluent resources for future studies. More importantly, we highlight twelve extensive future research directions according to our survey results covering unsolved and emerging research problems and real-world applications. With this survey, our goal is to create a "one-stop-shop" that provides a unified understanding of the problem categories and existing approaches, publicly available hands-on resources, and high-impact open challenges for graph anomaly detection using deep learning.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning},
  file = {/home/domvwt/Zotero/storage/R9D9L5EC/Ma et al. - 2021 - A Comprehensive Survey on Graph Anomaly Detection .pdf;/home/domvwt/Zotero/storage/MTIZ4LQI/2106.html}
}

@book{maImbalancedLearningFoundations2013,
  title = {Imbalanced {{Learning}}: {{Foundations}}, {{Algorithms}}, and {{Applications}}},
  shorttitle = {Imbalanced {{Learning}}},
  editor = {Ma, Yunqian and He, Haibo},
  date = {2013-07-01},
  edition = {1st edition},
  publisher = {{Wiley-IEEE Press}},
  location = {{Hoboken, New Jersey}},
  isbn = {978-1-118-07462-6},
  langid = {english},
  pagetotal = {216}
}

@article{mccallumAutomatingConstructionInternet2000,
  title = {Automating the {{Construction}} of {{Internet Portals}} with {{Machine Learning}}},
  author = {McCallum, Andrew Kachites and Nigam, Kamal and Rennie, Jason and Seymore, Kristie},
  date = {2000-07-01},
  journaltitle = {Information Retrieval},
  shortjournal = {Information Retrieval},
  volume = {3},
  number = {2},
  pages = {127--163},
  issn = {1573-7659},
  doi = {10.1023/A:1009953814988},
  url = {https://doi.org/10.1023/A:1009953814988},
  urldate = {2022-09-20},
  abstract = {Domain-specific internet portals are growing in popularity because they gather content from the Web and organize it for easy access, retrieval and search. For example, www.campsearch.com allows complex queries by age, location, cost and specialty over summer camps. This functionality is not possible with general, Web-wide search engines. Unfortunately these portals are difficult and time-consuming to maintain. This paper advocates the use of machine learning techniques to greatly automate the creation and maintenance of domain-specific Internet portals. We describe new research in reinforcement learning, information extraction and text classification that enables efficient spidering, the identification of informative text segments, and the population of topic hierarchies. Using these techniques, we have built a demonstration system: a portal for computer science research papers. It already contains over 50,000 papers and is publicly available at www.cora.justresearch.com. These techniques are widely applicable to portal creation in other domains.},
  langid = {english},
  keywords = {crawling,expectation-maximization,hidden Markov models,information extraction,naive Bayes,reinforcement learning,spidering,text classification,unlabeled data}
}

@inproceedings{molloyGraphAnalyticsRealtime2016,
  title = {Graph {{Analytics}} for {{Real-time Scoring}} of {{Cross-channel Transactional Fraud}}},
  author = {Molloy, Ian and Chari, Suresh and Finkler, Ulrich and Wiggerman, Mark and Jonker, Coen and Habeck, Ted and Park, Youngja and Jordens, Frank and Schaik, Ron},
  date = {2016-02-22},
  abstract = {We present a new approach to cross channel fraud detection: build graphs representing transactions from all channels and use analyt-ics on features extracted from these graphs. Our underlying hypothesis is community based fraud detection: an account (holder) performs normal or trusted transactions within a community that is " local " to the account. We explore several notions of community based on graph properties. Our results show that properties such as shortest distance between transaction endpoints, whether they are in the same strongly connected component, whether the destination has high page rank, etc., provide excellent discriminators of fraudulent and normal transactions whereas traditional social network analysis yields poor results. Evaluation on a large dataset from a European bank shows that such methods can substantially reduce false positives in traditional fraud scoring. We show that classifiers built purely out of graph properties are very promising, with high AUC, and can complement existing fraud detection approaches.},
  file = {/home/domvwt/Zotero/storage/6LFQRF6R/Molloy et al. - 2016 - Graph Analytics for Real-time Scoring of Cross-cha.pdf}
}

@misc{morrisWeisfeilerLemanGo2021,
  title = {Weisfeiler and {{Leman Go Neural}}: {{Higher-order Graph Neural Networks}}},
  shorttitle = {Weisfeiler and {{Leman Go Neural}}},
  author = {Morris, Christopher and Ritzert, Martin and Fey, Matthias and Hamilton, William L. and Lenssen, Jan Eric and Rattan, Gaurav and Grohe, Martin},
  date = {2021-11-30},
  number = {arXiv:1810.02244},
  eprint = {1810.02244},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1810.02244},
  url = {http://arxiv.org/abs/1810.02244},
  urldate = {2022-09-19},
  abstract = {In recent years, graph neural networks (GNNs) have emerged as a powerful neural architecture to learn vector representations of nodes and graphs in a supervised, end-to-end fashion. Up to now, GNNs have only been evaluated empirically -- showing promising results. The following work investigates GNNs from a theoretical point of view and relates them to the \$1\$-dimensional Weisfeiler-Leman graph isomorphism heuristic (\$1\$-WL). We show that GNNs have the same expressiveness as the \$1\$-WL in terms of distinguishing non-isomorphic (sub-)graphs. Hence, both algorithms also have the same shortcomings. Based on this, we propose a generalization of GNNs, so-called \$k\$-dimensional GNNs (\$k\$-GNNs), which can take higher-order graph structures at multiple scales into account. These higher-order structures play an essential role in the characterization of social networks and molecule graphs. Our experimental evaluation confirms our theoretical findings as well as confirms that higher-order information is useful in the task of graph classification and regression.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  file = {/home/domvwt/Zotero/storage/TSALZHM8/Morris et al. - 2021 - Weisfeiler and Leman Go Neural Higher-order Graph.pdf;/home/domvwt/Zotero/storage/2G6SC4MX/1810.html}
}

@online{OpenCorporatesOpenDatabase2022,
  title = {{{OpenCorporates}} :: {{The Open Database Of The Corporate World}}},
  date = {2022-05-24},
  url = {https://opencorporates.com/},
  urldate = {2022-05-24},
  file = {/home/domvwt/Zotero/storage/6CPWKHGP/opencorporates.com.html}
}

@online{OpenOwnership2022,
  title = {Open {{Ownership}}},
  date = {2022-05-24},
  url = {https://www.openownership.org/en/},
  urldate = {2022-05-24},
  abstract = {Open Ownership provides support and guidance on all aspects of beneficial ownership transparency reforms as we believe revealing the true owners of companies is an essential part of a well-functioning economy and society},
  langid = {english},
  organization = {{openownership.org}},
  file = {/home/domvwt/Zotero/storage/G3FIVPF3/en.html}
}

@online{OrganizedCrimeCorruption2022,
  title = {Organized {{Crime}} and {{Corruption Reporting Project}} - {{OCCRP}}},
  date = {2022-05-24},
  url = {https://www.occrp.org/en},
  urldate = {2022-05-24},
  file = {/home/domvwt/Zotero/storage/ECQYCGKA/en.html}
}

@online{OverviewGraphFramesDocumentation2022,
  title = {Overview - {{GraphFrames}} 0.8.0 {{Documentation}}},
  date = {2022-06-13},
  url = {https://graphframes.github.io/graphframes/docs/_site/index.html},
  urldate = {2022-06-13},
  file = {/home/domvwt/Zotero/storage/SP7I5EYV/index.html}
}

@misc{pagePageRankCitationRanking1998,
  title = {The {{PageRank Citation Ranking}}: {{Bringing Order}} to the {{Web}}},
  shorttitle = {The {{PageRank Citation Ranking}}},
  author = {Page, Larry and Brin, Sergey and Motwani, R. and Winograd, T.},
  date = {1998},
  abstract = {The importance of a Web page is an inherently subjective matter, which depends on the readers interests, knowledge and attitudes. But there is still much that can be said objectively about the relative importance of Web pages. This paper describes PageRank, a method for rating Web pages objectively and mechanically, efectively measuring the human interest and attention devoted to them. We compare PageRank to an idealized random Web surfer. We show how to efficiently compute PageRank for large numbers of pages. And, we show how to apply PageRank to search and to user navigation.},
  file = {/home/domvwt/Zotero/storage/Y5VE8W5D/Page et al. - 1998 - The PageRank Citation Ranking Bringing Order to t.pdf;/home/domvwt/Zotero/storage/WA3IEAE6/summary.html}
}

@article{pancinoGNNkerasKerasbasedLibrary2022,
  title = {{{GNNkeras}}: {{A Keras-based}} Library for {{Graph Neural Networks}} and Homogeneous and Heterogeneous Graph Processing},
  shorttitle = {{{GNNkeras}}},
  author = {Pancino, Niccolò and Bongini, Pietro and Scarselli, Franco and Bianchini, Monica},
  date = {2022-06-01},
  journaltitle = {SoftwareX},
  shortjournal = {SoftwareX},
  volume = {18},
  pages = {101061},
  issn = {2352-7110},
  doi = {10.1016/j.softx.2022.101061},
  url = {https://www.sciencedirect.com/science/article/pii/S2352711022000486},
  urldate = {2022-08-24},
  abstract = {In several areas of science and engineering, data can be naturally represented in graph form, where nodes denote entities and edges stand for relationships between them. Graph Neural Networks (GNNs) are a well-known class of machine learning models for graph processing. In this paper, we present GNNkeras, a library, based on Keras, which allows the implementation of a large subclass of GNNs. GNNkeras is a flexible tool: the implemented models can be used to classify/cluster nodes, edges, or whole graphs. Moreover, GNNkeras can be applied to both homogeneous and heterogeneous graphs, exploiting both inductive and mixed inductive–transductive learning, and can implement a layered version of GNNs, namely the LGNN model.},
  langid = {english},
  keywords = {Graph Neural Networks,Graphs,Keras,Machine Learning,TensorFlow},
  file = {/home/domvwt/Zotero/storage/VT237376/S2352711022000486.html}
}

@article{pangDeepLearningAnomaly2021,
  title = {Deep {{Learning}} for {{Anomaly Detection}}: {{A Review}}},
  shorttitle = {Deep {{Learning}} for {{Anomaly Detection}}},
  author = {Pang, Guansong and Shen, Chunhua and Cao, Longbing and Hengel, Anton Van Den},
  date = {2021-03-05},
  journaltitle = {ACM Computing Surveys},
  shortjournal = {ACM Comput. Surv.},
  volume = {54},
  number = {2},
  pages = {38:1--38:38},
  issn = {0360-0300},
  doi = {10.1145/3439950},
  url = {https://doi.org/10.1145/3439950},
  urldate = {2022-06-12},
  abstract = {Anomaly detection, a.k.a. outlier detection or novelty detection, has been a lasting yet active research area in various research communities for several decades. There are still some unique problem complexities and challenges that require advanced approaches. In recent years, deep learning enabled anomaly detection, i.e., deep anomaly detection, has emerged as a critical direction. This article surveys the research of deep anomaly detection with a comprehensive taxonomy, covering advancements in 3 high-level categories and 11 fine-grained categories of the methods. We review their key intuitions, objective functions, underlying assumptions, advantages, and disadvantages and discuss how they address the aforementioned challenges. We further discuss a set of possible future opportunities and new perspectives on addressing the challenges.},
  issue = {2},
  keywords = {Anomaly detection,deep learning,novelty detection,one-class classification,outlier detection},
  file = {/home/domvwt/Zotero/storage/AA3AS9IQ/Pang et al. - 2021 - Deep Learning for Anomaly Detection A Review.pdf}
}

@online{panlogicMoneyLaunderingIllicit2022,
  title = {Money Laundering and Illicit Finance},
  author = {{Panlogic}},
  date = {2022-06-04},
  url = {https://www.nationalcrimeagency.gov.uk/what-we-do/crime-threats/money-laundering-and-illicit-finance},
  urldate = {2022-06-04},
  abstract = {The threat from money laundering Money laundering has the potential to threaten the UK’s national security, national ...},
  langid = {british},
  file = {/home/domvwt/Zotero/storage/YBIJVBE5/money-laundering-and-illicit-finance.html}
}

@article{pedregosaScikitlearnMachineLearning2011,
  title = {Scikit-Learn: {{Machine Learning}} in {{Python}}},
  shorttitle = {Scikit-Learn},
  author = {Pedregosa, Fabian and Varoquaux, Gaël and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David and Brucher, Matthieu and Perrot, Matthieu and Duchesnay, Édouard},
  date = {2011},
  journaltitle = {Journal of Machine Learning Research},
  volume = {12},
  number = {85},
  pages = {2825--2830},
  issn = {1533-7928},
  url = {http://jmlr.org/papers/v12/pedregosa11a.html},
  urldate = {2022-09-20},
  abstract = {Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net.},
  file = {/home/domvwt/Zotero/storage/VUIIHGBF/Pedregosa et al. - 2011 - Scikit-learn Machine Learning in Python.pdf}
}

@article{pengDeepMultiViewFramework2022,
  title = {A {{Deep Multi-View Framework}} for {{Anomaly Detection}} on {{Attributed Networks}}},
  author = {Peng, Zhen and Luo, Minnan and Li, Jundong and Xue, Luguo and Zheng, Qinghua},
  date = {2022-06},
  journaltitle = {IEEE Transactions on Knowledge and Data Engineering},
  volume = {34},
  number = {6},
  pages = {2539--2552},
  issn = {1558-2191},
  doi = {10.1109/TKDE.2020.3015098},
  abstract = {The explosion of modeling complex systems using attributed networks boosts the research on anomaly detection in such networks, which can be applied in various high-impact domains. Many existing attempts, however, do not seriously tackle the inherent multi-view property in attribute space but concatenate multiple views into a single feature vector, which inevitably ignores the incompatibility between heterogeneous views caused by their own statistical properties. Actually, the distinct but complementary information brought by multi-view data promises the potential for more effective anomaly detection than the efforts only based on single-view data. Furthermore, the abnormal patterns naturally behave diversely in different views, which coincides with people’s desire to discover specific abnormality according to their preferences for views (attributes). Most existing methods cannot adapt to people’s requirements as they fail to consider the idiosyncrasy of user preferences. Therefore, we propose a multi-view framework \textsc{Alarm} to incorporate user preferences into anomaly detection and simultaneously tackle heterogeneous attribute characteristics through multiple graph encoders and a well-designed aggregator that supports self-learning and user-guided learning. Experiments on synthetic and real-world datasets, e.g., Disney, Books, and Enron, corroborate the improvement of \textsc{Alarm} in detection accuracy evaluated by the AUC metric and its effectiveness in supporting user-oriented anomaly detection.},
  eventtitle = {{{IEEE Transactions}} on {{Knowledge}} and {{Data Engineering}}},
  issue = {6},
  keywords = {Anomaly detection,attributed networks,Electronic mail,Explosions,Feature extraction,graph convolutional networks,Machine learning,Social network services,unsupervised learning},
  file = {/home/domvwt/Zotero/storage/SFJ4U7C4/9162509.html}
}

@online{PeopleSignificantControl2022,
  title = {People with Significant Control ({{PSCs}})},
  date = {2022-09-18},
  url = {https://www.gov.uk/guidance/people-with-significant-control-pscs},
  urldate = {2022-09-18},
  abstract = {How to identify and record the people who own or control your company.},
  langid = {english},
  organization = {{GOV.UK}},
  file = {/home/domvwt/Zotero/storage/Z6K9TKEG/people-with-significant-control-pscs.html}
}

@article{pourhabibiFraudDetectionSystematic2020,
  title = {Fraud Detection: {{A}} Systematic Literature Review of Graph-Based Anomaly Detection Approaches},
  shorttitle = {Fraud Detection},
  author = {Pourhabibi, Tahereh and Ong, Kok-Leong and Kam, Booi H. and Boo, Yee Ling},
  date = {2020-06-01},
  journaltitle = {Decision Support Systems},
  shortjournal = {Decision Support Systems},
  volume = {133},
  pages = {113303},
  issn = {0167-9236},
  doi = {10.1016/j.dss.2020.113303},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0167923620300580},
  urldate = {2022-06-12},
  abstract = {Graph-based anomaly detection (GBAD) approaches are among the most popular techniques used to analyze connectivity patterns in communication networks and identify suspicious behaviors. Given the different GBAD approaches proposed for fraud detection, in this study, we develop a framework to synthesize the existing literature on the application of GBAD methods in fraud detection published between 2007 and 2018. This study aims to investigate the present trends and identify the key challenges that require significant research efforts to increase the credibility of the technique. Additionally, we provide some recommendations to deal with these challenges.},
  langid = {english},
  keywords = {Big data analytics,Fraud detection,Graph data,Graph-based anomaly detection,Social network,Systematic literature review},
  file = {/home/domvwt/Zotero/storage/VIYPXMJ2/Pourhabibi et al. - 2020 - Fraud detection A systematic literature review of.pdf;/home/domvwt/Zotero/storage/SHCPX358/S0167923620300580.html}
}

@online{ProceedingsPythonScience2022,
  title = {Proceedings of the {{Python}} in {{Science Conference}} ({{SciPy}}): {{Exploring Network Structure}}, {{Dynamics}}, and {{Function}} Using {{NetworkX}}},
  date = {2022-06-13},
  url = {https://conference.scipy.org/proceedings/SciPy2008/paper_2/},
  urldate = {2022-06-13},
  file = {/home/domvwt/Zotero/storage/Z3AG6KZF/paper_2.html}
}

@misc{prokhorenkovaCatBoostUnbiasedBoosting2019,
  title = {{{CatBoost}}: Unbiased Boosting with Categorical Features},
  shorttitle = {{{CatBoost}}},
  author = {Prokhorenkova, Liudmila and Gusev, Gleb and Vorobev, Aleksandr and Dorogush, Anna Veronika and Gulin, Andrey},
  date = {2019-01-20},
  number = {arXiv:1706.09516},
  eprint = {1706.09516},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1706.09516},
  url = {http://arxiv.org/abs/1706.09516},
  urldate = {2022-09-17},
  abstract = {This paper presents the key algorithmic techniques behind CatBoost, a new gradient boosting toolkit. Their combination leads to CatBoost outperforming other publicly available boosting implementations in terms of quality on a variety of datasets. Two critical algorithmic advances introduced in CatBoost are the implementation of ordered boosting, a permutation-driven alternative to the classic algorithm, and an innovative algorithm for processing categorical features. Both techniques were created to fight a prediction shift caused by a special kind of target leakage present in all currently existing implementations of gradient boosting algorithms. In this paper, we provide a detailed analysis of this problem and demonstrate that proposed algorithms solve it effectively, leading to excellent empirical results.},
  archiveprefix = {arXiv},
  issue = {arXiv:1706.09516},
  keywords = {Computer Science - Machine Learning},
  file = {/home/domvwt/Zotero/storage/BXIBJZ6S/1706.html}
}

@online{PytorchGeometricTutorial2022,
  title = {Pytorch {{Geometric Tutorial}}},
  date = {2022-07-04},
  url = {https://antoniolonga.github.io/Pytorch_geometric_tutorials/posts/post5.html},
  urldate = {2022-07-04},
  file = {/home/domvwt/Zotero/storage/9J55ACSQ/post5.html}
}

@article{saitoPrecisionRecallPlotMore2015,
  title = {The {{Precision-Recall Plot Is More Informative}} than the {{ROC Plot When Evaluating Binary Classifiers}} on {{Imbalanced Datasets}}},
  author = {Saito, Takaya and Rehmsmeier, Marc},
  date = {2015-03-04},
  journaltitle = {PLOS ONE},
  shortjournal = {PLOS ONE},
  volume = {10},
  number = {3},
  pages = {e0118432},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0118432},
  url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0118432},
  urldate = {2022-09-19},
  abstract = {Binary classifiers are routinely evaluated with performance measures such as sensitivity and specificity, and performance is frequently illustrated with Receiver Operating Characteristics (ROC) plots. Alternative measures such as positive predictive value (PPV) and the associated Precision/Recall (PRC) plots are used less frequently. Many bioinformatics studies develop and evaluate classifiers that are to be applied to strongly imbalanced datasets in which the number of negatives outweighs the number of positives significantly. While ROC plots are visually appealing and provide an overview of a classifier's performance across a wide range of specificities, one can ask whether ROC plots could be misleading when applied in imbalanced classification scenarios. We show here that the visual interpretability of ROC plots in the context of imbalanced datasets can be deceptive with respect to conclusions about the reliability of classification performance, owing to an intuitive but wrong interpretation of specificity. PRC plots, on the other hand, can provide the viewer with an accurate prediction of future classification performance due to the fact that they evaluate the fraction of true positives among positive predictions. Our findings have potential implications for the interpretation of a large number of studies that use ROC plots on imbalanced datasets.},
  langid = {english},
  keywords = {Bioinformatics,Caenorhabditis elegans,Exponential functions,Genome-wide association studies,Interpolation,Measurement,MicroRNAs,Support vector machines},
  file = {/home/domvwt/Zotero/storage/HDY78SJW/Saito and Rehmsmeier - 2015 - The Precision-Recall Plot Is More Informative than.pdf;/home/domvwt/Zotero/storage/2N52H3DY/article.html}
}

@article{sanchez-lengelingGentleIntroductionGraph2021,
  title = {A {{Gentle Introduction}} to {{Graph Neural Networks}}},
  author = {Sanchez-Lengeling, Benjamin and Reif, Emily and Pearce, Adam and Wiltschko, Alexander B.},
  date = {2021-09-02},
  journaltitle = {Distill},
  shortjournal = {Distill},
  volume = {6},
  number = {9},
  pages = {e33},
  issn = {2476-0757},
  doi = {10.23915/distill.00033},
  url = {https://distill.pub/2021/gnn-intro},
  urldate = {2022-05-24},
  abstract = {What components are needed for building learning algorithms that leverage the structure and properties of graphs?},
  issue = {9},
  langid = {english},
  file = {/home/domvwt/Zotero/storage/ZLGUYPS2/gnn-intro.html}
}

@article{sarajlicGraphletbasedCharacterizationDirected2016,
  title = {Graphlet-Based {{Characterization}} of {{Directed Networks}}},
  author = {Sarajlić, Anida and Malod-Dognin, Noël and Yaveroğlu, Ömer Nebil and Pržulj, Nataša},
  date = {2016-10-13},
  journaltitle = {Scientific Reports},
  shortjournal = {Sci Rep},
  volume = {6},
  number = {1},
  pages = {35098},
  publisher = {{Nature Publishing Group}},
  issn = {2045-2322},
  doi = {10.1038/srep35098},
  url = {https://www.nature.com/articles/srep35098},
  urldate = {2022-09-18},
  abstract = {We are flooded with large-scale, dynamic, directed, networked data. Analyses requiring exact comparisons between networks are computationally intractable, so new methodologies are sought. To analyse directed networks, we extend graphlets (small induced sub-graphs) and their degrees to directed data. Using these directed graphlets, we generalise state-of-the-art network distance measures (RGF, GDDA and GCD) to directed networks and show their superiority for comparing directed networks. Also, we extend the canonical correlation analysis framework that enables uncovering the relationships between the wiring patterns around nodes in a directed network and their expert annotations. On directed World Trade Networks (WTNs), our methodology allows uncovering the core-broker-periphery structure of the WTN, predicting the economic attributes of a country, such as its gross domestic product, from its wiring patterns in the WTN for up-to ten years in the future. It does so by enabling us to track the dynamics of a country’s positioning in the WTN over years. On directed metabolic networks, our framework yields insights into preservation of enzyme function from the network wiring patterns rather than from sequence data. Overall, our methodology enables advanced analyses of directed networked data from any area of science, allowing domain-specific interpretation of a directed network’s topology.},
  issue = {1},
  langid = {english},
  keywords = {Computational science,Systems analysis},
  file = {/home/domvwt/Zotero/storage/28FAPEUF/srep35098.html}
}

@article{scarselliGraphNeuralNetwork2009,
  title = {The {{Graph Neural Network Model}}},
  author = {Scarselli, Franco and Gori, Marco and Tsoi, Ah Chung and Hagenbuchner, Markus and Monfardini, Gabriele},
  date = {2009-01},
  journaltitle = {IEEE Transactions on Neural Networks},
  volume = {20},
  number = {1},
  pages = {61--80},
  issn = {1941-0093},
  doi = {10.1109/TNN.2008.2005605},
  abstract = {Many underlying relationships among data in several areas of science and engineering, e.g., computer vision, molecular chemistry, molecular biology, pattern recognition, and data mining, can be represented in terms of graphs. In this paper, we propose a new neural network model, called graph neural network (GNN) model, that extends existing neural network methods for processing the data represented in graph domains. This GNN model, which can directly process most of the practically useful types of graphs, e.g., acyclic, cyclic, directed, and undirected, implements a function tau(G,n) isin IRm that maps a graph G and one of its nodes n into an m-dimensional Euclidean space. A supervised learning algorithm is derived to estimate the parameters of the proposed GNN model. The computational cost of the proposed algorithm is also considered. Some experimental results are shown to validate the proposed learning algorithm, and to demonstrate its generalization capabilities.},
  eventtitle = {{{IEEE Transactions}} on {{Neural Networks}}},
  issue = {1},
  keywords = {Biological system modeling,Biology,Chemistry,Computer vision,Data engineering,Data mining,graph neural networks (GNNs),graph processing,Graphical domains,Neural networks,Parameter estimation,Pattern recognition,recursive neural networks,Supervised learning},
  file = {/home/domvwt/Zotero/storage/B3ZVKKUW/Scarselli et al. - 2009 - The Graph Neural Network Model.pdf;/home/domvwt/Zotero/storage/ZJFP664P/4700287.html}
}

@misc{schlichtkrullModelingRelationalData2017,
  title = {Modeling {{Relational Data}} with {{Graph Convolutional Networks}}},
  author = {Schlichtkrull, Michael and Kipf, Thomas N. and Bloem, Peter and van den Berg, Rianne and Titov, Ivan and Welling, Max},
  date = {2017-10-26},
  number = {arXiv:1703.06103},
  eprint = {1703.06103},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1703.06103},
  url = {http://arxiv.org/abs/1703.06103},
  urldate = {2022-09-19},
  abstract = {Knowledge graphs enable a wide variety of applications, including question answering and information retrieval. Despite the great effort invested in their creation and maintenance, even the largest (e.g., Yago, DBPedia or Wikidata) remain incomplete. We introduce Relational Graph Convolutional Networks (R-GCNs) and apply them to two standard knowledge base completion tasks: Link prediction (recovery of missing facts, i.e. subject-predicate-object triples) and entity classification (recovery of missing entity attributes). R-GCNs are related to a recent class of neural networks operating on graphs, and are developed specifically to deal with the highly multi-relational data characteristic of realistic knowledge bases. We demonstrate the effectiveness of R-GCNs as a stand-alone model for entity classification. We further show that factorization models for link prediction such as DistMult can be significantly improved by enriching them with an encoder model to accumulate evidence over multiple inference steps in the relational graph, demonstrating a large improvement of 29.8\% on FB15k-237 over a decoder-only baseline.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Databases,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/domvwt/Zotero/storage/4CQL57AK/Schlichtkrull et al. - 2017 - Modeling Relational Data with Graph Convolutional .pdf;/home/domvwt/Zotero/storage/9D58EGIS/1703.html}
}

@online{SpendNetworkGlobal2022,
  title = {Spend {{Network}} – {{Global}} Procurement Data and Analysis},
  date = {2022-05-24},
  url = {https://spendnetwork.com/},
  urldate = {2022-05-24},
  langid = {british},
  file = {/home/domvwt/Zotero/storage/NC2JRTIN/spendnetwork.com.html}
}

@video{stevebruntonFourierAnalysisOverview2020,
  title = {Fourier {{Analysis}}: {{Overview}}},
  shorttitle = {Fourier {{Analysis}}},
  editor = {{Steve Brunton}},
  date = {2020-03-07},
  url = {https://www.youtube.com/watch?v=jNC0jxb0OxE},
  urldate = {2022-04-27},
  abstract = {This video presents an overview of the Fourier Transform, which is one of the most important transformations in all of mathematical physics and engineering.  This series will introduce the analytic theory of the Fourier Transform, along with the Fast Fourier Transform (FFT) algorithm for efficient computations.  We will explore lots of applications in image compression, audio analysis, and solving partial differential equations.  Book Website: http://databookuw.com  Book PDF: http://databookuw.com/databook.pdf These lectures follow Chapter 2 from:  "Data-Driven Science and Engineering: Machine Learning, Dynamical Systems, and Control"  by Brunton and Kutz Amazon: https://www.amazon.com/Data-Driven-Sc... Brunton Website: eigensteve.com},
  editortype = {director},
  annotation = {Directors: \_:n25}
}

@online{stevenm.CombatingIllicitFinancing2019,
  type = {Testimony},
  title = {Combating {{Illicit Financing}} by {{Anonymous Shell Companies}} — {{FBI}}},
  author = {Steven M., D’Antuono},
  date = {2019-05-21},
  url = {https://www.fbi.gov/news/testimony/combating-illicit-financing-by-anonymous-shell-companies},
  urldate = {2022-06-07},
  abstract = {Statement by Acting Deputy Assistant Director Steven M. D’Antuono, Criminal Investigative Division, before the Senate Banking, Housing, and Urban Affairs Committee},
  langid = {american},
  file = {/home/domvwt/Zotero/storage/FFFCT5RN/combating-illicit-financing-by-anonymous-shell-companies.html}
}

@unpublished{suzumuraFederatedGraphLearning2019,
  title = {Towards {{Federated Graph Learning}} for {{Collaborative Financial Crimes Detection}}},
  author = {Suzumura, Toyotaro and Zhou, Yi and Baracaldo, Natahalie and Ye, Guangnan and Houck, Keith and Kawahara, Ryo and Anwar, Ali and Stavarache, Lucia Larise and Watanabe, Yuji and Loyola, Pablo and Klyashtorny, Daniel and Ludwig, Heiko and Bhaskaran, Kumar},
  date = {2019-10-02},
  number = {arXiv:1909.12946},
  eprint = {1909.12946},
  eprinttype = {arxiv},
  primaryclass = {cs, q-fin},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1909.12946},
  url = {http://arxiv.org/abs/1909.12946},
  urldate = {2022-06-12},
  abstract = {Financial crime is a large and growing problem, in some way touching almost every financial institution. Financial institutions are the front line in the war against financial crime and accordingly, must devote substantial human and technology resources to this effort. Current processes to detect financial misconduct have limitations in their ability to effectively differentiate between malicious behavior and ordinary financial activity. These limitations tend to result in gross over-reporting of suspicious activity that necessitate time-intensive and costly manual review. Advances in technology used in this domain, including machine learning based approaches, can improve upon the effectiveness of financial institutions' existing processes, however, a key challenge that most financial institutions continue to face is that they address financial crimes in isolation without any insight from other firms. Where financial institutions address financial crimes through the lens of their own firm, perpetrators may devise sophisticated strategies that may span across institutions and geographies. Financial institutions continue to work relentlessly to advance their capabilities, forming partnerships across institutions to share insights, patterns and capabilities. These public-private partnerships are subject to stringent regulatory and data privacy requirements, thereby making it difficult to rely on traditional technology solutions. In this paper, we propose a methodology to share key information across institutions by using a federated graph learning platform that enables us to build more accurate machine learning models by leveraging federated learning and also graph learning approaches. We demonstrated that our federated model outperforms local model by 20\% with the UK FCA TechSprint data set. This new platform opens up a door to efficiently detecting global money laundering activity.},
  archiveprefix = {arXiv},
  issue = {arXiv:1909.12946},
  keywords = {Computer Science - Computers and Society,Computer Science - Cryptography and Security,Computer Science - Machine Learning,Computer Science - Social and Information Networks,Quantitative Finance - Statistical Finance},
  file = {/home/domvwt/Zotero/storage/LAJCRQ5I/Suzumura et al. - 2019 - Towards Federated Graph Learning for Collaborative.pdf;/home/domvwt/Zotero/storage/6DKWSK4B/1909.html}
}

@inproceedings{tangLINELargescaleInformation2015,
  title = {{{LINE}}: {{Large-scale Information Network Embedding}}},
  shorttitle = {{{LINE}}},
  booktitle = {Proceedings of the 24th {{International Conference}} on {{World Wide Web}}},
  author = {Tang, Jian and Qu, Meng and Wang, Mingzhe and Zhang, Ming and Yan, Jun and Mei, Qiaozhu},
  date = {2015-05-18},
  eprint = {1503.03578},
  eprinttype = {arxiv},
  primaryclass = {cs},
  pages = {1067--1077},
  doi = {10.1145/2736277.2741093},
  url = {http://arxiv.org/abs/1503.03578},
  urldate = {2022-06-13},
  abstract = {This paper studies the problem of embedding very large information networks into low-dimensional vector spaces, which is useful in many tasks such as visualization, node classification, and link prediction. Most existing graph embedding methods do not scale for real world information networks which usually contain millions of nodes. In this paper, we propose a novel network embedding method called the "LINE," which is suitable for arbitrary types of information networks: undirected, directed, and/or weighted. The method optimizes a carefully designed objective function that preserves both the local and global network structures. An edge-sampling algorithm is proposed that addresses the limitation of the classical stochastic gradient descent and improves both the effectiveness and the efficiency of the inference. Empirical experiments prove the effectiveness of the LINE on a variety of real-world information networks, including language networks, social networks, and citation networks. The algorithm is very efficient, which is able to learn the embedding of a network with millions of vertices and billions of edges in a few hours on a typical single machine. The source code of the LINE is available online.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning},
  file = {/home/domvwt/Zotero/storage/MSC6KJS5/Tang et al. - 2015 - LINE Large-scale Information Network Embedding.pdf;/home/domvwt/Zotero/storage/7B29CY67/1503.html}
}

@misc{togninalliWassersteinWeisfeilerLehmanGraph2019,
  title = {Wasserstein {{Weisfeiler-Lehman Graph Kernels}}},
  author = {Togninalli, Matteo and Ghisu, Elisabetta and Llinares-López, Felipe and Rieck, Bastian and Borgwardt, Karsten},
  date = {2019-10-30},
  number = {arXiv:1906.01277},
  eprint = {1906.01277},
  eprinttype = {arxiv},
  primaryclass = {cs, q-bio, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1906.01277},
  url = {http://arxiv.org/abs/1906.01277},
  urldate = {2022-09-19},
  abstract = {Most graph kernels are an instance of the class of \$\textbackslash mathcal\{R\}\$-Convolution kernels, which measure the similarity of objects by comparing their substructures. Despite their empirical success, most graph kernels use a naive aggregation of the final set of substructures, usually a sum or average, thereby potentially discarding valuable information about the distribution of individual components. Furthermore, only a limited instance of these approaches can be extended to continuously attributed graphs. We propose a novel method that relies on the Wasserstein distance between the node feature vector distributions of two graphs, which allows to find subtler differences in data sets by considering graphs as high-dimensional objects, rather than simple means. We further propose a Weisfeiler-Lehman inspired embedding scheme for graphs with continuous node attributes and weighted edges, enhance it with the computed Wasserstein distance, and thus improve the state-of-the-art prediction performance on several graph classification tasks.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Quantitative Biology - Molecular Networks,Statistics - Machine Learning},
  file = {/home/domvwt/Zotero/storage/Z4RCZLJT/Togninalli et al. - 2019 - Wasserstein Weisfeiler-Lehman Graph Kernels.pdf;/home/domvwt/Zotero/storage/I43ZM9MX/1906.html}
}

@unpublished{treinishRetworkxHighPerformanceGraph2022,
  title = {Retworkx: {{A High-Performance Graph Library}} for {{Python}}},
  shorttitle = {Retworkx},
  author = {Treinish, Matthew and Carvalho, Ivan and Tsilimigkounakis, Georgios and Sá, Nahum},
  date = {2022-02-26},
  eprint = {2110.15221},
  eprinttype = {arxiv},
  primaryclass = {cs},
  url = {http://arxiv.org/abs/2110.15221},
  urldate = {2022-04-27},
  abstract = {In retworkx, we provide a high-performance, flexible graph library for Python. retworkx is inspired by NetworkX but addresses many performance concerns of the latter. retworkx is written in Rust and is particularly suited for performance-sensitive applications that use graph representations.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Data Structures and Algorithms,E.1},
  file = {/home/domvwt/Zotero/storage/Y23PBAIL/Treinish et al. - 2022 - retworkx A High-Performance Graph Library for Pyt.pdf;/home/domvwt/Zotero/storage/ZFV4SXDP/2110.html}
}

@misc{tuLearningFeaturesNetwork2020,
  title = {Learning {{Features}} of {{Network Structures Using Graphlets}}},
  author = {Tu, Kun and Li, Jian and Towsley, Don and Braines, Dave and Turner, Liam},
  date = {2020-04-05},
  number = {arXiv:1812.05473},
  eprint = {1812.05473},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1812.05473},
  url = {http://arxiv.org/abs/1812.05473},
  urldate = {2022-09-18},
  abstract = {Networks are fundamental to the study of complex systems, ranging from social contacts, message transactions, to biological regulations and economical networks. In many realistic applications, these networks may vary over time. Modeling and analyzing such temporal properties is of additional interest as it can provide a richer characterization of relations between nodes in networks. In this paper, we explore the role of \textbackslash emph\{graphlets\} in network classification for both static and temporal networks. Graphlets are small non-isomorphic induced subgraphs representing connected patterns in a network and their frequency can be used to assess network structures. We show that graphlet features, which are not captured by state-of-the-art methods, play a significant role in enhancing the performance of network classification. To that end, we propose two novel graphlet-based techniques, \textbackslash emph\{gl2vec\} for network embedding, and \textbackslash emph\{gl-DCNN\} for diffusion-convolutional neural networks. We demonstrate the efficacy and usability of \textbackslash emph\{gl2vec\} and \textbackslash emph\{gl-DCNN\} through extensive experiments using several real-world static and temporal networks. We find that features learned from graphlets can bring notable performance increases to state-of-the-art methods in network analysis.},
  archiveprefix = {arXiv},
  issue = {arXiv:1812.05473},
  keywords = {Computer Science - Machine Learning,Computer Science - Social and Information Networks},
  file = {/home/domvwt/Zotero/storage/SA6K5AMQ/1812.html}
}

@misc{velickovicGraphAttentionNetworks2018,
  title = {Graph {{Attention Networks}}},
  author = {Veličković, Petar and Cucurull, Guillem and Casanova, Arantxa and Romero, Adriana and Liò, Pietro and Bengio, Yoshua},
  date = {2018-02-04},
  number = {arXiv:1710.10903},
  eprint = {1710.10903},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  url = {http://arxiv.org/abs/1710.10903},
  urldate = {2022-06-13},
  abstract = {We present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods’ features, we enable (implicitly) specifying different weights to different nodes in a neighborhood, without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems. Our GAT models have achieved or matched state-of-theart results across four established transductive and inductive graph benchmarks: the Cora, Citeseer and Pubmed citation network datasets, as well as a proteinprotein interaction dataset (wherein test graphs remain unseen during training).},
  archiveprefix = {arXiv},
  issue = {arXiv:1710.10903},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Social and Information Networks,Statistics - Machine Learning},
  file = {/home/domvwt/Zotero/storage/LQ88KH5F/Veličković et al. - 2018 - Graph Attention Networks.pdf}
}

@misc{wangHeterogeneousGraphAttention2021,
  title = {Heterogeneous {{Graph Attention Network}}},
  author = {Wang, Xiao and Ji, Houye and Shi, Chuan and Wang, Bai and Cui, Peng and Yu, P. and Ye, Yanfang},
  date = {2021-01-20},
  number = {arXiv:1903.07293},
  eprint = {1903.07293},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1903.07293},
  url = {http://arxiv.org/abs/1903.07293},
  urldate = {2022-09-20},
  abstract = {Graph neural network, as a powerful graph representation technique based on deep learning, has shown superior performance and attracted considerable research interest. However, it has not been fully considered in graph neural network for heterogeneous graph which contains different types of nodes and links. The heterogeneity and rich semantic information bring great challenges for designing a graph neural network for heterogeneous graph. Recently, one of the most exciting advancements in deep learning is the attention mechanism, whose great potential has been well demonstrated in various areas. In this paper, we first propose a novel heterogeneous graph neural network based on the hierarchical attention, including node-level and semantic-level attentions. Specifically, the node-level attention aims to learn the importance between a node and its metapath based neighbors, while the semantic-level attention is able to learn the importance of different meta-paths. With the learned importance from both node-level and semantic-level attention, the importance of node and meta-path can be fully considered. Then the proposed model can generate node embedding by aggregating features from meta-path based neighbors in a hierarchical manner. Extensive experimental results on three real-world heterogeneous graphs not only show the superior performance of our proposed model over the state-of-the-arts, but also demonstrate its potentially good interpretability for graph analysis.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Social and Information Networks},
  file = {/home/domvwt/Zotero/storage/I5NI4RG3/Wang et al. - 2021 - Heterogeneous Graph Attention Network.pdf;/home/domvwt/Zotero/storage/2B4N7RKD/1903.html}
}

@inproceedings{wangSemisupervisedGraphAttentive2019,
  title = {A {{Semi-supervised Graph Attentive Network}} for {{Financial Fraud Detection}}},
  booktitle = {2019 {{IEEE International Conference}} on {{Data Mining}} ({{ICDM}})},
  author = {Wang, Daixin and Lin, Jianbin and Cui, Peng and Jia, Quanhui and Wang, Zhen and Fang, Yanming and Yu, Quan and Zhou, Jun and Yang, Shuang and Qi, Yuan},
  date = {2019-11},
  eprint = {2003.01171},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  pages = {598--607},
  doi = {10.1109/ICDM.2019.00070},
  url = {http://arxiv.org/abs/2003.01171},
  urldate = {2022-06-13},
  abstract = {With the rapid growth of financial services, fraud detection has been a very important problem to guarantee a healthy environment for both users and providers. Conventional solutions for fraud detection mainly use some rule-based methods or distract some features manually to perform prediction. However, in financial services, users have rich interactions and they themselves always show multifaceted information. These data form a large multiview network, which is not fully exploited by conventional methods. Additionally, among the network, only very few of the users are labelled, which also poses a great challenge for only utilizing labeled data to achieve a satisfied performance on fraud detection. To address the problem, we expand the labeled data through their social relations to get the unlabeled data and propose a semi-supervised attentive graph neural network, namedSemiGNN to utilize the multi-view labeled and unlabeled data for fraud detection. Moreover, we propose a hierarchical attention mechanism to better correlate different neighbors and different views. Simultaneously, the attention mechanism can make the model interpretable and tell what are the important factors for the fraud and why the users are predicted as fraud. Experimentally, we conduct the prediction task on the users of Alipay, one of the largest third-party online and offline cashless payment platform serving more than 4 hundreds of million users in China. By utilizing the social relations and the user attributes, our method can achieve a better accuracy compared with the state-of-the-art methods on two tasks. Moreover, the interpretable results also give interesting intuitions regarding the tasks.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning,Computer Science - Social and Information Networks,Statistics - Machine Learning},
  file = {/home/domvwt/Zotero/storage/I4WRJAGQ/Wang et al. - 2019 - A Semi-supervised Graph Attentive Network for Fina.pdf;/home/domvwt/Zotero/storage/KUAPEQAU/2003.html}
}

@unpublished{weberAntiMoneyLaunderingBitcoin2019,
  title = {Anti-{{Money Laundering}} in {{Bitcoin}}: {{Experimenting}} with {{Graph Convolutional Networks}} for {{Financial Forensics}}},
  shorttitle = {Anti-{{Money Laundering}} in {{Bitcoin}}},
  author = {Weber, Mark and Domeniconi, Giacomo and Chen, Jie and Weidele, Daniel Karl I. and Bellei, Claudio and Robinson, Tom and Leiserson, Charles E.},
  date = {2019-07-31},
  number = {arXiv:1908.02591},
  eprint = {1908.02591},
  eprinttype = {arxiv},
  primaryclass = {cs, q-fin},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1908.02591},
  url = {http://arxiv.org/abs/1908.02591},
  urldate = {2022-06-12},
  abstract = {Anti-money laundering (AML) regulations play a critical role in safeguarding financial systems, but bear high costs for institutions and drive financial exclusion for those on the socioeconomic and international margins. The advent of cryptocurrency has introduced an intriguing paradox: pseudonymity allows criminals to hide in plain sight, but open data gives more power to investigators and enables the crowdsourcing of forensic analysis. Meanwhile advances in learning algorithms show great promise for the AML toolkit. In this workshop tutorial, we motivate the opportunity to reconcile the cause of safety with that of financial inclusion. We contribute the Elliptic Data Set, a time series graph of over 200K Bitcoin transactions (nodes), 234K directed payment flows (edges), and 166 node features, including ones based on non-public data; to our knowledge, this is the largest labelled transaction data set publicly available in any cryptocurrency. We share results from a binary classification task predicting illicit transactions using variations of Logistic Regression (LR), Random Forest (RF), Multilayer Perceptrons (MLP), and Graph Convolutional Networks (GCN), with GCN being of special interest as an emergent new method for capturing relational information. The results show the superiority of Random Forest (RF), but also invite algorithmic work to combine the respective powers of RF and graph methods. Lastly, we consider visualization for analysis and explainability, which is difficult given the size and dynamism of real-world transaction graphs, and we offer a simple prototype capable of navigating the graph and observing model performance on illicit activity over time. With this tutorial and data set, we hope to a) invite feedback in support of our ongoing inquiry, and b) inspire others to work on this societally important challenge.},
  archiveprefix = {arXiv},
  issue = {arXiv:1908.02591},
  keywords = {Computer Science - Computers and Society,Computer Science - Machine Learning,Computer Science - Social and Information Networks,Quantitative Finance - General Finance},
  file = {/home/domvwt/Zotero/storage/BL6LJTEL/Weber et al. - 2019 - Anti-Money Laundering in Bitcoin Experimenting wi.pdf;/home/domvwt/Zotero/storage/IURLMK9V/1908.html}
}

@unpublished{weberScalableGraphLearning2018,
  title = {Scalable {{Graph Learning}} for {{Anti-Money Laundering}}: {{A First Look}}},
  shorttitle = {Scalable {{Graph Learning}} for {{Anti-Money Laundering}}},
  author = {Weber, Mark and Chen, Jie and Suzumura, Toyotaro and Pareja, Aldo and Ma, Tengfei and Kanezashi, Hiroki and Kaler, Tim and Leiserson, Charles E. and Schardl, Tao B.},
  date = {2018-11-30},
  number = {arXiv:1812.00076},
  eprint = {1812.00076},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1812.00076},
  url = {http://arxiv.org/abs/1812.00076},
  urldate = {2022-06-12},
  abstract = {Organized crime inflicts human suffering on a genocidal scale: the Mexican drug cartels have murdered 150,000 people since 2006, upwards of 700,000 people per year are "exported" in a human trafficking industry enslaving an estimated 40 million people. These nefarious industries rely on sophisticated money laundering schemes to operate. Despite tremendous resources dedicated to anti-money laundering (AML) only a tiny fraction of illicit activity is prevented. The research community can help. In this brief paper, we map the structural and behavioral dynamics driving the technical challenge. We review AML methods, current and emergent. We provide a first look at scalable graph convolutional neural networks for forensic analysis of financial data, which is massive, dense, and dynamic. We report preliminary experimental results using a large synthetic graph (1M nodes, 9M edges) generated by a data simulator we created called AMLSim. We consider opportunities for high performance efficiency, in terms of computation and memory, and we share results from a simple graph compression experiment. Our results support our working hypothesis that graph deep learning for AML bears great promise in the fight against criminal financial activity.},
  archiveprefix = {arXiv},
  issue = {arXiv:1812.00076},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Social and Information Networks},
  file = {/home/domvwt/Zotero/storage/V4ZMJTZA/Weber et al. - 2018 - Scalable Graph Learning for Anti-Money Laundering.pdf;/home/domvwt/Zotero/storage/J2PIVPAJ/1812.html}
}

@online{WhatDoesUK2022,
  title = {What Does the {{UK}} Beneficial Ownership Data Show Us?},
  date = {2022-05-24},
  url = {https:///en/blog/what-does-uk-beneficial-ownership-data-show-us/},
  urldate = {2022-05-24},
  abstract = {Find out what we found on our deep dive into the UK register of who owns companies},
  langid = {english},
  organization = {{Global Witness}},
  file = {/home/domvwt/Zotero/storage/GZ544KVF/what-does-uk-beneficial-ownership-data-show-us.html}
}

@inproceedings{xuRepresentationLearningGraphs2018,
  title = {Representation {{Learning}} on {{Graphs}} with {{Jumping Knowledge Networks}}},
  booktitle = {Proceedings of the 35th {{International Conference}} on {{Machine Learning}}},
  author = {Xu, Keyulu and Li, Chengtao and Tian, Yonglong and Sonobe, Tomohiro and Kawarabayashi, Ken-ichi and Jegelka, Stefanie},
  date = {2018-07-03},
  pages = {5453--5462},
  publisher = {{PMLR}},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v80/xu18c.html},
  urldate = {2022-09-20},
  abstract = {Recent deep learning approaches for representation learning on graphs follow a neighborhood aggregation procedure. We analyze some important properties of these models, and propose a strategy to overcome those. In particular, the range of "neighboring" nodes that a node’s representation draws from strongly depends on the graph structure, analogous to the spread of a random walk. To adapt to local neighborhood properties and tasks, we explore an architecture – jumping knowledge (JK) networks – that flexibly leverages, for each node, different neighborhood ranges to enable better structure-aware representation. In a number of experiments on social, bioinformatics and citation networks, we demonstrate that our model achieves state-of-the-art performance. Furthermore, combining the JK framework with models like Graph Convolutional Networks, GraphSAGE and Graph Attention Networks consistently improves those models’ performance.},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english},
  file = {/home/domvwt/Zotero/storage/26UZ49NQ/Xu et al. - 2018 - Representation Learning on Graphs with Jumping Kno.pdf;/home/domvwt/Zotero/storage/N7S3ZTS8/Xu et al. - 2018 - Representation Learning on Graphs with Jumping Kno.pdf}
}

@misc{yingGNNExplainerGeneratingExplanations2019,
  title = {{{GNNExplainer}}: {{Generating Explanations}} for {{Graph Neural Networks}}},
  shorttitle = {{{GNNExplainer}}},
  author = {Ying, Rex and Bourgeois, Dylan and You, Jiaxuan and Zitnik, Marinka and Leskovec, Jure},
  date = {2019-11-13},
  number = {arXiv:1903.03894},
  eprint = {1903.03894},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1903.03894},
  url = {http://arxiv.org/abs/1903.03894},
  urldate = {2022-09-15},
  abstract = {Graph Neural Networks (GNNs) are a powerful tool for machine learning on graphs.GNNs combine node feature information with the graph structure by recursively passing neural messages along edges of the input graph. However, incorporating both graph structure and feature information leads to complex models, and explaining predictions made by GNNs remains unsolved. Here we propose GNNExplainer, the first general, model-agnostic approach for providing interpretable explanations for predictions of any GNN-based model on any graph-based machine learning task. Given an instance, GNNExplainer identifies a compact subgraph structure and a small subset of node features that have a crucial role in GNN's prediction. Further, GNNExplainer can generate consistent and concise explanations for an entire class of instances. We formulate GNNExplainer as an optimization task that maximizes the mutual information between a GNN's prediction and distribution of possible subgraph structures. Experiments on synthetic and real-world graphs show that our approach can identify important graph structures as well as node features, and outperforms baselines by 17.1\% on average. GNNExplainer provides a variety of benefits, from the ability to visualize semantically relevant structures to interpretability, to giving insights into errors of faulty GNNs.},
  archiveprefix = {arXiv},
  issue = {arXiv:1903.03894},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/domvwt/Zotero/storage/S3T7ANI4/Ying et al. - 2019 - GNNExplainer Generating Explanations for Graph Ne.pdf;/home/domvwt/Zotero/storage/IWKKV9H7/1903.html}
}

@inproceedings{youDesignSpaceGraph2020,
  title = {Design {{Space}} for {{Graph Neural Networks}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {You, Jiaxuan and Ying, Zhitao and Leskovec, Jure},
  date = {2020},
  volume = {33},
  pages = {17009--17021},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper/2020/hash/c5c3d4fe6b2cc463c7d7ecba17cc9de7-Abstract.html},
  urldate = {2022-07-04},
  abstract = {The rapid evolution of Graph Neural Networks (GNNs) has led to a growing number of new architectures as well as novel applications. However, current research focuses on proposing and evaluating specific architectural designs of GNNs, such as GCN, GIN, or GAT, as opposed to studying the more general design space of GNNs that consists of a Cartesian product of different design dimensions, such as the number of layers or the type of the aggregation function. Additionally, GNN designs are often specialized to a single task, yet few efforts have been made to understand how to quickly find the best GNN design for a novel task or a novel dataset. Here we define and systematically study the architectural design space for GNNs which consists of 315,000 different designs over 32 different predictive tasks. Our approach features three key innovations: (1) A general GNN design space; (2) a GNN task space with a similarity metric, so that for a given novel task/dataset, we can quickly identify/transfer the best performing architecture; (3) an efficient and effective design space evaluation method which allows insights to be distilled from a huge number of model-task combinations. Our key results include: (1) A comprehensive set of guidelines for designing well-performing GNNs; (2) while best GNN designs for different tasks vary significantly, the GNN task space allows for transferring the best designs across different tasks; (3) models discovered using our design space achieve state-of-the-art performance. Overall, our work offers a principled and scalable approach to transition from studying individual GNN designs for specific tasks, to systematically studying the GNN design space and the task space. Finally, we release GraphGym, a powerful platform for exploring different GNN designs and tasks. GraphGym features modularized GNN implementation, standardized GNN evaluation, and reproducible and scalable experiment management.}
}

@unpublished{zhangGCNBasedUserRepresentation2020,
  title = {{{GCN-Based User Representation Learning}} for {{Unifying Robust Recommendation}} and {{Fraudster Detection}}},
  author = {Zhang, Shijie and Yin, Hongzhi and Chen, Tong and Hung, Quoc Viet Nguyen and Huang, Zi and Cui, Lizhen},
  date = {2020-05-20},
  number = {arXiv:2005.10150},
  eprint = {2005.10150},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2005.10150},
  url = {http://arxiv.org/abs/2005.10150},
  urldate = {2022-06-13},
  abstract = {In recent years, recommender system has become an indispensable function in all e-commerce platforms. The review rating data for a recommender system typically comes from open platforms, which may attract a group of malicious users to deliberately insert fake feedback in an attempt to bias the recommender system to their favour. The presence of such attacks may violate modeling assumptions that high-quality data is always available and these data truly reflect users' interests and preferences. Therefore, it is of great practical significance to construct a robust recommender system that is able to generate stable recommendations even in the presence of shilling attacks. In this paper, we propose GraphRfi - a GCN-based user representation learning framework to perform robust recommendation and fraudster detection in a unified way. In its end-to-end learning process, the probability of a user being identified as a fraudster in the fraudster detection component automatically determines the contribution of this user's rating data in the recommendation component; while the prediction error outputted in the recommendation component acts as an important feature in the fraudster detection component. Thus, these two components can mutually enhance each other. Extensive experiments have been conducted and the experimental results show the superiority of our GraphRfi in the two tasks - robust rating prediction and fraudster detection. Furthermore, the proposed GraphRfi is validated to be more robust to the various types of shilling attacks over the state-of-the-art recommender systems.},
  archiveprefix = {arXiv},
  issue = {arXiv:2005.10150},
  keywords = {Computer Science - Information Retrieval,Computer Science - Social and Information Networks},
  file = {/home/domvwt/Zotero/storage/3MJ7Q4JC/Zhang et al. - 2020 - GCN-Based User Representation Learning for Unifyin.pdf;/home/domvwt/Zotero/storage/44AYAYIH/2005.html}
}

@article{zhouGraphNeuralNetworks2020,
  title = {Graph Neural Networks: {{A}} Review of Methods and Applications},
  shorttitle = {Graph Neural Networks},
  author = {Zhou, Jie and Cui, Ganqu and Hu, Shengding and Zhang, Zhengyan and Yang, Cheng and Liu, Zhiyuan and Wang, Lifeng and Li, Changcheng and Sun, Maosong},
  date = {2020-01-01},
  journaltitle = {AI Open},
  shortjournal = {AI Open},
  volume = {1},
  pages = {57--81},
  issn = {2666-6510},
  doi = {10.1016/j.aiopen.2021.01.001},
  url = {https://www.sciencedirect.com/science/article/pii/S2666651021000012},
  urldate = {2022-09-02},
  abstract = {Lots of learning tasks require dealing with graph data which contains rich relation information among elements. Modeling physics systems, learning molecular fingerprints, predicting protein interface, and classifying diseases demand a model to learn from graph inputs. In other domains such as learning from non-structural data like texts and images, reasoning on extracted structures (like the dependency trees of sentences and the scene graphs of images) is an important research topic which also needs graph reasoning models. Graph neural networks (GNNs) are neural models that capture the dependence of graphs via message passing between the nodes of graphs. In recent years, variants of GNNs such as graph convolutional network (GCN), graph attention network (GAT), graph recurrent network (GRN) have demonstrated ground-breaking performances on many deep learning tasks. In this survey, we propose a general design pipeline for GNN models and discuss the variants of each component, systematically categorize the applications, and propose four open problems for future research.},
  langid = {english},
  keywords = {Deep learning,Graph neural network},
  file = {/home/domvwt/Zotero/storage/NGLVPQZ2/S2666651021000012.html}
}


