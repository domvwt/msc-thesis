{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5a71bd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "# jupyter:\n",
    "#   jupytext:\n",
    "#     formats: ipynb,py:percent\n",
    "#     text_representation:\n",
    "#       extension: .py\n",
    "#       format_name: percent\n",
    "#       format_version: '1.3'\n",
    "#       jupytext_version: 1.13.8\n",
    "#   kernelspec:\n",
    "#     display_name: Python 3 (ipykernel)\n",
    "#     language: python\n",
    "#     name: python3\n",
    "# ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e37eb8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import to_hetero\n",
    "\n",
    "\n",
    "from mscproject.metrics import EvalMetrics\n",
    "from mscproject import models\n",
    "from mscproject.datasets import CompanyBeneficialOwners\n",
    "\n",
    "# TODO: regularisation like https://stackoverflow.com/questions/42704283/l1-l2-regularization-in-pytorch\n",
    "# TODO: follow this example https://github.com/pyg-team/pytorch_geometric/issues/3958\n",
    "\n",
    "while not Path(\"data\") in Path(\".\").iterdir():\n",
    "    os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b1ffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_dict = yaml.safe_load(Path(\"config/conf.yaml\").read_text())\n",
    "dataset_path = \"data/pyg/\"\n",
    "\n",
    "dataset = CompanyBeneficialOwners(dataset_path, to_undirected=True)\n",
    "\n",
    "input_data = dataset[0]  # type: ignore\n",
    "input_metadata = dataset.metadata()\n",
    "\n",
    "model = models.GAT(\n",
    "    in_channels=-1,\n",
    "    hidden_channels=16,\n",
    "    num_layers=3,\n",
    "    out_channels=1,\n",
    "    jk=\"last\",\n",
    "    # heads=1,\n",
    "    # concat=True,\n",
    "    v2=True,\n",
    "    add_self_loops=False,\n",
    ")\n",
    "\n",
    "model = to_hetero(model, metadata=input_metadata, aggr=\"sum\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataset, model = dataset.data.to(device), model.to(device)\n",
    "\n",
    "with torch.no_grad():  # Initialize lazy modules.\n",
    "    out = model(dataset.x_dict, dataset.edge_index_dict)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.05, weight_decay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1f880675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(input_data.x_dict, input_data.edge_index_dict)\n",
    "\n",
    "    company_train_mask = input_data[\"company\"].train_mask\n",
    "    person_train_mask = input_data[\"person\"].train_mask\n",
    "\n",
    "    companies_out = out[\"company\"][company_train_mask]\n",
    "    persons_out = out[\"person\"][person_train_mask]\n",
    "    out_tensor = torch.cat((companies_out, persons_out), dim=0).float().squeeze()\n",
    "\n",
    "    companies_y = input_data.y_dict[\"company\"][company_train_mask]\n",
    "    persons_y = input_data.y_dict[\"person\"][person_train_mask]\n",
    "\n",
    "    y_tensor = torch.cat((companies_y, persons_y), dim=0).float().squeeze()\n",
    "\n",
    "    # Multiply importance of anomalous data by 10.\n",
    "    importance = (y_tensor * 9) + 1\n",
    "\n",
    "    loss = F.binary_cross_entropy(out_tensor, y_tensor, weight=importance)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return float(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7a5267",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "\n",
    "    prediction_dict = model(input_data.x_dict, input_data.edge_index_dict)\n",
    "\n",
    "    metrics_dict = {}\n",
    "\n",
    "    for split in [\"train_mask\", \"val_mask\"]:\n",
    "\n",
    "        masks = []\n",
    "        actuals = []\n",
    "        predictions = []\n",
    "\n",
    "        for node_type in [\"company\", \"person\"]:\n",
    "            mask = input_data[node_type][split]\n",
    "            actual = input_data.y_dict[node_type][mask]\n",
    "            prediction = prediction_dict[node_type][mask]\n",
    "\n",
    "            masks.append(mask)\n",
    "            predictions.append(prediction)\n",
    "            actuals.append(actual)\n",
    "\n",
    "        combined_predictions = torch.cat(predictions, dim=0).squeeze()\n",
    "        combined_actuals = torch.cat(actuals, dim=0).squeeze()\n",
    "\n",
    "        metrics_dict[split] = EvalMetrics.from_tensors(\n",
    "            combined_predictions, combined_actuals, pos_weight_multiplier=10\n",
    "        )\n",
    "\n",
    "    return metrics_dict\n",
    "\n",
    "\n",
    "metrics_history = []\n",
    "\n",
    "for epoch in range(1, 101):\n",
    "    # ! Use average precision score to evaluate model.\n",
    "    loss = train()\n",
    "    metrics_dict = test()\n",
    "    metrics_history.append(metrics_dict)\n",
    "    print(f\"Epoch: {epoch:03d}\")\n",
    "    print(f\"Train: {metrics_dict['train_mask']}\")\n",
    "    print(f\"Valid: {metrics_dict['val_mask']}\")\n",
    "    print(\"-\" * 79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4e17bd6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['onehotencoder__CompanyStatus_Active - Proposal to Strike off__processed',\n",
       " 'onehotencoder__CompanyStatus_None__processed',\n",
       " 'onehotencoder__CompanyStatus_infrequent_sklearn__processed',\n",
       " 'onehotencoder__Accounts_AccountCategory_DORMANT__processed',\n",
       " 'onehotencoder__Accounts_AccountCategory_FULL__processed',\n",
       " 'onehotencoder__Accounts_AccountCategory_GROUP__processed',\n",
       " 'onehotencoder__Accounts_AccountCategory_MICRO ENTITY__processed',\n",
       " 'onehotencoder__Accounts_AccountCategory_NO ACCOUNTS FILED__processed',\n",
       " 'onehotencoder__Accounts_AccountCategory_SMALL__processed',\n",
       " 'onehotencoder__Accounts_AccountCategory_TOTAL EXEMPTION FULL__processed',\n",
       " 'onehotencoder__Accounts_AccountCategory_UNAUDITED ABRIDGED__processed',\n",
       " 'onehotencoder__Accounts_AccountCategory_None__processed',\n",
       " 'onehotencoder__Accounts_AccountCategory_infrequent_sklearn__processed',\n",
       " 'onehotencoder__SICCode_SicText_1_41202 - Construction of domestic buildings__processed',\n",
       " 'onehotencoder__SICCode_SicText_1_64209 - Activities of other holding companies n.e.c.__processed',\n",
       " 'onehotencoder__SICCode_SicText_1_68100 - Buying and selling of own real estate__processed',\n",
       " 'onehotencoder__SICCode_SicText_1_68209 - Other letting and operating of own or leased real estate__processed',\n",
       " 'onehotencoder__SICCode_SicText_1_68320 - Management of real estate on a fee or contract basis__processed',\n",
       " 'onehotencoder__SICCode_SicText_1_70100 - Activities of head offices__processed',\n",
       " 'onehotencoder__SICCode_SicText_1_70229 - Management consultancy activities other than financial management__processed',\n",
       " 'onehotencoder__SICCode_SicText_1_74990 - Non-trading company__processed',\n",
       " 'onehotencoder__SICCode_SicText_1_82990 - Other business support service activities n.e.c.__processed',\n",
       " 'onehotencoder__SICCode_SicText_1_96090 - Other service activities n.e.c.__processed',\n",
       " 'onehotencoder__SICCode_SicText_1_99999 - Dormant Company__processed',\n",
       " 'onehotencoder__SICCode_SicText_1_None__processed',\n",
       " 'onehotencoder__SICCode_SicText_1_infrequent_sklearn__processed',\n",
       " 'foundingDate__processed',\n",
       " 'indegree__processed',\n",
       " 'outdegree__processed',\n",
       " 'closeness__processed',\n",
       " 'clustering__processed',\n",
       " 'pagerank__processed']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"company\"].feature_names"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c9b131bfea46adc0e6841e7be18b140852cf163d67d3b9948cbb78fda58292a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
