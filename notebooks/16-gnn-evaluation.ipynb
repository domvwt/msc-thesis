{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b0a93c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.transforms import AddSelfLoops\n",
    "from mscproject.transforms import RemoveSelfLoops\n",
    "\n",
    "from mscproject.datasets import CompanyBeneficialOwners\n",
    "from mscproject.transforms import RemoveSelfLoops\n",
    "import mscproject.models as mod\n",
    "import mscproject.experiment as exp\n",
    "\n",
    "while not Path(\"data\") in Path(\".\").iterdir():\n",
    "    os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df4d972e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GraphSAGE', 'KGNN']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_DIR = Path(\"data/models/pyg/weights-unregularised/\")\n",
    "OPTUNA_DB = Path(\"data/optuna-06.db\")\n",
    "DATASET_PATH = Path(\"data/pyg\")\n",
    "PREDICTION_DIR = Path(\"data/predictions\")\n",
    "\n",
    "model_names = [x.stem for x in MODEL_DIR.iterdir()]\n",
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b47d8dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CompanyBeneficialOwners(DATASET_PATH, to_undirected=True)\n",
    "dataset = dataset.data.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "422394fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_trial(model_name):\n",
    "    study = optuna.load_study(\n",
    "        study_name=f\"pyg_model_selection_{model_name}_ARCHITECTURE\",\n",
    "        storage=f\"sqlite:///{OPTUNA_DB}\",\n",
    "    )\n",
    "    model_params = study.best_params\n",
    "    user_attrs = study.best_trial.user_attrs\n",
    "    return model_params, user_attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18956051",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"GraphSAGE\"\n",
    "study = optuna.load_study(\n",
    "    study_name=f\"pyg_model_selection_{model_name}_ARCHITECTURE\",\n",
    "    storage=f\"sqlite:///{OPTUNA_DB}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4945f1c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>71</th>\n",
       "      <th>2</th>\n",
       "      <th>90</th>\n",
       "      <th>57</th>\n",
       "      <th>65</th>\n",
       "      <th>92</th>\n",
       "      <th>42</th>\n",
       "      <th>22</th>\n",
       "      <th>25</th>\n",
       "      <th>56</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <td>71</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>57</td>\n",
       "      <td>65</td>\n",
       "      <td>92</td>\n",
       "      <td>42</td>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>value</th>\n",
       "      <td>0.974547</td>\n",
       "      <td>0.964633</td>\n",
       "      <td>0.964578</td>\n",
       "      <td>0.953541</td>\n",
       "      <td>0.890489</td>\n",
       "      <td>0.846144</td>\n",
       "      <td>0.804536</td>\n",
       "      <td>0.798571</td>\n",
       "      <td>0.772965</td>\n",
       "      <td>0.749134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime_start</th>\n",
       "      <td>2023-01-09 13:51:44.689671</td>\n",
       "      <td>2023-01-08 23:45:58.579411</td>\n",
       "      <td>2023-01-09 14:37:38.644384</td>\n",
       "      <td>2023-01-09 13:03:53.627998</td>\n",
       "      <td>2023-01-09 13:38:23.969175</td>\n",
       "      <td>2023-01-09 14:43:26.845169</td>\n",
       "      <td>2023-01-09 01:23:31.508692</td>\n",
       "      <td>2023-01-09 00:31:55.916797</td>\n",
       "      <td>2023-01-09 00:38:23.500434</td>\n",
       "      <td>2023-01-09 12:59:41.820345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime_complete</th>\n",
       "      <td>2023-01-09 13:55:06.312907</td>\n",
       "      <td>2023-01-09 00:01:36.145491</td>\n",
       "      <td>2023-01-09 14:41:50.938074</td>\n",
       "      <td>2023-01-09 13:07:27.693139</td>\n",
       "      <td>2023-01-09 13:40:37.164632</td>\n",
       "      <td>2023-01-09 14:45:21.441809</td>\n",
       "      <td>2023-01-09 01:27:14.505445</td>\n",
       "      <td>2023-01-09 00:35:09.474524</td>\n",
       "      <td>2023-01-09 00:41:06.815786</td>\n",
       "      <td>2023-01-09 13:03:53.590702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration</th>\n",
       "      <td>0 days 00:03:21.623236</td>\n",
       "      <td>0 days 00:15:37.566080</td>\n",
       "      <td>0 days 00:04:12.293690</td>\n",
       "      <td>0 days 00:03:34.065141</td>\n",
       "      <td>0 days 00:02:13.195457</td>\n",
       "      <td>0 days 00:01:54.596640</td>\n",
       "      <td>0 days 00:03:42.996753</td>\n",
       "      <td>0 days 00:03:13.557727</td>\n",
       "      <td>0 days 00:02:43.315352</td>\n",
       "      <td>0 days 00:04:11.770357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params_act</th>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>gelu</td>\n",
       "      <td>gelu</td>\n",
       "      <td>relu</td>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>gelu</td>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>leaky_relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params_add_self_loops</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params_bias</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params_gnn_aggr</th>\n",
       "      <td>max</td>\n",
       "      <td>max</td>\n",
       "      <td>min</td>\n",
       "      <td>min</td>\n",
       "      <td>min</td>\n",
       "      <td>min</td>\n",
       "      <td>mean</td>\n",
       "      <td>mean</td>\n",
       "      <td>mean</td>\n",
       "      <td>mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params_hidden_channels_log2</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params_jk</th>\n",
       "      <td>none</td>\n",
       "      <td>last</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params_num_layers</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params_to_hetero_aggr</th>\n",
       "      <td>min</td>\n",
       "      <td>mean</td>\n",
       "      <td>min</td>\n",
       "      <td>min</td>\n",
       "      <td>min</td>\n",
       "      <td>min</td>\n",
       "      <td>min</td>\n",
       "      <td>min</td>\n",
       "      <td>min</td>\n",
       "      <td>min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_attrs_acc</th>\n",
       "      <td>0.930924</td>\n",
       "      <td>0.931325</td>\n",
       "      <td>0.930388</td>\n",
       "      <td>0.928916</td>\n",
       "      <td>0.931325</td>\n",
       "      <td>0.927041</td>\n",
       "      <td>0.927845</td>\n",
       "      <td>0.927577</td>\n",
       "      <td>0.928648</td>\n",
       "      <td>0.928648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_attrs_aprc</th>\n",
       "      <td>0.974547</td>\n",
       "      <td>0.964633</td>\n",
       "      <td>0.964578</td>\n",
       "      <td>0.953541</td>\n",
       "      <td>0.890489</td>\n",
       "      <td>0.846144</td>\n",
       "      <td>0.804536</td>\n",
       "      <td>0.798571</td>\n",
       "      <td>0.772965</td>\n",
       "      <td>0.749134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_attrs_aprc_history</th>\n",
       "      <td>[0.08378168940544128, 0.05609657242894173, 0.0...</td>\n",
       "      <td>[0.07739533483982086, 0.080048568546772, 0.089...</td>\n",
       "      <td>[0.08926263451576233, 0.06005857139825821, 0.0...</td>\n",
       "      <td>[0.10039807856082916, 0.09880204498767853, 0.1...</td>\n",
       "      <td>[0.08270087838172913, 0.0893382802605629, 0.08...</td>\n",
       "      <td>[0.09540335834026337, 0.1048639714717865, 0.09...</td>\n",
       "      <td>[0.09267298877239227, 0.10853002965450287, 0.0...</td>\n",
       "      <td>[0.08961427211761475, 0.10988513380289078, 0.0...</td>\n",
       "      <td>[0.09363724291324615, 0.09883667528629303, 0.0...</td>\n",
       "      <td>[0.10130488872528076, 0.10246395319700241, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_attrs_auc</th>\n",
       "      <td>0.997689</td>\n",
       "      <td>0.996783</td>\n",
       "      <td>0.99633</td>\n",
       "      <td>0.995127</td>\n",
       "      <td>0.984969</td>\n",
       "      <td>0.980221</td>\n",
       "      <td>0.948339</td>\n",
       "      <td>0.949581</td>\n",
       "      <td>0.940571</td>\n",
       "      <td>0.941333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_attrs_best_epoch</th>\n",
       "      <td>186.0</td>\n",
       "      <td>754.0</td>\n",
       "      <td>857.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>673.0</td>\n",
       "      <td>559.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>251.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_attrs_f1</th>\n",
       "      <td>0.798246</td>\n",
       "      <td>0.779128</td>\n",
       "      <td>0.784737</td>\n",
       "      <td>0.762771</td>\n",
       "      <td>0.721358</td>\n",
       "      <td>0.667086</td>\n",
       "      <td>0.72404</td>\n",
       "      <td>0.712271</td>\n",
       "      <td>0.669328</td>\n",
       "      <td>0.68599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_attrs_learning_rate</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_attrs_loss</th>\n",
       "      <td>0.089603</td>\n",
       "      <td>0.100851</td>\n",
       "      <td>0.150573</td>\n",
       "      <td>0.15866</td>\n",
       "      <td>0.322625</td>\n",
       "      <td>0.441667</td>\n",
       "      <td>1.588745</td>\n",
       "      <td>1.409402</td>\n",
       "      <td>1.935887</td>\n",
       "      <td>2.761004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_attrs_n_hidden</th>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_attrs_precision</th>\n",
       "      <td>0.664234</td>\n",
       "      <td>0.638921</td>\n",
       "      <td>0.646501</td>\n",
       "      <td>0.617214</td>\n",
       "      <td>0.587558</td>\n",
       "      <td>0.50815</td>\n",
       "      <td>0.59186</td>\n",
       "      <td>0.579128</td>\n",
       "      <td>0.525601</td>\n",
       "      <td>0.550388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_attrs_recall</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998168</td>\n",
       "      <td>0.998168</td>\n",
       "      <td>0.998168</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.970696</td>\n",
       "      <td>0.932234</td>\n",
       "      <td>0.924908</td>\n",
       "      <td>0.921245</td>\n",
       "      <td>0.910256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_attrs_total_epochs</th>\n",
       "      <td>386.0</td>\n",
       "      <td>954.0</td>\n",
       "      <td>1057.0</td>\n",
       "      <td>601.0</td>\n",
       "      <td>556.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>873.0</td>\n",
       "      <td>759.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>451.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_attrs_training_time</th>\n",
       "      <td>NaN</td>\n",
       "      <td>00:15:37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00:03:42</td>\n",
       "      <td>00:03:13</td>\n",
       "      <td>00:02:43</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            71  \\\n",
       "number                                                                      71   \n",
       "value                                                                 0.974547   \n",
       "datetime_start                                      2023-01-09 13:51:44.689671   \n",
       "datetime_complete                                   2023-01-09 13:55:06.312907   \n",
       "duration                                                0 days 00:03:21.623236   \n",
       "params_act                                                          leaky_relu   \n",
       "params_add_self_loops                                                    False   \n",
       "params_bias                                                               True   \n",
       "params_gnn_aggr                                                            max   \n",
       "params_hidden_channels_log2                                                  8   \n",
       "params_jk                                                                 none   \n",
       "params_num_layers                                                            4   \n",
       "params_to_hetero_aggr                                                      min   \n",
       "user_attrs_acc                                                        0.930924   \n",
       "user_attrs_aprc                                                       0.974547   \n",
       "user_attrs_aprc_history      [0.08378168940544128, 0.05609657242894173, 0.0...   \n",
       "user_attrs_auc                                                        0.997689   \n",
       "user_attrs_best_epoch                                                    186.0   \n",
       "user_attrs_f1                                                         0.798246   \n",
       "user_attrs_learning_rate                                                  0.01   \n",
       "user_attrs_loss                                                       0.089603   \n",
       "user_attrs_n_hidden                                                        256   \n",
       "user_attrs_precision                                                  0.664234   \n",
       "user_attrs_recall                                                          1.0   \n",
       "user_attrs_total_epochs                                                  386.0   \n",
       "user_attrs_training_time                                                   NaN   \n",
       "state                                                                 COMPLETE   \n",
       "\n",
       "                                                                            2   \\\n",
       "number                                                                       2   \n",
       "value                                                                 0.964633   \n",
       "datetime_start                                      2023-01-08 23:45:58.579411   \n",
       "datetime_complete                                   2023-01-09 00:01:36.145491   \n",
       "duration                                                0 days 00:15:37.566080   \n",
       "params_act                                                                gelu   \n",
       "params_add_self_loops                                                     True   \n",
       "params_bias                                                              False   \n",
       "params_gnn_aggr                                                            max   \n",
       "params_hidden_channels_log2                                                  8   \n",
       "params_jk                                                                 last   \n",
       "params_num_layers                                                            5   \n",
       "params_to_hetero_aggr                                                     mean   \n",
       "user_attrs_acc                                                        0.931325   \n",
       "user_attrs_aprc                                                       0.964633   \n",
       "user_attrs_aprc_history      [0.07739533483982086, 0.080048568546772, 0.089...   \n",
       "user_attrs_auc                                                        0.996783   \n",
       "user_attrs_best_epoch                                                    754.0   \n",
       "user_attrs_f1                                                         0.779128   \n",
       "user_attrs_learning_rate                                                  0.01   \n",
       "user_attrs_loss                                                       0.100851   \n",
       "user_attrs_n_hidden                                                        256   \n",
       "user_attrs_precision                                                  0.638921   \n",
       "user_attrs_recall                                                     0.998168   \n",
       "user_attrs_total_epochs                                                  954.0   \n",
       "user_attrs_training_time                                              00:15:37   \n",
       "state                                                                 COMPLETE   \n",
       "\n",
       "                                                                            90  \\\n",
       "number                                                                      90   \n",
       "value                                                                 0.964578   \n",
       "datetime_start                                      2023-01-09 14:37:38.644384   \n",
       "datetime_complete                                   2023-01-09 14:41:50.938074   \n",
       "duration                                                0 days 00:04:12.293690   \n",
       "params_act                                                                gelu   \n",
       "params_add_self_loops                                                    False   \n",
       "params_bias                                                               True   \n",
       "params_gnn_aggr                                                            min   \n",
       "params_hidden_channels_log2                                                  7   \n",
       "params_jk                                                                 none   \n",
       "params_num_layers                                                            4   \n",
       "params_to_hetero_aggr                                                      min   \n",
       "user_attrs_acc                                                        0.930388   \n",
       "user_attrs_aprc                                                       0.964578   \n",
       "user_attrs_aprc_history      [0.08926263451576233, 0.06005857139825821, 0.0...   \n",
       "user_attrs_auc                                                         0.99633   \n",
       "user_attrs_best_epoch                                                    857.0   \n",
       "user_attrs_f1                                                         0.784737   \n",
       "user_attrs_learning_rate                                                  0.01   \n",
       "user_attrs_loss                                                       0.150573   \n",
       "user_attrs_n_hidden                                                        128   \n",
       "user_attrs_precision                                                  0.646501   \n",
       "user_attrs_recall                                                     0.998168   \n",
       "user_attrs_total_epochs                                                 1057.0   \n",
       "user_attrs_training_time                                                   NaN   \n",
       "state                                                                 COMPLETE   \n",
       "\n",
       "                                                                            57  \\\n",
       "number                                                                      57   \n",
       "value                                                                 0.953541   \n",
       "datetime_start                                      2023-01-09 13:03:53.627998   \n",
       "datetime_complete                                   2023-01-09 13:07:27.693139   \n",
       "duration                                                0 days 00:03:34.065141   \n",
       "params_act                                                                relu   \n",
       "params_add_self_loops                                                     True   \n",
       "params_bias                                                               True   \n",
       "params_gnn_aggr                                                            min   \n",
       "params_hidden_channels_log2                                                  7   \n",
       "params_jk                                                                 none   \n",
       "params_num_layers                                                            5   \n",
       "params_to_hetero_aggr                                                      min   \n",
       "user_attrs_acc                                                        0.928916   \n",
       "user_attrs_aprc                                                       0.953541   \n",
       "user_attrs_aprc_history      [0.10039807856082916, 0.09880204498767853, 0.1...   \n",
       "user_attrs_auc                                                        0.995127   \n",
       "user_attrs_best_epoch                                                    401.0   \n",
       "user_attrs_f1                                                         0.762771   \n",
       "user_attrs_learning_rate                                                  0.01   \n",
       "user_attrs_loss                                                        0.15866   \n",
       "user_attrs_n_hidden                                                        128   \n",
       "user_attrs_precision                                                  0.617214   \n",
       "user_attrs_recall                                                     0.998168   \n",
       "user_attrs_total_epochs                                                  601.0   \n",
       "user_attrs_training_time                                                   NaN   \n",
       "state                                                                 COMPLETE   \n",
       "\n",
       "                                                                            65  \\\n",
       "number                                                                      65   \n",
       "value                                                                 0.890489   \n",
       "datetime_start                                      2023-01-09 13:38:23.969175   \n",
       "datetime_complete                                   2023-01-09 13:40:37.164632   \n",
       "duration                                                0 days 00:02:13.195457   \n",
       "params_act                                                          leaky_relu   \n",
       "params_add_self_loops                                                    False   \n",
       "params_bias                                                               True   \n",
       "params_gnn_aggr                                                            min   \n",
       "params_hidden_channels_log2                                                  7   \n",
       "params_jk                                                                 none   \n",
       "params_num_layers                                                            4   \n",
       "params_to_hetero_aggr                                                      min   \n",
       "user_attrs_acc                                                        0.931325   \n",
       "user_attrs_aprc                                                       0.890489   \n",
       "user_attrs_aprc_history      [0.08270087838172913, 0.0893382802605629, 0.08...   \n",
       "user_attrs_auc                                                        0.984969   \n",
       "user_attrs_best_epoch                                                    356.0   \n",
       "user_attrs_f1                                                         0.721358   \n",
       "user_attrs_learning_rate                                                  0.01   \n",
       "user_attrs_loss                                                       0.322625   \n",
       "user_attrs_n_hidden                                                        128   \n",
       "user_attrs_precision                                                  0.587558   \n",
       "user_attrs_recall                                                     0.934066   \n",
       "user_attrs_total_epochs                                                  556.0   \n",
       "user_attrs_training_time                                                   NaN   \n",
       "state                                                                 COMPLETE   \n",
       "\n",
       "                                                                            92  \\\n",
       "number                                                                      92   \n",
       "value                                                                 0.846144   \n",
       "datetime_start                                      2023-01-09 14:43:26.845169   \n",
       "datetime_complete                                   2023-01-09 14:45:21.441809   \n",
       "duration                                                0 days 00:01:54.596640   \n",
       "params_act                                                                gelu   \n",
       "params_add_self_loops                                                    False   \n",
       "params_bias                                                               True   \n",
       "params_gnn_aggr                                                            min   \n",
       "params_hidden_channels_log2                                                  6   \n",
       "params_jk                                                                 none   \n",
       "params_num_layers                                                            4   \n",
       "params_to_hetero_aggr                                                      min   \n",
       "user_attrs_acc                                                        0.927041   \n",
       "user_attrs_aprc                                                       0.846144   \n",
       "user_attrs_aprc_history      [0.09540335834026337, 0.1048639714717865, 0.09...   \n",
       "user_attrs_auc                                                        0.980221   \n",
       "user_attrs_best_epoch                                                    680.0   \n",
       "user_attrs_f1                                                         0.667086   \n",
       "user_attrs_learning_rate                                                  0.01   \n",
       "user_attrs_loss                                                       0.441667   \n",
       "user_attrs_n_hidden                                                         64   \n",
       "user_attrs_precision                                                   0.50815   \n",
       "user_attrs_recall                                                     0.970696   \n",
       "user_attrs_total_epochs                                                  880.0   \n",
       "user_attrs_training_time                                                   NaN   \n",
       "state                                                                 COMPLETE   \n",
       "\n",
       "                                                                            42  \\\n",
       "number                                                                      42   \n",
       "value                                                                 0.804536   \n",
       "datetime_start                                      2023-01-09 01:23:31.508692   \n",
       "datetime_complete                                   2023-01-09 01:27:14.505445   \n",
       "duration                                                0 days 00:03:42.996753   \n",
       "params_act                                                          leaky_relu   \n",
       "params_add_self_loops                                                    False   \n",
       "params_bias                                                               True   \n",
       "params_gnn_aggr                                                           mean   \n",
       "params_hidden_channels_log2                                                  8   \n",
       "params_jk                                                                 none   \n",
       "params_num_layers                                                            3   \n",
       "params_to_hetero_aggr                                                      min   \n",
       "user_attrs_acc                                                        0.927845   \n",
       "user_attrs_aprc                                                       0.804536   \n",
       "user_attrs_aprc_history      [0.09267298877239227, 0.10853002965450287, 0.0...   \n",
       "user_attrs_auc                                                        0.948339   \n",
       "user_attrs_best_epoch                                                    673.0   \n",
       "user_attrs_f1                                                          0.72404   \n",
       "user_attrs_learning_rate                                                  0.01   \n",
       "user_attrs_loss                                                       1.588745   \n",
       "user_attrs_n_hidden                                                        256   \n",
       "user_attrs_precision                                                   0.59186   \n",
       "user_attrs_recall                                                     0.932234   \n",
       "user_attrs_total_epochs                                                  873.0   \n",
       "user_attrs_training_time                                              00:03:42   \n",
       "state                                                                 COMPLETE   \n",
       "\n",
       "                                                                            22  \\\n",
       "number                                                                      22   \n",
       "value                                                                 0.798571   \n",
       "datetime_start                                      2023-01-09 00:31:55.916797   \n",
       "datetime_complete                                   2023-01-09 00:35:09.474524   \n",
       "duration                                                0 days 00:03:13.557727   \n",
       "params_act                                                          leaky_relu   \n",
       "params_add_self_loops                                                    False   \n",
       "params_bias                                                               True   \n",
       "params_gnn_aggr                                                           mean   \n",
       "params_hidden_channels_log2                                                  8   \n",
       "params_jk                                                                 none   \n",
       "params_num_layers                                                            3   \n",
       "params_to_hetero_aggr                                                      min   \n",
       "user_attrs_acc                                                        0.927577   \n",
       "user_attrs_aprc                                                       0.798571   \n",
       "user_attrs_aprc_history      [0.08961427211761475, 0.10988513380289078, 0.0...   \n",
       "user_attrs_auc                                                        0.949581   \n",
       "user_attrs_best_epoch                                                    559.0   \n",
       "user_attrs_f1                                                         0.712271   \n",
       "user_attrs_learning_rate                                                  0.01   \n",
       "user_attrs_loss                                                       1.409402   \n",
       "user_attrs_n_hidden                                                        256   \n",
       "user_attrs_precision                                                  0.579128   \n",
       "user_attrs_recall                                                     0.924908   \n",
       "user_attrs_total_epochs                                                  759.0   \n",
       "user_attrs_training_time                                              00:03:13   \n",
       "state                                                                 COMPLETE   \n",
       "\n",
       "                                                                            25  \\\n",
       "number                                                                      25   \n",
       "value                                                                 0.772965   \n",
       "datetime_start                                      2023-01-09 00:38:23.500434   \n",
       "datetime_complete                                   2023-01-09 00:41:06.815786   \n",
       "duration                                                0 days 00:02:43.315352   \n",
       "params_act                                                          leaky_relu   \n",
       "params_add_self_loops                                                    False   \n",
       "params_bias                                                               True   \n",
       "params_gnn_aggr                                                           mean   \n",
       "params_hidden_channels_log2                                                  8   \n",
       "params_jk                                                                 none   \n",
       "params_num_layers                                                            4   \n",
       "params_to_hetero_aggr                                                      min   \n",
       "user_attrs_acc                                                        0.928648   \n",
       "user_attrs_aprc                                                       0.772965   \n",
       "user_attrs_aprc_history      [0.09363724291324615, 0.09883667528629303, 0.0...   \n",
       "user_attrs_auc                                                        0.940571   \n",
       "user_attrs_best_epoch                                                    206.0   \n",
       "user_attrs_f1                                                         0.669328   \n",
       "user_attrs_learning_rate                                                  0.01   \n",
       "user_attrs_loss                                                       1.935887   \n",
       "user_attrs_n_hidden                                                        256   \n",
       "user_attrs_precision                                                  0.525601   \n",
       "user_attrs_recall                                                     0.921245   \n",
       "user_attrs_total_epochs                                                  406.0   \n",
       "user_attrs_training_time                                              00:02:43   \n",
       "state                                                                 COMPLETE   \n",
       "\n",
       "                                                                            56  \n",
       "number                                                                      56  \n",
       "value                                                                 0.749134  \n",
       "datetime_start                                      2023-01-09 12:59:41.820345  \n",
       "datetime_complete                                   2023-01-09 13:03:53.590702  \n",
       "duration                                                0 days 00:04:11.770357  \n",
       "params_act                                                          leaky_relu  \n",
       "params_add_self_loops                                                    False  \n",
       "params_bias                                                               True  \n",
       "params_gnn_aggr                                                           mean  \n",
       "params_hidden_channels_log2                                                  8  \n",
       "params_jk                                                                 none  \n",
       "params_num_layers                                                            5  \n",
       "params_to_hetero_aggr                                                      min  \n",
       "user_attrs_acc                                                        0.928648  \n",
       "user_attrs_aprc                                                       0.749134  \n",
       "user_attrs_aprc_history      [0.10130488872528076, 0.10246395319700241, 0.1...  \n",
       "user_attrs_auc                                                        0.941333  \n",
       "user_attrs_best_epoch                                                    251.0  \n",
       "user_attrs_f1                                                          0.68599  \n",
       "user_attrs_learning_rate                                                  0.01  \n",
       "user_attrs_loss                                                       2.761004  \n",
       "user_attrs_n_hidden                                                        256  \n",
       "user_attrs_precision                                                  0.550388  \n",
       "user_attrs_recall                                                     0.910256  \n",
       "user_attrs_total_epochs                                                  451.0  \n",
       "user_attrs_training_time                                                   NaN  \n",
       "state                                                                 COMPLETE  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.trials_dataframe().sort_values(\"value\", ascending=False)[:10].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09b4769d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'act': 'leaky_relu',\n",
       "  'add_self_loops': False,\n",
       "  'bias': True,\n",
       "  'gnn_aggr': 'max',\n",
       "  'hidden_channels_log2': 8,\n",
       "  'jk': 'none',\n",
       "  'num_layers': 4,\n",
       "  'to_hetero_aggr': 'min'},\n",
       " {'acc': 0.9309237003326416,\n",
       "  'aprc': 0.9745465517044067,\n",
       "  'aprc_history': [0.08378168940544128,\n",
       "   0.05609657242894173,\n",
       "   0.06113765388727188,\n",
       "   0.10603241622447968,\n",
       "   0.11127810180187225,\n",
       "   0.11036204546689987,\n",
       "   0.10628073662519455,\n",
       "   0.09745337069034576,\n",
       "   0.09453783929347992,\n",
       "   0.10052155703306198,\n",
       "   0.11373697966337204,\n",
       "   0.12952886521816254,\n",
       "   0.1178245022892952,\n",
       "   0.15287569165229797,\n",
       "   0.16045233607292175,\n",
       "   0.17180752754211426,\n",
       "   0.15863114595413208,\n",
       "   0.1991516649723053,\n",
       "   0.222223162651062,\n",
       "   0.2511574327945709,\n",
       "   0.2615694999694824,\n",
       "   0.24503661692142487,\n",
       "   0.33745962381362915,\n",
       "   0.29018062353134155,\n",
       "   0.2849925756454468,\n",
       "   0.3031104803085327,\n",
       "   0.4120880365371704,\n",
       "   0.4282169044017792,\n",
       "   0.41041746735572815,\n",
       "   0.4452163279056549,\n",
       "   0.4496076703071594,\n",
       "   0.4592607319355011,\n",
       "   0.5381366610527039,\n",
       "   0.5367771983146667,\n",
       "   0.5403066873550415,\n",
       "   0.5802596211433411,\n",
       "   0.5135948657989502,\n",
       "   0.5547066330909729,\n",
       "   0.5828062295913696,\n",
       "   0.5758428573608398,\n",
       "   0.636320173740387,\n",
       "   0.6050524711608887,\n",
       "   0.6368228793144226,\n",
       "   0.6266875863075256,\n",
       "   0.6790778040885925,\n",
       "   0.6808006763458252,\n",
       "   0.6921828985214233,\n",
       "   0.7154231071472168,\n",
       "   0.7223482131958008,\n",
       "   0.7239585518836975,\n",
       "   0.7468473315238953,\n",
       "   0.7423714995384216,\n",
       "   0.7095706462860107,\n",
       "   0.7187294960021973,\n",
       "   0.701946496963501,\n",
       "   0.6685253977775574,\n",
       "   0.6746786236763,\n",
       "   0.7027553915977478,\n",
       "   0.6844801902770996,\n",
       "   0.7208927869796753,\n",
       "   0.6626729965209961,\n",
       "   0.6691762804985046,\n",
       "   0.7107092142105103,\n",
       "   0.7129679918289185,\n",
       "   0.7233364582061768,\n",
       "   0.7482967376708984,\n",
       "   0.7565539479255676,\n",
       "   0.7586519122123718,\n",
       "   0.761980414390564,\n",
       "   0.776875913143158,\n",
       "   0.7927799224853516,\n",
       "   0.8000285625457764,\n",
       "   0.8061153888702393,\n",
       "   0.8097981214523315,\n",
       "   0.8235149383544922,\n",
       "   0.8352124094963074,\n",
       "   0.8364468216896057,\n",
       "   0.8485282063484192,\n",
       "   0.852916419506073,\n",
       "   0.8542563915252686,\n",
       "   0.8664587736129761,\n",
       "   0.8670817613601685,\n",
       "   0.8783296346664429,\n",
       "   0.8849488496780396,\n",
       "   0.886677622795105,\n",
       "   0.895021915435791,\n",
       "   0.8821429014205933,\n",
       "   0.8693006634712219,\n",
       "   0.872012734413147,\n",
       "   0.8874919414520264,\n",
       "   0.8841824531555176,\n",
       "   0.8921735286712646,\n",
       "   0.903165340423584,\n",
       "   0.8985670804977417,\n",
       "   0.903755784034729,\n",
       "   0.9026191234588623,\n",
       "   0.9022588729858398,\n",
       "   0.8994636535644531,\n",
       "   0.9001274704933167,\n",
       "   0.8982210159301758,\n",
       "   0.8788655996322632,\n",
       "   0.8823747634887695,\n",
       "   0.8700831532478333,\n",
       "   0.8558641672134399,\n",
       "   0.8690454363822937,\n",
       "   0.8389104008674622,\n",
       "   0.8444875478744507,\n",
       "   0.8568928241729736,\n",
       "   0.8824228048324585,\n",
       "   0.8773214817047119,\n",
       "   0.8782912492752075,\n",
       "   0.8756126761436462,\n",
       "   0.8931014537811279,\n",
       "   0.8957064151763916,\n",
       "   0.8962557315826416,\n",
       "   0.8994101285934448,\n",
       "   0.907559871673584,\n",
       "   0.9118914604187012,\n",
       "   0.9129606485366821,\n",
       "   0.9133535623550415,\n",
       "   0.9166741967201233,\n",
       "   0.9208464622497559,\n",
       "   0.9228023290634155,\n",
       "   0.9268097877502441,\n",
       "   0.9333655834197998,\n",
       "   0.9373326301574707,\n",
       "   0.9387643337249756,\n",
       "   0.9405914545059204,\n",
       "   0.943702220916748,\n",
       "   0.9464222192764282,\n",
       "   0.9480868577957153,\n",
       "   0.9493749141693115,\n",
       "   0.9502983093261719,\n",
       "   0.9519646763801575,\n",
       "   0.9528913497924805,\n",
       "   0.9549635648727417,\n",
       "   0.9555566310882568,\n",
       "   0.9562713503837585,\n",
       "   0.9575996994972229,\n",
       "   0.957247257232666,\n",
       "   0.9582363367080688,\n",
       "   0.9579639434814453,\n",
       "   0.9554443359375,\n",
       "   0.955345630645752,\n",
       "   0.9581972360610962,\n",
       "   0.9575914144515991,\n",
       "   0.9577934741973877,\n",
       "   0.9589682221412659,\n",
       "   0.9592520594596863,\n",
       "   0.9564048051834106,\n",
       "   0.9553287029266357,\n",
       "   0.9582774639129639,\n",
       "   0.9582284688949585,\n",
       "   0.9568769335746765,\n",
       "   0.9514588713645935,\n",
       "   0.9548892974853516,\n",
       "   0.9529134631156921,\n",
       "   0.949910044670105,\n",
       "   0.947085976600647,\n",
       "   0.9492995142936707,\n",
       "   0.9438762664794922,\n",
       "   0.9431322813034058,\n",
       "   0.9323476552963257,\n",
       "   0.9446349740028381,\n",
       "   0.9421276450157166,\n",
       "   0.9481236934661865,\n",
       "   0.9431426525115967,\n",
       "   0.9512377977371216,\n",
       "   0.9506634473800659,\n",
       "   0.9533172249794006,\n",
       "   0.9545729160308838,\n",
       "   0.9546551704406738,\n",
       "   0.9574517011642456,\n",
       "   0.9574196338653564,\n",
       "   0.9574060440063477,\n",
       "   0.9580696821212769,\n",
       "   0.9585315585136414,\n",
       "   0.9605656266212463,\n",
       "   0.9618207216262817,\n",
       "   0.9614515900611877,\n",
       "   0.9625186920166016,\n",
       "   0.9630743265151978,\n",
       "   0.9639481902122498,\n",
       "   0.964339017868042,\n",
       "   0.9647008776664734,\n",
       "   0.9654221534729004,\n",
       "   0.965447187423706,\n",
       "   0.9657708406448364,\n",
       "   0.966223955154419,\n",
       "   0.9654492139816284,\n",
       "   0.9660406112670898,\n",
       "   0.9652067422866821,\n",
       "   0.9599183797836304,\n",
       "   0.9600688219070435,\n",
       "   0.9482722282409668,\n",
       "   0.958987832069397,\n",
       "   0.95067298412323,\n",
       "   0.9266253709793091,\n",
       "   0.9158806800842285,\n",
       "   0.9272785186767578,\n",
       "   0.9249522686004639,\n",
       "   0.8965168595314026,\n",
       "   0.9117714166641235,\n",
       "   0.9125298261642456,\n",
       "   0.9183489084243774,\n",
       "   0.9242896437644958,\n",
       "   0.9251790046691895,\n",
       "   0.9274141788482666,\n",
       "   0.9338628053665161,\n",
       "   0.9424117803573608,\n",
       "   0.9475113749504089,\n",
       "   0.947975218296051,\n",
       "   0.947823166847229,\n",
       "   0.9503286480903625,\n",
       "   0.9525279402732849,\n",
       "   0.955707311630249,\n",
       "   0.960290253162384,\n",
       "   0.9617084264755249,\n",
       "   0.9620698690414429,\n",
       "   0.9584046602249146,\n",
       "   0.9582763910293579,\n",
       "   0.9595212936401367,\n",
       "   0.9617187976837158,\n",
       "   0.9635352492332458,\n",
       "   0.9652718305587769,\n",
       "   0.9660080671310425,\n",
       "   0.9667320251464844,\n",
       "   0.9660812616348267,\n",
       "   0.9669682383537292,\n",
       "   0.967761754989624,\n",
       "   0.967737078666687,\n",
       "   0.9670171737670898,\n",
       "   0.9681600332260132,\n",
       "   0.9670226573944092,\n",
       "   0.9669473767280579,\n",
       "   0.9659048318862915,\n",
       "   0.9655669927597046,\n",
       "   0.9627857208251953,\n",
       "   0.9664062261581421,\n",
       "   0.9637802839279175,\n",
       "   0.9662591218948364,\n",
       "   0.965735673904419,\n",
       "   0.9667397737503052,\n",
       "   0.9662525653839111,\n",
       "   0.9657312631607056,\n",
       "   0.9656013250350952,\n",
       "   0.9659795165061951,\n",
       "   0.9649612903594971,\n",
       "   0.965499997138977,\n",
       "   0.9656957983970642,\n",
       "   0.9644056558609009,\n",
       "   0.9649258852005005,\n",
       "   0.9645888209342957,\n",
       "   0.964651882648468,\n",
       "   0.9652860164642334,\n",
       "   0.9636144042015076,\n",
       "   0.963600218296051,\n",
       "   0.9597823023796082,\n",
       "   0.9623571634292603,\n",
       "   0.9608249068260193,\n",
       "   0.9640611410140991,\n",
       "   0.9632387161254883,\n",
       "   0.9649016857147217,\n",
       "   0.9658639430999756,\n",
       "   0.9668619632720947,\n",
       "   0.9658466577529907,\n",
       "   0.9666903614997864,\n",
       "   0.9654234051704407,\n",
       "   0.9664629697799683,\n",
       "   0.9651661515235901,\n",
       "   0.9670255184173584,\n",
       "   0.9658172726631165,\n",
       "   0.9672304391860962,\n",
       "   0.9651577472686768,\n",
       "   0.9682649374008179,\n",
       "   0.9669815301895142,\n",
       "   0.9683023691177368,\n",
       "   0.9655380249023438,\n",
       "   0.9670877456665039,\n",
       "   0.9665654897689819,\n",
       "   0.968193769454956,\n",
       "   0.9650869369506836,\n",
       "   0.9670671224594116,\n",
       "   0.9651308059692383,\n",
       "   0.9652401208877563,\n",
       "   0.9609123468399048,\n",
       "   0.9663436412811279,\n",
       "   0.9647588133811951,\n",
       "   0.9662632942199707,\n",
       "   0.9616818428039551,\n",
       "   0.9654067158699036,\n",
       "   0.9654043912887573,\n",
       "   0.9680504202842712,\n",
       "   0.9621363282203674,\n",
       "   0.9663084745407104,\n",
       "   0.9627577066421509,\n",
       "   0.9666193723678589,\n",
       "   0.9670488834381104,\n",
       "   0.9682751893997192,\n",
       "   0.9665337800979614,\n",
       "   0.967372477054596,\n",
       "   0.9673503637313843,\n",
       "   0.9684495329856873,\n",
       "   0.9692995548248291,\n",
       "   0.9682718515396118,\n",
       "   0.9684395790100098,\n",
       "   0.9702208042144775,\n",
       "   0.971286416053772,\n",
       "   0.9710738658905029,\n",
       "   0.9706991910934448,\n",
       "   0.9711948037147522,\n",
       "   0.9715486764907837,\n",
       "   0.9717949628829956,\n",
       "   0.9718421697616577,\n",
       "   0.972373366355896,\n",
       "   0.9726943969726562,\n",
       "   0.9720546007156372,\n",
       "   0.9730807542800903,\n",
       "   0.9711719155311584,\n",
       "   0.9694775938987732,\n",
       "   0.968224048614502,\n",
       "   0.9692949056625366,\n",
       "   0.9671028852462769,\n",
       "   0.9649916291236877,\n",
       "   0.9638180732727051,\n",
       "   0.9602445363998413,\n",
       "   0.9622195959091187,\n",
       "   0.9609082937240601,\n",
       "   0.9614436030387878,\n",
       "   0.9653048515319824,\n",
       "   0.9639742374420166,\n",
       "   0.9655454158782959,\n",
       "   0.9683736562728882,\n",
       "   0.9685180187225342,\n",
       "   0.9699686765670776,\n",
       "   0.9700149893760681,\n",
       "   0.9719163179397583,\n",
       "   0.9710060358047485,\n",
       "   0.9707356691360474,\n",
       "   0.9713874459266663,\n",
       "   0.9716938734054565,\n",
       "   0.9727237224578857,\n",
       "   0.9736461043357849,\n",
       "   0.9727017283439636,\n",
       "   0.9729844927787781,\n",
       "   0.9732959270477295,\n",
       "   0.9742373824119568,\n",
       "   0.9739619493484497,\n",
       "   0.9738795757293701,\n",
       "   0.9740509986877441,\n",
       "   0.9742895364761353,\n",
       "   0.9731323719024658,\n",
       "   0.9722025394439697,\n",
       "   0.9712578654289246,\n",
       "   0.9716297388076782,\n",
       "   0.9693990349769592,\n",
       "   0.9694791436195374,\n",
       "   0.9678207039833069,\n",
       "   0.9713255167007446,\n",
       "   0.9701547622680664,\n",
       "   0.9697507619857788,\n",
       "   0.9682918787002563,\n",
       "   0.9683626890182495,\n",
       "   0.9681626558303833,\n",
       "   0.9695941805839539,\n",
       "   0.9700661301612854,\n",
       "   0.970371663570404,\n",
       "   0.9711538553237915,\n",
       "   0.9714046120643616,\n",
       "   0.9729517698287964,\n",
       "   0.9734405279159546,\n",
       "   0.9730710983276367,\n",
       "   0.97409987449646,\n",
       "   0.9739996194839478,\n",
       "   0.9737454056739807,\n",
       "   0.9740533232688904,\n",
       "   0.9742451906204224,\n",
       "   0.9743905663490295,\n",
       "   0.9736016988754272,\n",
       "   0.9745465517044067,\n",
       "   0.9727154970169067,\n",
       "   0.9714674949645996,\n",
       "   0.9700644612312317,\n",
       "   0.9695525765419006,\n",
       "   0.9679975509643555,\n",
       "   0.9695234298706055],\n",
       "  'auc': 0.997688889503479,\n",
       "  'best_epoch': 186,\n",
       "  'f1': 0.7982456088066101,\n",
       "  'learning_rate': 0.01,\n",
       "  'loss': 0.08960308879613876,\n",
       "  'n_hidden': 256,\n",
       "  'precision': 0.6642335653305054,\n",
       "  'recall': 1.0,\n",
       "  'total_epochs': 386})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_best_trial(\"GraphSAGE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b12cec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'act': 'gelu',\n",
       "  'add_self_loops': False,\n",
       "  'bias': True,\n",
       "  'gnn_aggr': 'max',\n",
       "  'hidden_channels_log2': 8,\n",
       "  'jk': 'last',\n",
       "  'num_layers': 3,\n",
       "  'to_hetero_aggr': 'min'},\n",
       " {'acc': 0.9291834235191345,\n",
       "  'aprc': 0.9709917306900024,\n",
       "  'aprc_history': [0.08662247657775879,\n",
       "   0.05535983294248581,\n",
       "   0.07431593537330627,\n",
       "   0.09581813216209412,\n",
       "   0.08236677944660187,\n",
       "   0.08700983971357346,\n",
       "   0.09674164652824402,\n",
       "   0.09904752671718597,\n",
       "   0.09727895259857178,\n",
       "   0.10366372764110565,\n",
       "   0.11654387414455414,\n",
       "   0.12331970781087875,\n",
       "   0.13008642196655273,\n",
       "   0.1216675266623497,\n",
       "   0.141188383102417,\n",
       "   0.1429957002401352,\n",
       "   0.13772374391555786,\n",
       "   0.13665030896663666,\n",
       "   0.16232596337795258,\n",
       "   0.15622681379318237,\n",
       "   0.1951773464679718,\n",
       "   0.17062173783779144,\n",
       "   0.21084186434745789,\n",
       "   0.23359593749046326,\n",
       "   0.23868553340435028,\n",
       "   0.2407713681459427,\n",
       "   0.29477977752685547,\n",
       "   0.29266539216041565,\n",
       "   0.30065950751304626,\n",
       "   0.3373481035232544,\n",
       "   0.31420618295669556,\n",
       "   0.2984260320663452,\n",
       "   0.34092456102371216,\n",
       "   0.2987310290336609,\n",
       "   0.28752779960632324,\n",
       "   0.28113245964050293,\n",
       "   0.23530063033103943,\n",
       "   0.26995325088500977,\n",
       "   0.2834216356277466,\n",
       "   0.2722892761230469,\n",
       "   0.28840237855911255,\n",
       "   0.32017892599105835,\n",
       "   0.29400634765625,\n",
       "   0.2684246301651001,\n",
       "   0.304105281829834,\n",
       "   0.3136395812034607,\n",
       "   0.30384552478790283,\n",
       "   0.34895583987236023,\n",
       "   0.3703838288784027,\n",
       "   0.3504384756088257,\n",
       "   0.40329545736312866,\n",
       "   0.4214555025100708,\n",
       "   0.40835943818092346,\n",
       "   0.4653991460800171,\n",
       "   0.45599842071533203,\n",
       "   0.48975318670272827,\n",
       "   0.4993564188480377,\n",
       "   0.5149372816085815,\n",
       "   0.5338115692138672,\n",
       "   0.5241478681564331,\n",
       "   0.5554975271224976,\n",
       "   0.45268839597702026,\n",
       "   0.5664914846420288,\n",
       "   0.2940085232257843,\n",
       "   0.5251023769378662,\n",
       "   0.5646945238113403,\n",
       "   0.5951328277587891,\n",
       "   0.4725329279899597,\n",
       "   0.5528905987739563,\n",
       "   0.6176354289054871,\n",
       "   0.6300032138824463,\n",
       "   0.6458992958068848,\n",
       "   0.6567039489746094,\n",
       "   0.6127070188522339,\n",
       "   0.6334543228149414,\n",
       "   0.5791873335838318,\n",
       "   0.5939385890960693,\n",
       "   0.6440005898475647,\n",
       "   0.6717087626457214,\n",
       "   0.6403433084487915,\n",
       "   0.679594874382019,\n",
       "   0.6813294291496277,\n",
       "   0.6671514511108398,\n",
       "   0.6977541446685791,\n",
       "   0.7258995771408081,\n",
       "   0.7268738150596619,\n",
       "   0.7234302759170532,\n",
       "   0.7354856729507446,\n",
       "   0.7676621675491333,\n",
       "   0.7765944004058838,\n",
       "   0.7903642654418945,\n",
       "   0.7927414774894714,\n",
       "   0.7909244298934937,\n",
       "   0.8081465363502502,\n",
       "   0.8198779821395874,\n",
       "   0.8268851041793823,\n",
       "   0.828101396560669,\n",
       "   0.8366752862930298,\n",
       "   0.847142219543457,\n",
       "   0.8523169755935669,\n",
       "   0.8634505271911621,\n",
       "   0.8655772805213928,\n",
       "   0.8672243356704712,\n",
       "   0.8739277124404907,\n",
       "   0.874791145324707,\n",
       "   0.883414089679718,\n",
       "   0.8784233331680298,\n",
       "   0.8434085845947266,\n",
       "   0.8610032796859741,\n",
       "   0.7589942812919617,\n",
       "   0.8433026075363159,\n",
       "   0.7801830172538757,\n",
       "   0.5666516423225403,\n",
       "   0.5825912952423096,\n",
       "   0.6116328835487366,\n",
       "   0.6301095485687256,\n",
       "   0.5641756057739258,\n",
       "   0.6193415522575378,\n",
       "   0.6210810542106628,\n",
       "   0.6924540996551514,\n",
       "   0.6784743070602417,\n",
       "   0.6762150526046753,\n",
       "   0.6914287805557251,\n",
       "   0.7255563139915466,\n",
       "   0.7443146705627441,\n",
       "   0.7596588134765625,\n",
       "   0.7629485130310059,\n",
       "   0.769310712814331,\n",
       "   0.7830724716186523,\n",
       "   0.7892617583274841,\n",
       "   0.7969316244125366,\n",
       "   0.8066793084144592,\n",
       "   0.815025269985199,\n",
       "   0.8282959461212158,\n",
       "   0.8394387364387512,\n",
       "   0.8459045886993408,\n",
       "   0.8518174290657043,\n",
       "   0.8572909832000732,\n",
       "   0.8620079755783081,\n",
       "   0.8656593561172485,\n",
       "   0.8692163228988647,\n",
       "   0.8744333386421204,\n",
       "   0.8803274631500244,\n",
       "   0.886776328086853,\n",
       "   0.8911672830581665,\n",
       "   0.8953686952590942,\n",
       "   0.8990364074707031,\n",
       "   0.9028588533401489,\n",
       "   0.9069795608520508,\n",
       "   0.910586953163147,\n",
       "   0.9137366414070129,\n",
       "   0.9157184362411499,\n",
       "   0.9176390171051025,\n",
       "   0.9195375442504883,\n",
       "   0.9224751591682434,\n",
       "   0.9246945381164551,\n",
       "   0.9261707067489624,\n",
       "   0.9280154705047607,\n",
       "   0.929528534412384,\n",
       "   0.9315603375434875,\n",
       "   0.933570146560669,\n",
       "   0.934821605682373,\n",
       "   0.9351867437362671,\n",
       "   0.9362818002700806,\n",
       "   0.9373875856399536,\n",
       "   0.9378858208656311,\n",
       "   0.938605785369873,\n",
       "   0.939196765422821,\n",
       "   0.9400018453598022,\n",
       "   0.9408160448074341,\n",
       "   0.9412441253662109,\n",
       "   0.9417471885681152,\n",
       "   0.9422154426574707,\n",
       "   0.9425610303878784,\n",
       "   0.9430294036865234,\n",
       "   0.9436187744140625,\n",
       "   0.9440681338310242,\n",
       "   0.9439510107040405,\n",
       "   0.9446804523468018,\n",
       "   0.9432670474052429,\n",
       "   0.9441930055618286,\n",
       "   0.9378950595855713,\n",
       "   0.9436208605766296,\n",
       "   0.9431769847869873,\n",
       "   0.9439215660095215,\n",
       "   0.9423116445541382,\n",
       "   0.943917989730835,\n",
       "   0.9435696005821228,\n",
       "   0.9410605430603027,\n",
       "   0.9430892467498779,\n",
       "   0.9347975254058838,\n",
       "   0.929823637008667,\n",
       "   0.9253144264221191,\n",
       "   0.9285171031951904,\n",
       "   0.9319504499435425,\n",
       "   0.9286052584648132,\n",
       "   0.9309977293014526,\n",
       "   0.9340909719467163,\n",
       "   0.9362553358078003,\n",
       "   0.9346514344215393,\n",
       "   0.9376765489578247,\n",
       "   0.936652421951294,\n",
       "   0.9383429884910583,\n",
       "   0.9396149516105652,\n",
       "   0.9408799409866333,\n",
       "   0.9443353414535522,\n",
       "   0.9438750147819519,\n",
       "   0.9443796873092651,\n",
       "   0.9445064067840576,\n",
       "   0.9459603428840637,\n",
       "   0.9463208913803101,\n",
       "   0.9470667839050293,\n",
       "   0.9474037885665894,\n",
       "   0.9479694366455078,\n",
       "   0.9494646787643433,\n",
       "   0.9486597180366516,\n",
       "   0.9479783177375793,\n",
       "   0.9492413401603699,\n",
       "   0.9498072862625122,\n",
       "   0.9503687620162964,\n",
       "   0.9510608315467834,\n",
       "   0.9501333236694336,\n",
       "   0.9504668116569519,\n",
       "   0.9511103630065918,\n",
       "   0.9513011574745178,\n",
       "   0.9520986080169678,\n",
       "   0.9512921571731567,\n",
       "   0.9495742321014404,\n",
       "   0.9501025676727295,\n",
       "   0.9446404576301575,\n",
       "   0.9453321695327759,\n",
       "   0.9450778365135193,\n",
       "   0.9425773620605469,\n",
       "   0.9443453550338745,\n",
       "   0.9465497732162476,\n",
       "   0.9458786249160767,\n",
       "   0.9448727369308472,\n",
       "   0.943635106086731,\n",
       "   0.9395799040794373,\n",
       "   0.9408658146858215,\n",
       "   0.9416103363037109,\n",
       "   0.9397401213645935,\n",
       "   0.9423245787620544,\n",
       "   0.9439535737037659,\n",
       "   0.9432313442230225,\n",
       "   0.9412205219268799,\n",
       "   0.9416808485984802,\n",
       "   0.9445047378540039,\n",
       "   0.9455692172050476,\n",
       "   0.9465726613998413,\n",
       "   0.9479126930236816,\n",
       "   0.9500732421875,\n",
       "   0.9505049586296082,\n",
       "   0.9522839188575745,\n",
       "   0.9512076377868652,\n",
       "   0.9522359371185303,\n",
       "   0.9527252912521362,\n",
       "   0.9530208110809326,\n",
       "   0.9530240297317505,\n",
       "   0.9540365934371948,\n",
       "   0.9532594680786133,\n",
       "   0.9541807174682617,\n",
       "   0.9542512893676758,\n",
       "   0.9551727175712585,\n",
       "   0.955414354801178,\n",
       "   0.9546396136283875,\n",
       "   0.9551223516464233,\n",
       "   0.9551587104797363,\n",
       "   0.9547501802444458,\n",
       "   0.9537808299064636,\n",
       "   0.9534363746643066,\n",
       "   0.9495404362678528,\n",
       "   0.9517867565155029,\n",
       "   0.9477013349533081,\n",
       "   0.9499761462211609,\n",
       "   0.9496589303016663,\n",
       "   0.9476765394210815,\n",
       "   0.9464175701141357,\n",
       "   0.9429854154586792,\n",
       "   0.9416149854660034,\n",
       "   0.9476974010467529,\n",
       "   0.9426932334899902,\n",
       "   0.9462717771530151,\n",
       "   0.94673752784729,\n",
       "   0.9460657835006714,\n",
       "   0.9450836777687073,\n",
       "   0.9475892186164856,\n",
       "   0.9489538669586182,\n",
       "   0.950264573097229,\n",
       "   0.9484649896621704,\n",
       "   0.949669361114502,\n",
       "   0.9495558142662048,\n",
       "   0.9508395791053772,\n",
       "   0.9507091045379639,\n",
       "   0.952093243598938,\n",
       "   0.951488733291626,\n",
       "   0.9540048837661743,\n",
       "   0.9551154375076294,\n",
       "   0.955729603767395,\n",
       "   0.9551903009414673,\n",
       "   0.9565181732177734,\n",
       "   0.9556958675384521,\n",
       "   0.9556568264961243,\n",
       "   0.9561330080032349,\n",
       "   0.9563331604003906,\n",
       "   0.9557014107704163,\n",
       "   0.9564033150672913,\n",
       "   0.9540865421295166,\n",
       "   0.9504218697547913,\n",
       "   0.9479423761367798,\n",
       "   0.950768232345581,\n",
       "   0.9396791458129883,\n",
       "   0.9465664625167847,\n",
       "   0.939067006111145,\n",
       "   0.9481185078620911,\n",
       "   0.9308077692985535,\n",
       "   0.9411534070968628,\n",
       "   0.9396251440048218,\n",
       "   0.9392678737640381,\n",
       "   0.9393839836120605,\n",
       "   0.9418308734893799,\n",
       "   0.941643238067627,\n",
       "   0.9441990852355957,\n",
       "   0.9437094926834106,\n",
       "   0.9415073990821838,\n",
       "   0.9460499882698059,\n",
       "   0.9491636157035828,\n",
       "   0.9498214721679688,\n",
       "   0.9510472416877747,\n",
       "   0.9534099102020264,\n",
       "   0.9537252187728882,\n",
       "   0.9540982246398926,\n",
       "   0.9543941020965576,\n",
       "   0.9544348120689392,\n",
       "   0.9550440311431885,\n",
       "   0.9552087783813477,\n",
       "   0.9561734199523926,\n",
       "   0.9561655521392822,\n",
       "   0.9569437503814697,\n",
       "   0.9576572775840759,\n",
       "   0.9580748081207275,\n",
       "   0.9583629369735718,\n",
       "   0.9585875272750854,\n",
       "   0.9593228101730347,\n",
       "   0.959182858467102,\n",
       "   0.9593282341957092,\n",
       "   0.959729790687561,\n",
       "   0.9601715803146362,\n",
       "   0.9603497982025146,\n",
       "   0.9606189727783203,\n",
       "   0.9603688716888428,\n",
       "   0.9598579406738281,\n",
       "   0.9596868753433228,\n",
       "   0.954754650592804,\n",
       "   0.9602047204971313,\n",
       "   0.9584433436393738,\n",
       "   0.9596880674362183,\n",
       "   0.9553238749504089,\n",
       "   0.9585731029510498,\n",
       "   0.9586459398269653,\n",
       "   0.9580867290496826,\n",
       "   0.9600551128387451,\n",
       "   0.9582892060279846,\n",
       "   0.9587485194206238,\n",
       "   0.9557673335075378,\n",
       "   0.9564915299415588,\n",
       "   0.9549508094787598,\n",
       "   0.9542759656906128,\n",
       "   0.9513705372810364,\n",
       "   0.9468454718589783,\n",
       "   0.9465810656547546,\n",
       "   0.9415825009346008,\n",
       "   0.9422747492790222,\n",
       "   0.9371330738067627,\n",
       "   0.9443955421447754,\n",
       "   0.938433051109314,\n",
       "   0.9389283657073975,\n",
       "   0.9302372932434082,\n",
       "   0.9360151886940002,\n",
       "   0.9202020168304443,\n",
       "   0.9301388263702393,\n",
       "   0.9255871176719666,\n",
       "   0.9290709495544434,\n",
       "   0.9252831935882568,\n",
       "   0.9334840178489685,\n",
       "   0.934386134147644,\n",
       "   0.9447349905967712,\n",
       "   0.9419286251068115,\n",
       "   0.945600688457489,\n",
       "   0.9416468739509583,\n",
       "   0.9458383917808533,\n",
       "   0.94603431224823,\n",
       "   0.948097288608551,\n",
       "   0.9490580558776855,\n",
       "   0.9492764472961426,\n",
       "   0.9496171474456787,\n",
       "   0.9510059952735901,\n",
       "   0.9517161846160889,\n",
       "   0.9544953107833862,\n",
       "   0.9538822770118713,\n",
       "   0.9547062516212463,\n",
       "   0.955499529838562,\n",
       "   0.9565714001655579,\n",
       "   0.9576605558395386,\n",
       "   0.9585880637168884,\n",
       "   0.959748387336731,\n",
       "   0.9602044224739075,\n",
       "   0.9608179330825806,\n",
       "   0.9603148102760315,\n",
       "   0.9604519605636597,\n",
       "   0.9610370397567749,\n",
       "   0.9614560008049011,\n",
       "   0.9620386362075806,\n",
       "   0.9624407887458801,\n",
       "   0.9624584317207336,\n",
       "   0.9624296426773071,\n",
       "   0.9629757404327393,\n",
       "   0.9634613394737244,\n",
       "   0.9632347226142883,\n",
       "   0.963432788848877,\n",
       "   0.9637855291366577,\n",
       "   0.9629883766174316,\n",
       "   0.9624592065811157,\n",
       "   0.9618962407112122,\n",
       "   0.9627707600593567,\n",
       "   0.9633305668830872,\n",
       "   0.964701771736145,\n",
       "   0.9648242592811584,\n",
       "   0.9648512005805969,\n",
       "   0.9649602174758911,\n",
       "   0.9654719233512878,\n",
       "   0.9652140736579895,\n",
       "   0.9649451971054077,\n",
       "   0.9634312391281128,\n",
       "   0.9614711999893188,\n",
       "   0.963897705078125,\n",
       "   0.9606364965438843,\n",
       "   0.9594263434410095,\n",
       "   0.9605834484100342,\n",
       "   0.9576364159584045,\n",
       "   0.9591728448867798,\n",
       "   0.9476456642150879,\n",
       "   0.9513086676597595,\n",
       "   0.9528451561927795,\n",
       "   0.95160973072052,\n",
       "   0.9526022672653198,\n",
       "   0.9549060463905334,\n",
       "   0.9557452201843262,\n",
       "   0.9574634432792664,\n",
       "   0.9584490060806274,\n",
       "   0.957802951335907,\n",
       "   0.9589226245880127,\n",
       "   0.9566852450370789,\n",
       "   0.959069013595581,\n",
       "   0.9596575498580933,\n",
       "   0.959200382232666,\n",
       "   0.9606962203979492,\n",
       "   0.9608972072601318,\n",
       "   0.9604766368865967,\n",
       "   0.962458610534668,\n",
       "   0.9622541666030884,\n",
       "   0.9619488716125488,\n",
       "   0.9611549973487854,\n",
       "   0.9621599316596985,\n",
       "   0.96265709400177,\n",
       "   0.9643188714981079,\n",
       "   0.9646236896514893,\n",
       "   0.9653177857398987,\n",
       "   0.9651328325271606,\n",
       "   0.9656283855438232,\n",
       "   0.9657783508300781,\n",
       "   0.9660934805870056,\n",
       "   0.9663841724395752,\n",
       "   0.9660053849220276,\n",
       "   0.9666266441345215,\n",
       "   0.9665228724479675,\n",
       "   0.9672877192497253,\n",
       "   0.9665951728820801,\n",
       "   0.9660485982894897,\n",
       "   0.9658908247947693,\n",
       "   0.9632831811904907,\n",
       "   0.9638689160346985,\n",
       "   0.9630622863769531,\n",
       "   0.9646525382995605,\n",
       "   0.9630304574966431,\n",
       "   0.9587292671203613,\n",
       "   0.9546569585800171,\n",
       "   0.9554692506790161,\n",
       "   0.9503819346427917,\n",
       "   0.946270227432251,\n",
       "   0.9545285701751709,\n",
       "   0.9488515257835388,\n",
       "   0.9496257305145264,\n",
       "   0.9493020176887512,\n",
       "   0.9478219151496887,\n",
       "   0.9519970417022705,\n",
       "   0.954887330532074,\n",
       "   0.9555943608283997,\n",
       "   0.9574476480484009,\n",
       "   0.9570519328117371,\n",
       "   0.9591268301010132,\n",
       "   0.9592998027801514,\n",
       "   0.9603633880615234,\n",
       "   0.9615943431854248,\n",
       "   0.9629219770431519,\n",
       "   0.9618363976478577,\n",
       "   0.9628009796142578,\n",
       "   0.9640010595321655,\n",
       "   0.9640020728111267,\n",
       "   0.9645916819572449,\n",
       "   0.9651395678520203,\n",
       "   0.9652296304702759,\n",
       "   0.9655892848968506,\n",
       "   0.9659421443939209,\n",
       "   0.9653159379959106,\n",
       "   0.9643656015396118,\n",
       "   0.9641113877296448,\n",
       "   0.9640907049179077,\n",
       "   0.9643291234970093,\n",
       "   0.9650062322616577,\n",
       "   0.965614914894104,\n",
       "   0.9662562608718872,\n",
       "   0.9677203893661499,\n",
       "   0.9676103591918945,\n",
       "   0.9680238366127014,\n",
       "   0.9684200882911682,\n",
       "   0.9688540697097778,\n",
       "   0.9690263867378235,\n",
       "   0.9691650867462158,\n",
       "   0.9685444831848145,\n",
       "   0.969025731086731,\n",
       "   0.968937873840332,\n",
       "   0.9690941572189331,\n",
       "   0.9681020975112915,\n",
       "   0.9673120379447937,\n",
       "   0.9676491022109985,\n",
       "   0.9656633734703064,\n",
       "   0.9661204814910889,\n",
       "   0.9659700393676758,\n",
       "   0.9664542078971863,\n",
       "   0.9655987024307251,\n",
       "   0.9641281962394714,\n",
       "   0.9633545875549316,\n",
       "   0.9575141668319702,\n",
       "   0.956950843334198,\n",
       "   0.9576995372772217,\n",
       "   0.9555119276046753,\n",
       "   0.9523195028305054,\n",
       "   0.9525516033172607,\n",
       "   0.9514671564102173,\n",
       "   0.9500341415405273,\n",
       "   0.9475840926170349,\n",
       "   0.9430234432220459,\n",
       "   0.9510449767112732,\n",
       "   0.9506856203079224,\n",
       "   0.9544016718864441,\n",
       "   0.9554411172866821,\n",
       "   0.955767810344696,\n",
       "   0.9574109315872192,\n",
       "   0.9562996029853821,\n",
       "   0.959041178226471,\n",
       "   0.9592840671539307,\n",
       "   0.9599701166152954,\n",
       "   0.9625847339630127,\n",
       "   0.9617882966995239,\n",
       "   0.962386965751648,\n",
       "   0.9636735916137695,\n",
       "   0.9646124839782715,\n",
       "   0.9640939235687256,\n",
       "   0.9641562700271606,\n",
       "   0.9656392931938171,\n",
       "   0.9658430814743042,\n",
       "   0.9664266109466553,\n",
       "   0.9667450189590454,\n",
       "   0.9671201705932617,\n",
       "   0.9682682156562805,\n",
       "   0.9680333733558655,\n",
       "   0.9675876498222351,\n",
       "   0.967487096786499,\n",
       "   0.9674146175384521,\n",
       "   0.9685583114624023,\n",
       "   0.9688712954521179,\n",
       "   0.9683865308761597,\n",
       "   0.9693657159805298,\n",
       "   0.9697265625,\n",
       "   0.9699698090553284,\n",
       "   0.9693253040313721,\n",
       "   0.9687772989273071,\n",
       "   0.9693685173988342,\n",
       "   0.9700924158096313,\n",
       "   0.9705150127410889,\n",
       "   0.9706147909164429,\n",
       "   0.9709917306900024,\n",
       "   0.9706639647483826,\n",
       "   0.9707316756248474,\n",
       "   0.9700053930282593,\n",
       "   0.969057023525238,\n",
       "   0.9687178134918213,\n",
       "   0.9630867838859558,\n",
       "   0.966511070728302,\n",
       "   0.9609684944152832,\n",
       "   0.8709717988967896,\n",
       "   0.8656989336013794,\n",
       "   0.28017061948776245,\n",
       "   0.15318647027015686,\n",
       "   0.23700758814811707,\n",
       "   0.10602372884750366,\n",
       "   0.08499307185411453,\n",
       "   0.10449839383363724,\n",
       "   0.15384969115257263,\n",
       "   0.14328201115131378,\n",
       "   0.11061312258243561,\n",
       "   0.12756679952144623,\n",
       "   0.1500242054462433,\n",
       "   0.146234929561615,\n",
       "   0.14026983082294464,\n",
       "   0.1966741383075714,\n",
       "   0.1984144151210785,\n",
       "   0.1947517991065979,\n",
       "   0.19592460989952087,\n",
       "   0.21809884905815125,\n",
       "   0.22739975154399872,\n",
       "   0.23881569504737854,\n",
       "   0.25015777349472046,\n",
       "   0.297620564699173,\n",
       "   0.2901792526245117,\n",
       "   0.2745095491409302],\n",
       "  'auc': 0.9971712827682495,\n",
       "  'best_epoch': 427,\n",
       "  'f1': 0.8032423853874207,\n",
       "  'learning_rate': 0.01,\n",
       "  'loss': 0.10644231736660004,\n",
       "  'n_hidden': 256,\n",
       "  'precision': 0.6720098853111267,\n",
       "  'recall': 0.9981684684753418,\n",
       "  'total_epochs': 627})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_best_trial(\"KGNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd8656a5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: GraphSAGE\n",
      "GraphSAGE loss: 1.194, acc: 0.926, prc: 0.597, rec: 0.891, f1: 0.715, auc: 0.953, aprc: 0.766\n",
      "Model structure:\n",
      "GraphModule(\n",
      "  (convs): ModuleList(\n",
      "    (0): ModuleDict(\n",
      "      (company__owns__company): SAGEConv(-1, 256, aggr=mean)\n",
      "      (person__owns__company): SAGEConv(-1, 256, aggr=mean)\n",
      "      (company__rev_owns__company): SAGEConv(-1, 256, aggr=mean)\n",
      "      (company__rev_owns__person): SAGEConv(-1, 256, aggr=mean)\n",
      "    )\n",
      "    (1): ModuleDict(\n",
      "      (company__owns__company): SAGEConv(256, 256, aggr=mean)\n",
      "      (person__owns__company): SAGEConv(256, 256, aggr=mean)\n",
      "      (company__rev_owns__company): SAGEConv(256, 256, aggr=mean)\n",
      "      (company__rev_owns__person): SAGEConv(256, 256, aggr=mean)\n",
      "    )\n",
      "    (2): ModuleDict(\n",
      "      (company__owns__company): SAGEConv(256, 1, aggr=mean)\n",
      "      (person__owns__company): SAGEConv(256, 1, aggr=mean)\n",
      "      (company__rev_owns__company): SAGEConv(256, 1, aggr=mean)\n",
      "      (company__rev_owns__person): SAGEConv(256, 1, aggr=mean)\n",
      "    )\n",
      "  )\n",
      "  (act): ModuleDict(\n",
      "    (company): GELU()\n",
      "    (person): GELU()\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x : typing_Dict[str,torch.Tensor], edge_index : typing_Dict[typing_Tuple[str,str,str],typing_Union[torch.Tensor,torch_sparse_tensor_SparseTensor]], edge_weight : typing_Dict[typing_Tuple[str,str,str],typing_Union[torch.Tensor,NoneType]] = None, edge_attr : typing_Dict[typing_Tuple[str,str,str],typing_Union[torch.Tensor,NoneType]] = None):\n",
      "    x_dict = torch_geometric_nn_to_hetero_transformer_get_dict(x);  x = None\n",
      "    x__company = x_dict.get('company', None)\n",
      "    x__person = x_dict.get('person', None);  x_dict = None\n",
      "    edge_index_dict = torch_geometric_nn_to_hetero_transformer_get_dict(edge_index);  edge_index = None\n",
      "    edge_index__company__owns__company = edge_index_dict.get(('company', 'owns', 'company'), None)\n",
      "    edge_index__person__owns__company = edge_index_dict.get(('person', 'owns', 'company'), None)\n",
      "    edge_index__company__rev_owns__company = edge_index_dict.get(('company', 'rev_owns', 'company'), None)\n",
      "    edge_index__company__rev_owns__person = edge_index_dict.get(('company', 'rev_owns', 'person'), None);  edge_index_dict = None\n",
      "    convs_0__company1 = getattr(self.convs, \"0\").company__owns__company(x__company, edge_index__company__owns__company)\n",
      "    convs_0__company2 = getattr(self.convs, \"0\").person__owns__company((x__person, x__company), edge_index__person__owns__company)\n",
      "    convs_0__company3 = getattr(self.convs, \"0\").company__rev_owns__company(x__company, edge_index__company__rev_owns__company)\n",
      "    convs_0__person = getattr(self.convs, \"0\").company__rev_owns__person((x__company, x__person), edge_index__company__rev_owns__person);  x__company = x__person = None\n",
      "    convs_0__company_1 = torch.max(convs_0__company1, convs_0__company2);  convs_0__company1 = convs_0__company2 = None\n",
      "    convs_0__company = torch.max(convs_0__company3, convs_0__company_1);  convs_0__company3 = convs_0__company_1 = None\n",
      "    act__company = self.act.company(convs_0__company);  convs_0__company = None\n",
      "    act__person = self.act.person(convs_0__person);  convs_0__person = None\n",
      "    dropout__company = torch.nn.functional.dropout(act__company, p = 0.0, training = True, inplace = False);  act__company = None\n",
      "    dropout__person = torch.nn.functional.dropout(act__person, p = 0.0, training = True, inplace = False);  act__person = None\n",
      "    convs_1__company1 = getattr(self.convs, \"1\").company__owns__company(dropout__company, edge_index__company__owns__company)\n",
      "    convs_1__company2 = getattr(self.convs, \"1\").person__owns__company((dropout__person, dropout__company), edge_index__person__owns__company)\n",
      "    convs_1__company3 = getattr(self.convs, \"1\").company__rev_owns__company(dropout__company, edge_index__company__rev_owns__company)\n",
      "    convs_1__person = getattr(self.convs, \"1\").company__rev_owns__person((dropout__company, dropout__person), edge_index__company__rev_owns__person);  dropout__company = dropout__person = None\n",
      "    convs_1__company_1 = torch.max(convs_1__company1, convs_1__company2);  convs_1__company1 = convs_1__company2 = None\n",
      "    convs_1__company = torch.max(convs_1__company3, convs_1__company_1);  convs_1__company3 = convs_1__company_1 = None\n",
      "    act_1__company = self.act.company(convs_1__company);  convs_1__company = None\n",
      "    act_1__person = self.act.person(convs_1__person);  convs_1__person = None\n",
      "    dropout_1__company = torch.nn.functional.dropout(act_1__company, p = 0.0, training = True, inplace = False);  act_1__company = None\n",
      "    dropout_1__person = torch.nn.functional.dropout(act_1__person, p = 0.0, training = True, inplace = False);  act_1__person = None\n",
      "    convs_2__company1 = getattr(self.convs, \"2\").company__owns__company(dropout_1__company, edge_index__company__owns__company);  edge_index__company__owns__company = None\n",
      "    convs_2__company2 = getattr(self.convs, \"2\").person__owns__company((dropout_1__person, dropout_1__company), edge_index__person__owns__company);  edge_index__person__owns__company = None\n",
      "    convs_2__company3 = getattr(self.convs, \"2\").company__rev_owns__company(dropout_1__company, edge_index__company__rev_owns__company);  edge_index__company__rev_owns__company = None\n",
      "    convs_2__person = getattr(self.convs, \"2\").company__rev_owns__person((dropout_1__company, dropout_1__person), edge_index__company__rev_owns__person);  dropout_1__company = dropout_1__person = edge_index__company__rev_owns__person = None\n",
      "    convs_2__company_1 = torch.max(convs_2__company1, convs_2__company2);  convs_2__company1 = convs_2__company2 = None\n",
      "    convs_2__company = torch.max(convs_2__company3, convs_2__company_1);  convs_2__company3 = convs_2__company_1 = None\n",
      "    sigmoid__company = torch.sigmoid(convs_2__company);  convs_2__company = None\n",
      "    sigmoid__person = torch.sigmoid(convs_2__person);  convs_2__person = None\n",
      "    return {'company': sigmoid__company, 'person': sigmoid__person}\n",
      "    \n",
      "Making predictions...\n",
      "Saving predictions...\n",
      "Evaluating model: GCN\n",
      "GCN loss: 0.925, acc: 0.932, prc: 0.617, rec: 0.970, f1: 0.754, auc: 0.982, aprc: 0.903\n",
      "Model structure:\n",
      "GraphModule(\n",
      "  (convs): ModuleList(\n",
      "    (0): ModuleDict(\n",
      "      (company__owns__company): GraphConv(-1, 128)\n",
      "      (person__owns__company): GraphConv(-1, 128)\n",
      "      (company__rev_owns__company): GraphConv(-1, 128)\n",
      "      (company__rev_owns__person): GraphConv(-1, 128)\n",
      "    )\n",
      "    (1): ModuleDict(\n",
      "      (company__owns__company): GraphConv(128, 128)\n",
      "      (person__owns__company): GraphConv(128, 128)\n",
      "      (company__rev_owns__company): GraphConv(128, 128)\n",
      "      (company__rev_owns__person): GraphConv(128, 128)\n",
      "    )\n",
      "    (2): ModuleDict(\n",
      "      (company__owns__company): GraphConv(128, 128)\n",
      "      (person__owns__company): GraphConv(128, 128)\n",
      "      (company__rev_owns__company): GraphConv(128, 128)\n",
      "      (company__rev_owns__person): GraphConv(128, 128)\n",
      "    )\n",
      "    (3): ModuleDict(\n",
      "      (company__owns__company): GraphConv(128, 128)\n",
      "      (person__owns__company): GraphConv(128, 128)\n",
      "      (company__rev_owns__company): GraphConv(128, 128)\n",
      "      (company__rev_owns__person): GraphConv(128, 128)\n",
      "    )\n",
      "  )\n",
      "  (act): ModuleDict(\n",
      "    (company): GELU()\n",
      "    (person): GELU()\n",
      "  )\n",
      "  (lin): ModuleDict(\n",
      "    (company): Linear(in_features=128, out_features=1, bias=True)\n",
      "    (person): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x : typing_Dict[str,torch.Tensor], edge_index : typing_Dict[typing_Tuple[str,str,str],typing_Union[torch.Tensor,torch_sparse_tensor_SparseTensor]], edge_weight : typing_Dict[typing_Tuple[str,str,str],typing_Union[torch.Tensor,NoneType]] = None, edge_attr : typing_Dict[typing_Tuple[str,str,str],typing_Union[torch.Tensor,NoneType]] = None):\n",
      "    x_dict = torch_geometric_nn_to_hetero_transformer_get_dict(x);  x = None\n",
      "    x__company = x_dict.get('company', None)\n",
      "    x__person = x_dict.get('person', None);  x_dict = None\n",
      "    edge_index_dict = torch_geometric_nn_to_hetero_transformer_get_dict(edge_index);  edge_index = None\n",
      "    edge_index__company__owns__company = edge_index_dict.get(('company', 'owns', 'company'), None)\n",
      "    edge_index__person__owns__company = edge_index_dict.get(('person', 'owns', 'company'), None)\n",
      "    edge_index__company__rev_owns__company = edge_index_dict.get(('company', 'rev_owns', 'company'), None)\n",
      "    edge_index__company__rev_owns__person = edge_index_dict.get(('company', 'rev_owns', 'person'), None);  edge_index_dict = None\n",
      "    edge_weight_dict = torch_geometric_nn_to_hetero_transformer_get_dict(edge_weight);  edge_weight = None\n",
      "    edge_weight__company__owns__company = edge_weight_dict.get(('company', 'owns', 'company'), None)\n",
      "    edge_weight__person__owns__company = edge_weight_dict.get(('person', 'owns', 'company'), None)\n",
      "    edge_weight__company__rev_owns__company = edge_weight_dict.get(('company', 'rev_owns', 'company'), None)\n",
      "    edge_weight__company__rev_owns__person = edge_weight_dict.get(('company', 'rev_owns', 'person'), None);  edge_weight_dict = None\n",
      "    convs_0__company1 = getattr(self.convs, \"0\").company__owns__company(x__company, edge_index__company__owns__company, edge_weight = edge_weight__company__owns__company)\n",
      "    convs_0__company2 = getattr(self.convs, \"0\").person__owns__company((x__person, x__company), edge_index__person__owns__company, edge_weight = edge_weight__person__owns__company)\n",
      "    convs_0__company3 = getattr(self.convs, \"0\").company__rev_owns__company(x__company, edge_index__company__rev_owns__company, edge_weight = edge_weight__company__rev_owns__company)\n",
      "    convs_0__person = getattr(self.convs, \"0\").company__rev_owns__person((x__company, x__person), edge_index__company__rev_owns__person, edge_weight = edge_weight__company__rev_owns__person);  x__company = x__person = None\n",
      "    convs_0__company_1 = torch.min(convs_0__company1, convs_0__company2);  convs_0__company1 = convs_0__company2 = None\n",
      "    convs_0__company = torch.min(convs_0__company3, convs_0__company_1);  convs_0__company3 = convs_0__company_1 = None\n",
      "    act__company = self.act.company(convs_0__company);  convs_0__company = None\n",
      "    act__person = self.act.person(convs_0__person);  convs_0__person = None\n",
      "    dropout__company = torch.nn.functional.dropout(act__company, p = 0.0, training = True, inplace = False);  act__company = None\n",
      "    dropout__person = torch.nn.functional.dropout(act__person, p = 0.0, training = True, inplace = False);  act__person = None\n",
      "    convs_1__company1 = getattr(self.convs, \"1\").company__owns__company(dropout__company, edge_index__company__owns__company, edge_weight = edge_weight__company__owns__company)\n",
      "    convs_1__company2 = getattr(self.convs, \"1\").person__owns__company((dropout__person, dropout__company), edge_index__person__owns__company, edge_weight = edge_weight__person__owns__company)\n",
      "    convs_1__company3 = getattr(self.convs, \"1\").company__rev_owns__company(dropout__company, edge_index__company__rev_owns__company, edge_weight = edge_weight__company__rev_owns__company)\n",
      "    convs_1__person = getattr(self.convs, \"1\").company__rev_owns__person((dropout__company, dropout__person), edge_index__company__rev_owns__person, edge_weight = edge_weight__company__rev_owns__person);  dropout__company = dropout__person = None\n",
      "    convs_1__company_1 = torch.min(convs_1__company1, convs_1__company2);  convs_1__company1 = convs_1__company2 = None\n",
      "    convs_1__company = torch.min(convs_1__company3, convs_1__company_1);  convs_1__company3 = convs_1__company_1 = None\n",
      "    act_1__company = self.act.company(convs_1__company);  convs_1__company = None\n",
      "    act_1__person = self.act.person(convs_1__person);  convs_1__person = None\n",
      "    dropout_1__company = torch.nn.functional.dropout(act_1__company, p = 0.0, training = True, inplace = False);  act_1__company = None\n",
      "    dropout_1__person = torch.nn.functional.dropout(act_1__person, p = 0.0, training = True, inplace = False);  act_1__person = None\n",
      "    convs_2__company1 = getattr(self.convs, \"2\").company__owns__company(dropout_1__company, edge_index__company__owns__company, edge_weight = edge_weight__company__owns__company)\n",
      "    convs_2__company2 = getattr(self.convs, \"2\").person__owns__company((dropout_1__person, dropout_1__company), edge_index__person__owns__company, edge_weight = edge_weight__person__owns__company)\n",
      "    convs_2__company3 = getattr(self.convs, \"2\").company__rev_owns__company(dropout_1__company, edge_index__company__rev_owns__company, edge_weight = edge_weight__company__rev_owns__company)\n",
      "    convs_2__person = getattr(self.convs, \"2\").company__rev_owns__person((dropout_1__company, dropout_1__person), edge_index__company__rev_owns__person, edge_weight = edge_weight__company__rev_owns__person);  dropout_1__company = dropout_1__person = None\n",
      "    convs_2__company_1 = torch.min(convs_2__company1, convs_2__company2);  convs_2__company1 = convs_2__company2 = None\n",
      "    convs_2__company = torch.min(convs_2__company3, convs_2__company_1);  convs_2__company3 = convs_2__company_1 = None\n",
      "    act_2__company = self.act.company(convs_2__company);  convs_2__company = None\n",
      "    act_2__person = self.act.person(convs_2__person);  convs_2__person = None\n",
      "    dropout_2__company = torch.nn.functional.dropout(act_2__company, p = 0.0, training = True, inplace = False);  act_2__company = None\n",
      "    dropout_2__person = torch.nn.functional.dropout(act_2__person, p = 0.0, training = True, inplace = False);  act_2__person = None\n",
      "    convs_3__company1 = getattr(self.convs, \"3\").company__owns__company(dropout_2__company, edge_index__company__owns__company, edge_weight = edge_weight__company__owns__company);  edge_index__company__owns__company = edge_weight__company__owns__company = None\n",
      "    convs_3__company2 = getattr(self.convs, \"3\").person__owns__company((dropout_2__person, dropout_2__company), edge_index__person__owns__company, edge_weight = edge_weight__person__owns__company);  edge_index__person__owns__company = edge_weight__person__owns__company = None\n",
      "    convs_3__company3 = getattr(self.convs, \"3\").company__rev_owns__company(dropout_2__company, edge_index__company__rev_owns__company, edge_weight = edge_weight__company__rev_owns__company);  edge_index__company__rev_owns__company = edge_weight__company__rev_owns__company = None\n",
      "    convs_3__person = getattr(self.convs, \"3\").company__rev_owns__person((dropout_2__company, dropout_2__person), edge_index__company__rev_owns__person, edge_weight = edge_weight__company__rev_owns__person);  dropout_2__company = dropout_2__person = edge_index__company__rev_owns__person = edge_weight__company__rev_owns__person = None\n",
      "    convs_3__company_1 = torch.min(convs_3__company1, convs_3__company2);  convs_3__company1 = convs_3__company2 = None\n",
      "    convs_3__company = torch.min(convs_3__company3, convs_3__company_1);  convs_3__company3 = convs_3__company_1 = None\n",
      "    act_3__company = self.act.company(convs_3__company);  convs_3__company = None\n",
      "    act_3__person = self.act.person(convs_3__person);  convs_3__person = None\n",
      "    dropout_3__company = torch.nn.functional.dropout(act_3__company, p = 0.0, training = True, inplace = False);  act_3__company = None\n",
      "    dropout_3__person = torch.nn.functional.dropout(act_3__person, p = 0.0, training = True, inplace = False);  act_3__person = None\n",
      "    lin__company = self.lin.company(dropout_3__company);  dropout_3__company = None\n",
      "    lin__person = self.lin.person(dropout_3__person);  dropout_3__person = None\n",
      "    sigmoid__company = torch.sigmoid(lin__company);  lin__company = None\n",
      "    sigmoid__person = torch.sigmoid(lin__person);  lin__person = None\n",
      "    return {'company': sigmoid__company, 'person': sigmoid__person}\n",
      "    \n",
      "Making predictions...\n",
      "Saving predictions...\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model_metrics = {}\n",
    "\n",
    "# Load and evaluate models\n",
    "for model_name in model_names:\n",
    "\n",
    "    print(\"Evaluating model:\", model_name)\n",
    "\n",
    "    model_path = MODEL_DIR / f\"{model_name}.pt\"\n",
    "\n",
    "    if not model_path.exists():\n",
    "        print(f\"Model {model_name} does not exist, skipping\")\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"Loading model from: {model_path}\")\n",
    "\n",
    "    model_params, user_attrs = get_best_trial(model_name)\n",
    "    user_attrs[\"model_type\"] = model_name\n",
    "    del user_attrs[\"aprc_history\"]\n",
    "\n",
    "    print(f\"Using model params: {model_params}\")\n",
    "    print(f\"Using user attrs: {user_attrs}\")\n",
    "\n",
    "    dataset = CompanyBeneficialOwners(DATASET_PATH, to_undirected=True)\n",
    "    dataset = dataset.data.to(device)\n",
    "\n",
    "    model, optimiser, _ = exp.build_experiment_from_trial_params(\n",
    "        model_params, user_attrs, dataset\n",
    "    )\n",
    "    model.load_state_dict(torch.load(model_path, map_location=torch.device(device)))\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    if model_params[\"add_self_loops\"]:\n",
    "        dataset = AddSelfLoops(fill_value=1.0)(dataset)\n",
    "    else:\n",
    "        dataset = RemoveSelfLoops()(dataset)\n",
    "\n",
    "    eval_metrics = exp.evaluate(\n",
    "        model, dataset, on_train=False, on_val=False, on_test=True\n",
    "    )\n",
    "\n",
    "    model_metrics[model_name] = eval_metrics.test\n",
    "    print(model_name, eval_metrics.test)\n",
    "\n",
    "    print(\"Making predictions...\")\n",
    "    prediction_dict = model(dataset.x_dict, dataset.edge_index_dict)\n",
    "    prediction_df_list = []\n",
    "\n",
    "    print(\"Saving predictions...\")\n",
    "    for node_type in dataset.node_types:\n",
    "        prediction = (\n",
    "            prediction_dict[node_type][dataset[node_type].test_mask]\n",
    "            .cpu()\n",
    "            .detach()\n",
    "            .numpy()\n",
    "            .flatten()\n",
    "        )\n",
    "        actual = (\n",
    "            dataset.y_dict[node_type][dataset[node_type].test_mask]\n",
    "            .cpu()\n",
    "            .detach()\n",
    "            .numpy()\n",
    "            .flatten()\n",
    "        )\n",
    "        df = pd.DataFrame({\"pred_proba\": prediction, \"actual\": actual})\n",
    "        prediction_df_list.append(df)\n",
    "\n",
    "    prediction_df = pd.concat(prediction_df_list)\n",
    "    prediction_df.to_csv(PREDICTION_DIR / f\"{model_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d62fce2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_comparison = pd.DataFrame.from_dict(model_metrics, orient=\"index\")\n",
    "performance_comparison.to_csv(\"reports/test-performance-pyg.csv\", index_label=\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b6ddfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c9b131bfea46adc0e6841e7be18b140852cf163d67d3b9948cbb78fda58292a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
