{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "\n",
    "import pdcast as pdc\n",
    "\n",
    "while not Path(\"data\") in Path(\".\").iterdir():\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "import sklearn.preprocessing as pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read config.\n",
    "conf_dict = yaml.safe_load(Path(\"config/conf.yaml\").read_text())\n",
    "\n",
    "persons_df = pd.read_parquet(conf_dict[\"persons_nodes\"])\n",
    "companies_df = pd.read_parquet(conf_dict[\"companies_nodes\"])\n",
    "edges_df = pd.read_parquet(conf_dict[\"edges\"])\n",
    "\n",
    "features_path = conf_dict[\"preprocessed_features_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load features for data split.\n",
    "def load_features(path_root, split):\n",
    "    features_dir = Path(path_root) / split\n",
    "    companies_df = pd.read_parquet(features_dir / \"companies.parquet\").dropna()\n",
    "    persons_df = pd.read_parquet(features_dir / \"persons.parquet\").dropna()\n",
    "    return companies_df, persons_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies_train_df, persons_train_df = load_features(features_path, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_cols = set(companies_train_df.columns) & set(persons_train_df.columns)\n",
    "processed_feature_cols = [x for x in select_cols if x.endswith(\"__processed\")]\n",
    "raw_feature_cols = [x.split(\"__processed\")[0] for x in processed_feature_cols]\n",
    "target = \"is_anomalous\"\n",
    "\n",
    "entities_df = pd.concat([companies_train_df, persons_train_df], axis=0)\n",
    "\n",
    "# Sample entities_df so that half of the entities are anomalous.\n",
    "def balanced_sample(entities_df) -> pd.DataFrame:\n",
    "    n_entities = len(entities_df)\n",
    "    n_anomalous = len(entities_df[entities_df[target] == True])\n",
    "    n_normal = n_entities - n_anomalous\n",
    "    n_sample = min(n_anomalous, n_normal)\n",
    "    anomalous_df = entities_df.query(\"is_anomalous == False\").sample(n_sample)\n",
    "    normal_df = entities_df.query(\"is_anomalous == True\").sample(n_sample)\n",
    "    return pd.concat([anomalous_df, normal_df], axis=0)\n",
    "\n",
    "\n",
    "balanced_sample_df = balanced_sample(entities_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([balanced_sample_df[processed_feature_cols]], axis=0)\n",
    "y = balanced_sample_df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1902\n",
       "True     1902\n",
       "Name: is_anomalous, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5177398160315374\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.52      0.56      0.54       386\n",
      "        True       0.51      0.47      0.49       375\n",
      "\n",
      "    accuracy                           0.52       761\n",
      "   macro avg       0.52      0.52      0.52       761\n",
      "weighted avg       0.52      0.52      0.52       761\n",
      "\n",
      "[[217 169]\n",
      " [198 177]]\n"
     ]
    }
   ],
   "source": [
    "# Train logistic regression model.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "logreg = LogisticRegression(solver=\"lbfgs\", max_iter=1000)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", acc)\n",
    "\n",
    "## classification report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "## confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5137976346911958\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.52      0.55      0.54       386\n",
      "        True       0.51      0.47      0.49       375\n",
      "\n",
      "    accuracy                           0.51       761\n",
      "   macro avg       0.51      0.51      0.51       761\n",
      "weighted avg       0.51      0.51      0.51       761\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Train random forest model.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Random forest classifier.\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", acc)\n",
    "\n",
    "# classification report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c9b131bfea46adc0e6841e7be18b140852cf163d67d3b9948cbb78fda58292a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
