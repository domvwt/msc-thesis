{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/06/25 17:36:49 WARN Utils: Your hostname, domvwt-XPS-13-9305 resolves to a loopback address: 127.0.1.1; using 192.168.0.24 instead (on interface wlp164s0)\n",
      "22/06/25 17:36:49 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "22/06/25 17:36:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/06/25 17:36:50 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pyspark.sql.functions as F\n",
    "import yaml\n",
    "\n",
    "import graphframes as gf\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "while not Path(\"data\") in Path(\".\").iterdir():\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "plt.style.use(\"seaborn-white\")\n",
    "conf_dict = yaml.safe_load(Path(\"config/conf.yaml\").read_text())\n",
    "\n",
    "checkpoint_dir = str(Path(\"spark-checkpoints\").absolute())\n",
    "graphframes_jar_path = str(\n",
    "    Path(\n",
    "        \".venv/lib/python3.9/site-packages/pyspark/jars/graphframes-0.8.2-spark3.1-s_2.12.jar\"\n",
    "    ).absolute()\n",
    ")\n",
    "\n",
    "spark_conf = (\n",
    "    SparkConf()\n",
    "    .set(\"spark.jars\", graphframes_jar_path)\n",
    "    .set(\"spark.sql.sources.partitionOverwriteMode\", \"dynamic\")\n",
    ")\n",
    "\n",
    "sc = SparkContext(conf=spark_conf).getOrCreate()\n",
    "sc.setCheckpointDir(checkpoint_dir)\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "\n",
    "spark = SparkSession.builder.config(\"spark.driver.memory\", \"8g\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies_processed_df = spark.read.parquet(conf_dict[\"companies_processed\"])\n",
    "relationships_processed_df = spark.read.parquet(conf_dict[\"relationships_processed\"])\n",
    "persons_processed_df = spark.read.parquet(conf_dict[\"persons_processed\"])\n",
    "nodes_df = spark.read.parquet(conf_dict[\"nodes\"])\n",
    "edges_df = spark.read.parquet(conf_dict[\"edges\"])\n",
    "connected_components = spark.read.parquet(conf_dict[\"connected_components\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count: 12,716,813\n",
      "Edge count: 5,704,926\n"
     ]
    }
   ],
   "source": [
    "print(f\"Node count: {nodes_df.count():,}\")\n",
    "print(f\"Edge count: {edges_df.count():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = gf.GraphFrame(connected_components, edges_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:=========================================>            (155 + 8) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected component count: 7,648,306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "component_sizes = (\n",
    "    connected_components.groupBy(\"component\").count().orderBy(F.desc(\"count\"))\n",
    ")\n",
    "print(f\"Connected component count: {component_sizes.count():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 103:======================================>                  (6 + 3) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|  component|count|\n",
      "+-----------+-----+\n",
      "| 8589988227|  300|\n",
      "|      16691|  298|\n",
      "|17179878787|  289|\n",
      "|      22303|  283|\n",
      "|      40669|  273|\n",
      "|       6587|  265|\n",
      "|      15187|  263|\n",
      "| 8589934701|  258|\n",
      "|      12283|  252|\n",
      "| 8589969829|  247|\n",
      "|        774|  243|\n",
      "|       1211|  236|\n",
      "| 8589960992|  234|\n",
      "|       9278|  231|\n",
      "|      51040|  227|\n",
      "|17179910232|  207|\n",
      "|      38111|  207|\n",
      "|17179898898|  206|\n",
      "| 8589982438|  205|\n",
      "| 8589941079|  203|\n",
      "+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "component_sizes.filter(\"count <= 300\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:===================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large component count: 12,039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "large_components = component_sizes.filter(\"count >= 10\")\n",
    "large_components.count()\n",
    "print(f\"Large component count: {large_components.count():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "large_component_ids = [\n",
    "    row.component for row in large_components.select(\"component\").collect()\n",
    "]\n",
    "graph_filtered = (\n",
    "    graph.filterVertices(F.col(\"component\").isin(large_component_ids))\n",
    "    .dropIsolatedVertices()\n",
    "    .cache()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "edges_filtered_df = graph_filtered.edges\n",
    "edges_filtered_df.write.parquet(\"data/graph/component-edges.parquet\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|isCompany| count|\n",
      "+---------+------+\n",
      "|     true|229736|\n",
      "|    false| 37120|\n",
      "+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graph_filtered.vertices.groupBy(\"isCompany\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph_pageranked = graph_filtered.pageRank(resetProbability=0.1, maxIter=20)\n",
    "# nodes_pageranked = graph_pageranked.vertices.select(\"id\", F.col(\"pagerank\").cast(\"Long\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "nodes_filtered_df = (\n",
    "    graph_filtered.vertices.join(graph_filtered.inDegrees, [\"id\"], how=\"left\")\n",
    "    .join(graph_filtered.outDegrees, [\"id\"], how=\"left\")\n",
    "    .join(\n",
    "        graph_filtered.triangleCount()\n",
    "        .withColumnRenamed(\"count\", \"triangleCount\")\n",
    "        .select(\"id\", \"triangleCount\"),\n",
    "        [\"id\"],\n",
    "    )\n",
    "    # .join(nodes_pageranked, [\"id\"])\n",
    "    .fillna(0)\n",
    ")\n",
    "nodes_filtered_df.write.parquet(\"data/graph/component-nodes.parquet\", mode=\"overwrite\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c9b131bfea46adc0e6841e7be18b140852cf163d67d3b9948cbb78fda58292a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
